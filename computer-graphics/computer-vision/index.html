<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-computer-graphics/computer-vision/computer-vision">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.21">
<title data-rh="true">Computer vision | Learning Resources</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://github.com/kinderheim/computer-graphics/computer-vision/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Computer vision | Learning Resources"><meta data-rh="true" name="description" content="LiT (Locked-image Tuning) paper is neat. Trying to understand Vision Transformers. Kornia seems like a great library. Imagen is fascinating."><meta data-rh="true" property="og:description" content="LiT (Locked-image Tuning) paper is neat. Trying to understand Vision Transformers. Kornia seems like a great library. Imagen is fascinating."><link data-rh="true" rel="icon" href="/kinderheim/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://github.com/kinderheim/computer-graphics/computer-vision/"><link data-rh="true" rel="alternate" href="https://github.com/kinderheim/computer-graphics/computer-vision/" hreflang="en"><link data-rh="true" rel="alternate" href="https://github.com/kinderheim/computer-graphics/computer-vision/" hreflang="x-default"><link rel="stylesheet" href="/kinderheim/assets/css/styles.45761c4f.css">
<link rel="preload" href="/kinderheim/assets/js/runtime~main.92f61fd9.js" as="script">
<link rel="preload" href="/kinderheim/assets/js/main.b95d4106.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/kinderheim/"><div class="navbar__logo"><img src="/kinderheim/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/kinderheim/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Resources</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/ecioran/kinderheim" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/3d-printing/">3D Printing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/kinderheim/Privacy-Adblock/Privacy--Adblock">Privacy-Adblock</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/analytics/">Analytics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Analytics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/android-ios/">Android-IOS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/anki/">Anki</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/api/">API</a><button aria-label="Toggle the collapsible sidebar category &#x27;API&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/art/">Art</a><button aria-label="Toggle the collapsible sidebar category &#x27;Art&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/augmented-reality/">Augmented Reality</a><button aria-label="Toggle the collapsible sidebar category &#x27;Augmented Reality&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/automation/">Automation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Automation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/backups/">Backups</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/biology/">Biology</a><button aria-label="Toggle the collapsible sidebar category &#x27;Biology&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/books/">Books</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/books-2.0/">Books</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/business/">Business</a><button aria-label="Toggle the collapsible sidebar category &#x27;Business&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/chemistry/">Chemistry</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cli/">Command Line Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Command Line Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cloud-computing/">Cloud computing</a><button aria-label="Toggle the collapsible sidebar category &#x27;Cloud computing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/code/">Code</a><button aria-label="Toggle the collapsible sidebar category &#x27;Code&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/compilers/">Compilers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Compilers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/kinderheim/computer-graphics/">Computer graphics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer graphics&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/bezier-curves">Bézier curves</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" aria-expanded="true" tabindex="0" href="/kinderheim/computer-graphics/computer-vision/">Computer vision</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer vision&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/computer-vision/ocr">Optical character recognition</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/cuda">CUDA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/image-processing">Image processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/metal">Metal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/opengl">OpenGL</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/procedural-generation">Procedural generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/ray-tracing">Ray tracing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/rendering">Rendering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/shaders">Shaders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/svg">SVG</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/vulkan">Vulkan API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/webgl">WebGL</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/computer-graphics/webgpu">WebGPU</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/computer-science/">Computer Science</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer Science&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/consciousness/">Consciousness</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/courses/">Courses</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cryptocurrencies/">Cryptocurrencies</a><button aria-label="Toggle the collapsible sidebar category &#x27;Cryptocurrencies&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/data-science/">Data Science</a><button aria-label="Toggle the collapsible sidebar category &#x27;Data Science&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/databases/">Databases</a><button aria-label="Toggle the collapsible sidebar category &#x27;Databases&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/design/">Design</a><button aria-label="Toggle the collapsible sidebar category &#x27;Design&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/devops/">DevOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/distributed-systems/">Distributed systems</a><button aria-label="Toggle the collapsible sidebar category &#x27;Distributed systems&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/documentaries/">Documentaries</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/education/">Education</a><button aria-label="Toggle the collapsible sidebar category &#x27;Education&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/future/">Future</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/hardware/">Hardware</a><button aria-label="Toggle the collapsible sidebar category &#x27;Hardware&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/history/">History</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/">Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/latex/">LaTeX</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/machine-learning/">Machine learning</a><button aria-label="Toggle the collapsible sidebar category &#x27;Machine learning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/math/">Math</a><button aria-label="Toggle the collapsible sidebar category &#x27;Math&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/networking/">Networking</a><button aria-label="Toggle the collapsible sidebar category &#x27;Networking&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/neuroscience/">Neuroscience</a><button aria-label="Toggle the collapsible sidebar category &#x27;Neuroscience&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/nlp/">Natural language processing</a><button aria-label="Toggle the collapsible sidebar category &#x27;Natural language processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/open-source/">Open Source</a><button aria-label="Toggle the collapsible sidebar category &#x27;Open Source&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/operating-systems/">Operating systems</a><button aria-label="Toggle the collapsible sidebar category &#x27;Operating systems&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/philosophy/">Philosophy</a><button aria-label="Toggle the collapsible sidebar category &#x27;Philosophy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/physics/">Physics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Physics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/privacy-2.0/">Privacy</a><button aria-label="Toggle the collapsible sidebar category &#x27;Privacy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/programming/">Programming</a><button aria-label="Toggle the collapsible sidebar category &#x27;Programming&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/programming-languages/">Programming languages</a><button aria-label="Toggle the collapsible sidebar category &#x27;Programming languages&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/research/">Research</a><button aria-label="Toggle the collapsible sidebar category &#x27;Research&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/research-papers/">Research papers</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/robots/">Robots</a><button aria-label="Toggle the collapsible sidebar category &#x27;Robots&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/security/">Security</a><button aria-label="Toggle the collapsible sidebar category &#x27;Security&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/space/">Space</a><button aria-label="Toggle the collapsible sidebar category &#x27;Space&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/virtual-reality/">Virtual reality</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/web/">Web</a><button aria-label="Toggle the collapsible sidebar category &#x27;Web&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_GujU"><div class="docItemContainer_Adtb"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/kinderheim/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/kinderheim/computer-graphics/"><span itemprop="name">Computer graphics</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Computer vision</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_aoJ5"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Computer vision</h1><p><a href="https://twitter.com/giffmana/status/1508400604082806785" target="_blank" rel="noopener noreferrer">LiT (Locked-image Tuning)</a> paper is neat. Trying to understand <a href="https://github.com/lucidrains/vit-pytorch" target="_blank" rel="noopener noreferrer">Vision Transformers</a>. <a href="https://github.com/kornia/kornia" target="_blank" rel="noopener noreferrer">Kornia</a> seems like a great library. <a href="https://github.com/lucidrains/imagen-pytorch" target="_blank" rel="noopener noreferrer">Imagen</a> is fascinating.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="links">Links<a class="hash-link" href="#links" title="Direct link to heading">​</a></h2><ul><li><a href="https://github.com/opencv/opencv" target="_blank" rel="noopener noreferrer">OpenCV</a> - Open Source Computer Vision Library. (<a href="https://opencv.org/" target="_blank" rel="noopener noreferrer">Web</a>) (<a href="https://www.youtube.com/watch?v=oXlwWbU8l2o" target="_blank" rel="noopener noreferrer">OpenCV Course</a>)</li><li><a href="https://github.com/dmlc/gluon-cv" target="_blank" rel="noopener noreferrer">Gluon CV Toolkit</a> - Provides implementations of the sate-of-the-art (SOTA) deep learning models in computer vision.</li><li><a href="https://github.com/facebookresearch/pythia" target="_blank" rel="noopener noreferrer">Pythia</a> - Modular framework for vision and language multimodal research. Built on top of PyTorch.</li><li><a href="https://github.com/zllrunning/video-object-removal" target="_blank" rel="noopener noreferrer">video-object-removal</a> - Just draw a bounding box and you can remove the object you want to remove.</li><li><a href="https://github.com/hybridgroup/gocv" target="_blank" rel="noopener noreferrer">GoCV</a> - Go package for computer vision using OpenCV 4 and beyond.</li><li><a href="https://github.com/osmr/imgclsmob" target="_blank" rel="noopener noreferrer">Sandbox for training convolutional networks for computer vision</a></li><li><a href="https://www.pyimagesearch.com/start-here/" target="_blank" rel="noopener noreferrer">Get started with Computer Vision, Deep Learning, and OpenCV</a></li><li><a href="https://github.com/donnyyou/torchcv" target="_blank" rel="noopener noreferrer">TorchCV</a> - PyTorch-Based Framework for Deep Learning in Computer Vision.</li><li><a href="https://github.com/facebookresearch/habitat-sim" target="_blank" rel="noopener noreferrer">AI Habitat</a> - Flexible, high-performance 3D simulator for Embodied AI research.</li><li><a href="https://github.com/kornia/kornia" target="_blank" rel="noopener noreferrer">Kornia</a> - Open Source Differentiable Computer Vision Library for PyTorch. (<a href="https://kornia.github.io//" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://roboflow.com/" target="_blank" rel="noopener noreferrer">Roboflow</a> - Raw images to trained computer vision model. (<a href="https://nickarner.com/notes/roboflow-memo-february-1-2021/" target="_blank" rel="noopener noreferrer">Article</a>)</li><li><a href="https://github.com/facebookresearch/SlowFast" target="_blank" rel="noopener noreferrer">PySlowFast</a> - Open source video understanding codebase from FAIR that provides state-of-the-art video classification models.</li><li><a href="https://brohrer.github.io/images_to_numbers.html" target="_blank" rel="noopener noreferrer">How to Convert a Picture to Numbers</a></li><li><a href="https://github.com/jbhuang0604/awesome-computer-vision" target="_blank" rel="noopener noreferrer">Awesome Computer Vision</a></li><li><a href="https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p" target="_blank" rel="noopener noreferrer">The Ancient Secrets of Computer Vision (2018)</a></li><li><a href="https://www.youtube.com/watch?v=fpw26tpHGr8&amp;list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI" target="_blank" rel="noopener noreferrer">Variational Methods for Computer Vision lectures (2013)</a></li><li><a href="https://github.com/facebookresearch/ClassyVision" target="_blank" rel="noopener noreferrer">Classy Vision</a> - New end-to-end, PyTorch-based framework for large-scale training of state-of-the-art image and video classification models.</li><li><a href="https://github.com/alicevision/meshroom" target="_blank" rel="noopener noreferrer">Meshroom</a> - 3D Reconstruction Software.</li><li><a href="https://alicevision.org/" target="_blank" rel="noopener noreferrer">AliceVision</a> - Photogrammetric Computer Vision Framework. (<a href="https://github.com/alicevision/AliceVision" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/alicevision" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="https://github.com/facebookresearch/pytorch3d" target="_blank" rel="noopener noreferrer">PyTorch3d</a> - Provides efficient, reusable components for 3D Computer Vision research with PyTorch. (<a href="https://pytorch3d.org/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/ageitgey/face_recognition" target="_blank" rel="noopener noreferrer">Face Recognition</a> - World&#x27;s simplest facial recognition api for Python and the command line.</li><li><a href="https://github.com/facebookresearch/votenet" target="_blank" rel="noopener noreferrer">Deep Hough Voting for 3D Object Detection in Point Clouds</a></li><li><a href="https://github.com/PointCloudLibrary/pcl" target="_blank" rel="noopener noreferrer">Point Cloud Library</a> - Standalone, large scale, open project for 2D/3D image and point cloud processing.</li><li><a href="https://github.com/jasonmayes/Real-Time-Person-Removal" target="_blank" rel="noopener noreferrer">Disappearing-People</a> - Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. (<a href="https://news.ycombinator.com/item?id=22353596" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/microsoft/computervision-recipes" target="_blank" rel="noopener noreferrer">Best Practices, code samples, and documentation for Computer Vision</a></li><li><a href="https://github.com/amzn/computer-vision-basics-in-microsoft-excel" target="_blank" rel="noopener noreferrer">Computer Vision Basics in Microsoft Excel</a></li><li><a href="https://arxiv.org/abs/2002.10880" target="_blank" rel="noopener noreferrer">PolyGen: An Autoregressive Generative Model of 3D Meshes (2020)</a></li><li><a href="https://github.com/strasdat/Sophus" target="_blank" rel="noopener noreferrer">Sophus</a> - C++ implementation of Lie Groups using Eigen.</li><li><a href="https://github.com/MIPT-Oulu/solt" target="_blank" rel="noopener noreferrer">SOLT</a> - Streaming over lightweight data transformations.</li><li><a href="https://github.com/jiachenli94/Awesome-Interaction-aware-Trajectory-Prediction" target="_blank" rel="noopener noreferrer">Awesome Interaction-aware Behavior and Trajectory Prediction</a></li><li><a href="http://www.robots.ox.ac.uk/~ow/synsin.html" target="_blank" rel="noopener noreferrer">SynSin: End-to-end View Synthesis from a Single Image (2020)</a> (<a href="https://github.com/facebookresearch/synsin" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/nywang16/Pixel2Mesh" target="_blank" rel="noopener noreferrer">Pixel2Mesh</a> - Generating 3D Mesh Models from Single RGB Images.</li><li><a href="https://aliaksandrsiarohin.github.io/first-order-model-website/" target="_blank" rel="noopener noreferrer">First Order Motion Model for Image Animation</a> (<a href="https://github.com/AliaksandrSiarohin/first-order-model" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cleardusk/3DDFA" target="_blank" rel="noopener noreferrer">PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution</a></li><li><a href="https://github.com/alex04072000/ObstructionRemoval" target="_blank" rel="noopener noreferrer">Learning to See Through Obstructions</a></li><li><a href="https://github.com/yl-1993/learn-to-cluster" target="_blank" rel="noopener noreferrer">Learning to Cluster Faces on an Affinity Graph (LTC)</a></li><li><a href="https://github.com/alievk/avatarify" target="_blank" rel="noopener noreferrer">Avatarify</a> - Avatars for Zoom and Skype.</li><li><a href="https://github.com/Maclory/SPSR" target="_blank" rel="noopener noreferrer">SPSR</a> - PyTorch implementation of Structure-Preserving Super Resolution with Gradient Guidance.</li><li><a href="https://github.com/HolmesShuan/OISR-PyTorch" target="_blank" rel="noopener noreferrer">OISR-PyTorch</a> - PyTorch implementation of &quot;ODE-inspired Network Design for Single Image Super-Resolution.</li><li><a href="https://github.com/vt-vl-lab/3d-photo-inpainting" target="_blank" rel="noopener noreferrer">3D Photography using Context-aware Layered Depth Inpainting</a></li><li><a href="https://github.com/youngwanLEE/CenterMask" target="_blank" rel="noopener noreferrer">CenterMask : Real-Time Anchor-Free Instance Segmentation</a></li><li><a href="https://www.youtube.com/watch?v=lWwkbiufwNE" target="_blank" rel="noopener noreferrer">Interview with Dmytro Mushkin | Computer Vision Research | Kaggle, ML &amp; Education (2020)</a></li><li><a href="https://github.com/devendrachaplot/Neural-SLAM" target="_blank" rel="noopener noreferrer">Pytorch code for ICLR-20 Paper &quot;Learning to Explore using Active Neural SLAM&quot;</a></li><li><a href="https://github.com/kylemcdonald/FaceTracker" target="_blank" rel="noopener noreferrer">FaceTracker</a> - Real time deformable face tracking in C++ with OpenCV 3.</li><li><a href="https://github.com/ChaofWang/Awesome-Super-Resolution" target="_blank" rel="noopener noreferrer">Awesome Super Resolution</a></li><li><a href="https://github.com/podgorskiy/ALAE" target="_blank" rel="noopener noreferrer">Adversarial Latent Autoencoders</a></li><li><a href="https://github.com/mp3guy/ElasticFusion" target="_blank" rel="noopener noreferrer">ElasticFusion</a> - Real-time dense visual SLAM system capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera.</li><li><a href="https://github.com/tancik/StegaStamp" target="_blank" rel="noopener noreferrer">StegaStamp: Invisible Hyperlinks in Physical Photographs</a></li><li><a href="https://github.com/yemount/pose-animator/" target="_blank" rel="noopener noreferrer">Pose Animator</a> - Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. (<a href="https://news.ycombinator.com/item?id=23124786" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/facebookresearch/fvcore" target="_blank" rel="noopener noreferrer">fvcore</a> - Collection of common code that&#x27;s shared among different research projects in FAIR computer vision team.</li><li><a href="http://ai.stanford.edu/blog/selfsupervised-multimodal/" target="_blank" rel="noopener noreferrer">Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks (2020)</a></li><li><a href="https://github.com/cyrildiagne/screenpoint" target="_blank" rel="noopener noreferrer">ScreenPoint</a> - Project an image centroid to another image using OpenCV.</li><li><a href="https://github.com/NathanUA/U-2-Net" target="_blank" rel="noopener noreferrer">U^2-Net</a> - Code for our newly accepted paper in Pattern Recognition 2020: &quot;U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection&quot;.</li><li><a href="https://github.com/fepegar/torchio" target="_blank" rel="noopener noreferrer">TorchIO</a> - Tools for medical image processing in deep learning.</li><li><a href="https://github.com/anandpawara/Real_Time_Image_Animation" target="_blank" rel="noopener noreferrer">Real time Image Animation in OpenCV using first order model</a> (<a href="https://news.ycombinator.com/item?id=23312259" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/openmv/openmv" target="_blank" rel="noopener noreferrer">OpenMV (Open-Source Machine Vision)</a> - Aims at making machine vision more accessible to beginners by developing a user-friendly, open-source, low-cost machine vision platform.</li><li><a href="https://github.com/Sense-X/TSD" target="_blank" rel="noopener noreferrer">TSD</a> - 1st place models in Google OpenImage Detection Challenge 2019.</li><li><a href="https://github.com/ZJULearning/ttfnet" target="_blank" rel="noopener noreferrer">Training-Time-Friendly Network for Real-Time Object Detection</a></li><li><a href="https://github.com/google-research/big_transfer" target="_blank" rel="noopener noreferrer">Big Transfer (BiT): General Visual Representation Learning</a></li><li><a href="https://github.com/ilovepose/fast-human-pose-estimation.pytorch" target="_blank" rel="noopener noreferrer">Fast Human Pose Estimation CVPR2019</a></li><li><a href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch" target="_blank" rel="noopener noreferrer">Deep High-Resolution Representation Learning for Human Pose Estimation</a></li><li><a href="https://github.com/senguptaumd/Background-Matting" target="_blank" rel="noopener noreferrer">Background Matting: The World is Your Green Screen</a></li><li><a href="https://github.com/facebookresearch/detr" target="_blank" rel="noopener noreferrer">DE⫶TR: End-to-End Object Detection with Transformers</a></li><li><a href="https://github.com/shunsukesaito/PIFu" target="_blank" rel="noopener noreferrer">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a></li><li><a href="https://github.com/xingyizhou/CenterTrack" target="_blank" rel="noopener noreferrer">Tracking Objects as Points</a></li><li><a href="https://github.com/mkocabas/VIBE" target="_blank" rel="noopener noreferrer">VIBE</a> - Video Inference for Human Body Pose and Shape Estimation.</li><li><a href="https://github.com/idearibosome/srzoo" target="_blank" rel="noopener noreferrer">SRZoo</a> - Integrated repository for super-resolution using deep learning.</li><li><a href="https://github.com/Cartucho/mAP" target="_blank" rel="noopener noreferrer">mAP (mean Average Precision)</a> - Evaluates the performance of your neural net for object recognition.</li><li><a href="https://github.com/jiashunwang/Neural-Pose-Transfer" target="_blank" rel="noopener noreferrer">Neural Pose Transfer by Spatially Adaptive Instance Normalization (2020)</a></li><li><a href="https://github.com/weihaox/awesome-neural-rendering" target="_blank" rel="noopener noreferrer">Awesome Neural Rendering</a></li><li><a href="https://github.com/wvangansbeke/Unsupervised-Classification" target="_blank" rel="noopener noreferrer">Learning To Classify Images Without Labels</a></li><li><a href="https://github.com/mit-han-lab/dlg" target="_blank" rel="noopener noreferrer">Deep Leakage From Gradients (2019)</a></li><li><a href="https://www.3dflow.net/" target="_blank" rel="noopener noreferrer">3Dflow</a> - Offers customized computer vision software solutions.</li><li><a href="https://github.com/wkentaro/labelme" target="_blank" rel="noopener noreferrer">labelme</a> - Image Polygonal Annotation with Python.</li><li><a href="https://github.com/wkentaro/imgviz" target="_blank" rel="noopener noreferrer">imgviz</a> - Image Visualization Tools.</li><li><a href="https://github.com/wukaoliu/CVPR2020-HAttMatting" target="_blank" rel="noopener noreferrer">Attention-Guided Hierarchical Structure Aggregation for Image Matting</a></li><li><a href="https://blog.roboflow.ai/yolov5-is-here/" target="_blank" rel="noopener noreferrer">YOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS (2020)</a> (<a href="https://news.ycombinator.com/item?id=23478151" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/joe-siyuan-qiao/DetectoRS" target="_blank" rel="noopener noreferrer">DetectoRS</a> - Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution.</li><li><a href="https://github.com/thepowerfuldeez/facemesh.pytorch" target="_blank" rel="noopener noreferrer">PyTorch implementation of paper Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs</a></li><li><a href="https://github.com/kdexd/virtex" target="_blank" rel="noopener noreferrer">VirTex: Learning Visual Representations from Textual Annotations</a></li><li><a href="https://github.com/facebookresearch/pifuhd" target="_blank" rel="noopener noreferrer">High-Resolution 3D Human Digitization from A Single Image</a></li><li><a href="https://github.com/ifzhang/FairMOT" target="_blank" rel="noopener noreferrer">FairMOT</a> - Simple baseline for one-shot multi-object tracking.</li><li><a href="https://vsitzmann.github.io/siren/" target="_blank" rel="noopener noreferrer">Implicit Neural Representations with Periodic Activation Functions (2020)</a></li><li><a href="https://github.com/mseg-dataset/mseg-semantic" target="_blank" rel="noopener noreferrer">MSeg: A Composite Dataset for Multi-Domain Segmentation</a></li><li><a href="https://github.com/CuriousAI/mean-teacher" target="_blank" rel="noopener noreferrer">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</a></li><li><a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener noreferrer">MMDetection</a> - OpenMMLab Detection Toolbox and Benchmark.</li><li><a href="https://github.com/noahtren/Fourier-Feature-Networks-TensorFlow-2" target="_blank" rel="noopener noreferrer">Fourier Feature Networks in TensorFlow 2</a></li><li><a href="https://vision.ee.ethz.ch/" target="_blank" rel="noopener noreferrer">Computer Vision Lab | ETH Zurich</a></li><li><a href="https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5" target="_blank" rel="noopener noreferrer">PyTorch Computer Vision Library for Experts and Beginners (2020)</a></li><li><a href="https://github.com/balavenkatesh3322/CV-pretrained-model" target="_blank" rel="noopener noreferrer">Computer Vision Pretrained Models</a></li><li><a href="http://sandlab.cs.uchicago.edu/fawkes/" target="_blank" rel="noopener noreferrer">Fawkes: Image “Cloaking” for Personal Privacy</a> (<a href="https://news.ycombinator.com/item?id=23917337" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/Motion-Project/motion" target="_blank" rel="noopener noreferrer">Motion</a> - Software motion detector.</li><li><a href="https://nextjournal.com/nirmal-suthar/supervised-3d-mesh-reconstruction" target="_blank" rel="noopener noreferrer">Supervised 3D Mesh Reconstruction (2020)</a></li><li><a href="https://nerf-w.github.io/" target="_blank" rel="noopener noreferrer">NeRF in the Wild</a> - Neural Radiance Fields for Unconstrained Photo Collections.</li><li><a href="https://arxiv.org/abs/1912.03207" target="_blank" rel="noopener noreferrer">NASA: Neural Articulated Shape Approximation (2020)</a></li><li><a href="https://arxiv.org/abs/2008.06365v2" target="_blank" rel="noopener noreferrer">An Overview of Deep Learning Architectures in Few-Shot Learning Domain (2020)</a></li><li><a href="https://arxiv.org/abs/1803.11288" target="_blank" rel="noopener noreferrer">FutureMapping: The Computational Structure of Spatial AI Systems (2018)</a> (<a href="https://twitter.com/AjdDavison/status/1045617261925543937" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/" target="_blank" rel="noopener noreferrer">Optimal Peanut Butter and Banana Sandwiches (2020)</a> (<a href="https://twitter.com/eprosenthal/status/1298290961294950401" target="_blank" rel="noopener noreferrer">Twitter</a>)</li><li><a href="https://justinmeiners.github.io/gesture-recognition/" target="_blank" rel="noopener noreferrer">Gesture Recognition with Line Integrals</a> (<a href="https://github.com/justinmeiners/gesture-recognition" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://slazebni.cs.illinois.edu/spring20/" target="_blank" rel="noopener noreferrer">Computer Vision: Looking Back to Look Forward (2020)</a></li><li><a href="https://github.com/baowenbo/DAIN" target="_blank" rel="noopener noreferrer">DAIN (Depth-Aware Video Frame Interpolation)</a></li><li><a href="https://picsellia.com/" target="_blank" rel="noopener noreferrer">Picsellia</a> - Development platform dedicated to Computer Vision.</li><li><a href="https://github.com/vita-epfl/openpifpaf" target="_blank" rel="noopener noreferrer">Official implementation of &quot;PifPaf: Composite Fields for Human Pose Estimation&quot; in PyTorch</a></li><li><a href="https://link.springer.com/chapter/10.1007/3-540-46805-6_19" target="_blank" rel="noopener noreferrer">Object Recognition with Gradient-Based Learning (1999)</a></li><li><a href="https://github.com/NVlabs/imaginaire" target="_blank" rel="noopener noreferrer">Imaginaire</a> - NVIDIA PyTorch GAN library with distributed and mixed precision support. (<a href="http://imaginaire.cc/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/floe/deepbacksub" target="_blank" rel="noopener noreferrer">DeepBackSub</a> - Virtual Video Device for Background Replacement with Deep Semantic Segmentation.</li><li><a href="https://github.com/kuanhungchen/awesome-tiny-object-detection" target="_blank" rel="noopener noreferrer">Awesome Tiny Object Detection</a></li><li><a href="https://github.com/vt-vl-lab/FGVC" target="_blank" rel="noopener noreferrer">Flow-edge Guided Video Completion</a></li><li><a href="https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/" target="_blank" rel="noopener noreferrer">5 Things to look for in a Computer Vision startup job (2020)</a></li><li><a href="https://www.youtube.com/watch?v=Gl48KciWZp0" target="_blank" rel="noopener noreferrer">Transformers for Image Recognition at Scale (2020)</a> (<a href="https://news.ycombinator.com/item?id=24754538" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/MIC-DKFZ/nnUNet" target="_blank" rel="noopener noreferrer">nnU-Net</a> - Segmentation method that is designed to deal with the dataset diversity.</li><li><a href="https://github.com/MIC-DKFZ/batchgenerators" target="_blank" rel="noopener noreferrer">batchgenerators</a> - Framework for data augmentation for 2D and 3D image classification and segmentation.</li><li><a href="https://www.lookuq.com/create-your-own-app" target="_blank" rel="noopener noreferrer">Lookuq</a> - App to create object detection projects without coding. (<a href="https://news.ycombinator.com/item?id=24784680" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/deepinsight/insightface" target="_blank" rel="noopener noreferrer">InsightFace</a> - Face Analysis Project on MXNet. (<a href="http://insightface.ai/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/facebookresearch/swav" target="_blank" rel="noopener noreferrer">PyTorch implementation of SwAV (Swapping Assignments between Views)</a></li><li><a href="https://github.com/Alibaba-MIIL/ASL" target="_blank" rel="noopener noreferrer">Asymmetric Loss For Multi-Label Classification in PyTorch</a></li><li><a href="https://github.com/adobe/antialiased-cnns" target="_blank" rel="noopener noreferrer">Antialiased CNNs</a> - Making Convolutional Networks Shift-Invariant Again.</li><li><a href="https://github.com/richzhang/PerceptualSimilarity" target="_blank" rel="noopener noreferrer">Perceptual Similarity Metric and Dataset</a> - Unreasonable Effectiveness of Deep Features as a Perceptual Metric.</li><li><a href="https://github.com/deeppomf/DeepLearningAnimePapers" target="_blank" rel="noopener noreferrer">Deep Learning Anime Papers</a></li><li><a href="https://github.com/google-research/vision_transformer" target="_blank" rel="noopener noreferrer">Vision Transformer</a> - Models from the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.</li><li><a href="https://github.com/MIDIBlocks/handsfree" target="_blank" rel="noopener noreferrer">Handsfree.js</a> - Wrapper library around computer vision models for working with face pointers, assistive tech, and creative expression. (<a href="https://handsfreejs.glitch.me/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/amirgholami/ZeroQ" target="_blank" rel="noopener noreferrer">ZeroQ: A Novel Zero Shot Quantization Framework</a></li><li><a href="https://github.com/amirgholami/SqueezeNext" target="_blank" rel="noopener noreferrer">SqueezeNext</a> - Contains the Caffe implementation of SqueezeNext.</li><li><a href="https://github.com/amirgholami/anode" target="_blank" rel="noopener noreferrer">ANODE: Adjoint Based Neural ODEs</a></li><li><a href="https://github.com/AdamSpannbauer/python_video_stab" target="_blank" rel="noopener noreferrer">Python Video Stabilization using OpenCV</a></li><li><a href="https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers" target="_blank" rel="noopener noreferrer">Recent Advances in Vision and Language PreTrained Models (VL-PTMs)</a></li><li><a href="https://github.com/kuangliu/torchcv" target="_blank" rel="noopener noreferrer">TorchCV</a> - PyTorch vision library mimics ChainerCV.</li><li><a href="https://github.com/jeonsworld/ViT-pytorch" target="_blank" rel="noopener noreferrer">Vision Transformer in PyTorch</a></li><li><a href="https://github.com/perone/medicaltorch" target="_blank" rel="noopener noreferrer">MedicalTorch</a> - Medical imaging framework for PyTorch. (<a href="https://medicaltorch.readthedocs.io/en/stable/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/elcorto/imagecluster" target="_blank" rel="noopener noreferrer">imagecluster</a> - Cluster images based on image content using a pre-trained deep neural network, optional time distance scaling and hierarchical clustering.</li><li><a href="https://github.com/alankbi/detecto" target="_blank" rel="noopener noreferrer">Detecto</a> - Build fully-functioning computer vision models with PyTorch. (<a href="https://detecto.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/thoughtworksarts/EmoPy" target="_blank" rel="noopener noreferrer">EmoPy</a> - Deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER).</li><li><a href="https://github.com/NVlabs/NVAE" target="_blank" rel="noopener noreferrer">PyTorch Implementation of &quot;NVAE: A Deep Hierarchical Variational Autoencoder&quot;</a></li><li><a href="https://github.com/weijun88/LDF" target="_blank" rel="noopener noreferrer">Label Decoupling Framework for Salient Object Detection</a></li><li><a href="https://github.com/Project-MONAI/MONAI" target="_blank" rel="noopener noreferrer">MONAI</a> - PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. (<a href="https://monai.io/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/implus/GFocal" target="_blank" rel="noopener noreferrer">Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection</a></li><li><a href="https://blog.paperspace.com/faster-r-cnn-explained-object-detection/" target="_blank" rel="noopener noreferrer">Faster R-CNN Explained for Object Detection Tasks (2020)</a></li><li><a href="https://www.jeremymorgan.com/tutorials/raspberry-pi/how-to-install-opencv-raspberry-pi/" target="_blank" rel="noopener noreferrer">How to Install OpenCV on a Raspberry Pi (2020)</a></li><li><a href="https://github.com/alexanderkroner/saliency" target="_blank" rel="noopener noreferrer">Contextual Encoder-Decoder Network for Visual Saliency Prediction</a></li><li><a href="https://www.pyimagesearch.com/" target="_blank" rel="noopener noreferrer">PyImageSearch</a> - Master Computer Vision, Deep Learning, and OpenCV.</li><li><a href="https://github.com/hendrycks/natural-adv-examples" target="_blank" rel="noopener noreferrer">Natural Adversarial Examples</a> - Harder ImageNet Test Set.</li><li><a href="https://medium.com/@venkateshpnk22/how-to-upload-50-opencv-frames-into-cloud-storage-within-1-second-653ee73d7711" target="_blank" rel="noopener noreferrer">How to upload 50 OpenCV frames into cloud storage within 1 second (2020)</a></li><li><a href="http://gvv.mpi-inf.mpg.de/projects/EgoChat/" target="_blank" rel="noopener noreferrer">Egocentric Videoconferencing (2020)</a> - Method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. (<a href="https://www.youtube.com/watch?v=atzPvW95ahQ" target="_blank" rel="noopener noreferrer">Video overview</a>)</li><li><a href="https://github.com/gradslam/gradslam" target="_blank" rel="noopener noreferrer">gradslam</a> - Open source differentiable dense SLAM library for PyTorch.</li><li><a href="https://github.com/saic-mdal/HiDT" target="_blank" rel="noopener noreferrer">High-Resolution Daytime Translation Without Domain Labels</a></li><li><a href="https://github.com/s9xie/hed" target="_blank" rel="noopener noreferrer">Holistically-Nested Edge Detection</a></li><li><a href="https://github.com/facebookresearch/pycls" target="_blank" rel="noopener noreferrer">pycls</a> - Image classification codebase, written in PyTorch.</li><li><a href="https://github.com/Justin-Tan/high-fidelity-generative-compression" target="_blank" rel="noopener noreferrer">PyTorch implementation of High-Fidelity Generative Image Compression + Routines for neural image compression</a></li><li><a href="https://github.com/princeton-vl/selfstudy" target="_blank" rel="noopener noreferrer">How Useful is Self-Supervised Pretraining for Visual Tasks?</a></li><li><a href="https://github.com/adamian98/pulse" target="_blank" rel="noopener noreferrer">PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models</a></li><li><a href="https://github.com/facebookresearch/InterHand2.6M" target="_blank" rel="noopener noreferrer">InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image</a></li><li><a href="https://github.com/adipandas/multi-object-tracker" target="_blank" rel="noopener noreferrer">Multi-object trackers in Python</a> - Easy to use implementation of various multi-object tracking algorithms.</li><li><a href="http://svl.stanford.edu/" target="_blank" rel="noopener noreferrer">Stanford Vision and Learning Lab</a> (<a href="https://github.com/StanfordVL" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="https://towardsdatascience.com/learning-computer-vision-41398ad9941f" target="_blank" rel="noopener noreferrer">Learning computer vision. Overview of methods and software (2018)</a></li><li><a href="https://medium.com/@rom1504/image-embeddings-ed1b194d113e" target="_blank" rel="noopener noreferrer">Image embeddings. Image similarity and building (2020)</a> (<a href="https://github.com/rom1504/image_embeddings" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/" target="_blank" rel="noopener noreferrer">All You Need to Know About Object Detection Systems (2020)</a></li><li><a href="https://github.com/lightly-ai/lightly" target="_blank" rel="noopener noreferrer">Lightly</a> - Computer vision framework for self-supervised learning.</li><li><a href="https://arxiv.org/abs/2006.13566" target="_blank" rel="noopener noreferrer">DISK: Learning local features with policy gradient (2020)</a> (<a href="https://github.com/cvlab-epfl/disk" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/jasmcaus/caer" target="_blank" rel="noopener noreferrer">Caer</a> - Lightweight Computer Vision library for high-performance AI research. (<a href="https://towardsdatascience.com/introducing-caer-modern-computer-vision-on-the-fly-1619d7155c15" target="_blank" rel="noopener noreferrer">Intro</a>)</li><li><a href="https://github.com/weihaox/awesome-image-translation" target="_blank" rel="noopener noreferrer">Awesome Image to Image Translation Papers</a></li><li><a href="https://github.com/toandaominh1997/EfficientDet.Pytorch" target="_blank" rel="noopener noreferrer">EfficientDet: Scalable and Efficient Object Detection, in PyTorch</a></li><li><a href="https://github.com/milesial/Pytorch-UNet" target="_blank" rel="noopener noreferrer">UNet: semantic segmentation with PyTorch</a></li><li><a href="https://arxiv.org/abs/2011.10566" target="_blank" rel="noopener noreferrer">Exploring Simple Siamese Representation Learning (2020)</a> (<a href="https://github.com/PatrickHua/SimSiam" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/facebookresearch/simsiam" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/aimagelab/show-control-and-tell" target="_blank" rel="noopener noreferrer">Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions</a></li><li><a href="https://nerfies.github.io/" target="_blank" rel="noopener noreferrer">Nerfies: Deformable Neural Radiance Fields</a> (<a href="https://github.com/google/nerfies" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1812.01289" target="_blank" rel="noopener noreferrer">Timeception for Complex Action Recognition (2019)</a> (<a href="https://github.com/noureldien/timeception" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://programmingcomputervision.com/" target="_blank" rel="noopener noreferrer">Programming Computer Vision with Python (2014)</a> (<a href="https://github.com/jesolem/PCV" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/nico/cvbook" target="_blank" rel="noopener noreferrer">Notes</a>)</li><li><a href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank" rel="noopener noreferrer">Fast and Accurate One-Stage Space-Time Video Super-Resolution (2020)</a></li><li><a href="https://alexyu.net/pixelnerf/" target="_blank" rel="noopener noreferrer">pixelNeRF: Neural Radiance Fields from One or Few Images (2020)</a> (<a href="https://github.com/sxyu/pixel-nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Media-Smart/vedadet" target="_blank" rel="noopener noreferrer">vedadet</a> - Single stage object detector toolbox based on PyTorch.</li><li><a href="https://github.com/PeizeSun/OneNet" target="_blank" rel="noopener noreferrer">OneNet: End-to-End One-Stage Object Detection by Classification Cost</a></li><li><a href="https://github.com/facebookresearch/consistent_depth" target="_blank" rel="noopener noreferrer">Consistent Video Depth Estimation</a> - Estimate dense, flicker-free, geometrically consistent depth from monocular video, for example hand-held cell phone video.</li><li><a href="https://github.com/vsitzmann/siren" target="_blank" rel="noopener noreferrer">Implicit Neural Representations with Periodic Activation Functions</a></li><li><a href="http://www.computationalimaging.org/" target="_blank" rel="noopener noreferrer">Computational Imaging Stanford Lab</a></li><li><a href="https://github.com/ZHKKKe/MODNet" target="_blank" rel="noopener noreferrer">Trimap-Free Solution for Portrait Matting in Real Time</a></li><li><a href="https://github.com/Fyusion/LLFF" target="_blank" rel="noopener noreferrer">Local Light Field Fusion</a></li><li><a href="https://github.com/gjy3035/Awesome-Crowd-Counting" target="_blank" rel="noopener noreferrer">Awesome Crowd Counting</a></li><li><a href="https://github.com/facebookresearch/NSVF" target="_blank" rel="noopener noreferrer">Neural Sparse Voxel Fields (NSVF)</a></li><li><a href="https://arxiv.org/abs/2011.15126" target="_blank" rel="noopener noreferrer">One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (2020)</a> (<a href="https://twitter.com/goodfellow_ian/status/1333845997697388544" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/SharpAI/DeepCamera" target="_blank" rel="noopener noreferrer">SharpAI DeepCamera</a> - Source stack for machine learning engineering with private deployment and AutoML for edge computing. (<a href="https://news.ycombinator.com/item?id=25368272" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/krishnabits001/domain_specific_cl" target="_blank" rel="noopener noreferrer">Contrastive learning of global and local features for medical image segmentation with limited annotations</a></li><li><a href="https://arxiv.org/abs/2012.07810" target="_blank" rel="noopener noreferrer">Real-Time High-Resolution Background Matting (2020)</a> (<a href="https://github.com/PeterL1n/BackgroundMattingV2" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/KaiyangZhou/deep-person-reid" target="_blank" rel="noopener noreferrer">Torchreid</a> - Deep learning person re-identification in PyTorch.</li><li><a href="https://github.com/mangye16/Unsupervised_Embedding_Learning" target="_blank" rel="noopener noreferrer">Unsupervised Embedding Learning via Invariant and Spreading Instance Feature</a></li><li><a href="https://github.com/vitoralbiero/img2pose" target="_blank" rel="noopener noreferrer">img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation</a></li><li><a href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection" target="_blank" rel="noopener noreferrer">SSD: Single Shot MultiBox Detector | a PyTorch Tutorial to Object Detection</a></li><li><a href="https://arxiv.org/pdf/2012.09688.pdf" target="_blank" rel="noopener noreferrer">PCT: Point Cloud Transformer (2020)</a> (<a href="https://github.com/MenghaoGuo/PCT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.09161" target="_blank" rel="noopener noreferrer">Learning Continuous Image Representation with Local Implicit Image Function (2020)</a> (<a href="https://github.com/yinboc/liif" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/openvinotoolkit/cvat" target="_blank" rel="noopener noreferrer">Computer Vision Annotation Tool (CVAT)</a></li><li><a href="https://github.com/facebookresearch/deit" target="_blank" rel="noopener noreferrer">DeiT: Data-efficient Image Transformers</a></li><li><a href="https://github.com/vsitzmann/awesome-implicit-representations" target="_blank" rel="noopener noreferrer">Awesome Implicit Neural Representations</a></li><li><a href="https://github.com/OlafenwaMoses/ImageAI" target="_blank" rel="noopener noreferrer">ImageAI</a> - Python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities. (<a href="http://imageai.org/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://raivn.cs.washington.edu/" target="_blank" rel="noopener noreferrer">RAIVN Lab</a> - Reasoning, AI and VisioN (RAIVN) Lab. (<a href="https://github.com/RAIVNLab" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="https://github.com/tryolabs/norfair" target="_blank" rel="noopener noreferrer">Norfair</a> - Customizable lightweight Python library for real-time 2D object tracking.</li><li><a href="https://github.com/sunshineatnoon/PytorchWCT" target="_blank" rel="noopener noreferrer">Universal Style Transfer in PyTorch</a></li><li><a href="https://github.com/NVIDIA/Dataset_Synthesizer" target="_blank" rel="noopener noreferrer">NVIDIA Deep learning Dataset Synthesizer (NDDS)</a></li><li><a href="https://paulbridger.com/posts/tensorrt-object-detection-quantized/" target="_blank" rel="noopener noreferrer">Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization (2020)</a></li><li><a href="https://github.com/mtli/HTML4Vision" target="_blank" rel="noopener noreferrer">HTML4Vision</a> - Simple HTML visualization tool for computer vision research.</li><li><a href="https://github.com/taldatech/soft-intro-vae-pytorch" target="_blank" rel="noopener noreferrer">Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders</a></li><li><a href="https://github.com/CompVis/taming-transformers" target="_blank" rel="noopener noreferrer">Taming Transformers for High-Resolution Image Synthesis</a></li><li><a href="https://github.com/Sense-X/X-Temporal" target="_blank" rel="noopener noreferrer">X-Temporal</a> - Easily implement SOTA video understanding methods with PyTorch on multiple machines and GPUs.</li><li><a href="https://github.com/RangiLyu/nanodet" target="_blank" rel="noopener noreferrer">NanoDet</a> - Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.</li><li><a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">PyTorch Image Models</a></li><li><a href="https://github.com/sangminwoo/awesome-vision-and-language" target="_blank" rel="noopener noreferrer">Awesome Vision and Language</a> - Curated list of awesome vision and language resources.</li><li><a href="https://arxiv.org/abs/1810.12890v1" target="_blank" rel="noopener noreferrer">DropBlock: A regularization method for convolutional networks (2018)</a> (<a href="https://github.com/miguelvr/dropblock" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/FrancescoSaverioZuppichini/glasses" target="_blank" rel="noopener noreferrer">Glasses</a> - Compact, concise and customizable deep learning computer vision library. (<a href="https://francescosaveriozuppichini.github.io/glasses-webapp/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/YuvalBahat/Explorable-Super-Resolution" target="_blank" rel="noopener noreferrer">Explorable Super Resolution (2019)</a></li><li><a href="https://github.com/Breakthrough/PySceneDetect" target="_blank" rel="noopener noreferrer">PySceneDetect</a> - Python and OpenCV-based scene cut/transition detection program &amp; library.</li><li><a href="https://phaseai.com/resources/computer-vision-best-practices" target="_blank" rel="noopener noreferrer">Best Practices for Building Computer Vision Models (2021)</a></li><li><a href="https://github.com/dbolya/tide" target="_blank" rel="noopener noreferrer">TIDE</a> - General Toolbox for Identifying Object Detection Errors.</li><li><a href="https://arxiv.org/abs/2011.12450" target="_blank" rel="noopener noreferrer">Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (2020)</a> (<a href="https://github.com/PeizeSun/SparseR-CNN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/haltakov/natural-language-image-search" target="_blank" rel="noopener noreferrer">Unsplash Image Search</a> - Search photos on Unsplash using natural language.</li><li><a href="https://github.com/MIT-SPARK/Kimera-Semantics" target="_blank" rel="noopener noreferrer">Kimera Semantics</a> - Real-Time 3D Semantic Reconstruction from 2D data.</li><li><a href="https://github.com/ethz-asl/voxblox-plusplus" target="_blank" rel="noopener noreferrer">Voxblox++</a> - Volumetric object-level semantic mapping framework.</li><li><a href="https://nv-tlabs.github.io/nglod/" target="_blank" rel="noopener noreferrer">Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Surfaces</a> (<a href="https://github.com/nv-tlabs/nglod" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/" target="_blank" rel="noopener noreferrer">Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video (2020)</a> (<a href="https://github.com/facebookresearch/nonrigid_nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html" target="_blank" rel="noopener noreferrer">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation (2019)</a> (<a href="https://github.com/facebookresearch/DeepSDF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/yenchenlin/awesome-NeRF" target="_blank" rel="noopener noreferrer">Awesome Neural Radiance Fields</a></li><li><a href="https://github.com/JialeCao001/D2Det" target="_blank" rel="noopener noreferrer">D2Det: Towards High Quality Object Detection and Instance Segmentation (2020)</a></li><li><a href="https://arxiv.org/abs/2102.04803" target="_blank" rel="noopener noreferrer">DetCo: Unsupervised Contrastive Learning for Object Detection (2021)</a> (<a href="https://github.com/xieenze/DetCo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/kuzand/Computer-Vision-Video-Lectures" target="_blank" rel="noopener noreferrer">Computer Vision Video Lectures</a> - Curated list of free, high-quality, university-level courses with video lectures related to the field of Computer Vision.</li><li><a href="https://cord.tech/" target="_blank" rel="noopener noreferrer">Cord</a> - Training data toolbox for computer vision. (<a href="https://news.ycombinator.com/item?id=26104104" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/orpatashnik/StyleCLIP" target="_blank" rel="noopener noreferrer">Text-Guided Editing of Images (Using CLIP and StyleGAN)</a></li><li><a href="https://github.com/pytorch/vision" target="_blank" rel="noopener noreferrer">torchvision</a> - Datasets, Transforms and Models specific to Computer Vision. (<a href="https://paperswithcode.com/lib/torchvision" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://arxiv.org/abs/2102.02371" target="_blank" rel="noopener noreferrer">MeInGame: Create a Game Character Face from a Single Portrait (2021)</a> (<a href="https://github.com/FuxiCV/MeInGame" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/kjw0612/awesome-deep-vision" target="_blank" rel="noopener noreferrer">Awesome Deep Vision</a></li><li><a href="https://github.com/dvschultz/dataset-tools" target="_blank" rel="noopener noreferrer">dataset-tools</a> - Tools for quickly normalizing image datasets.</li><li><a href="https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/" target="_blank" rel="noopener noreferrer">Using Streamlit to visualize object detection output (2021)</a></li><li><a href="https://github.com/facebookresearch/mobile-vision" target="_blank" rel="noopener noreferrer">Mobile Computer Vision @ Facebook</a></li><li><a href="https://medium.com/hasty-ai/opening-the-black-box-of-vision-ai-algorithms-466fc3d4bf78" target="_blank" rel="noopener noreferrer">Opening the black box of vision AI algorithms (2021)</a></li><li><a href="https://github.com/exadel-inc/CompreFace" target="_blank" rel="noopener noreferrer">CompreFace</a> - Free face recognition solution that can be easily integrated into any IT system without prior machine learning skills.</li><li><a href="https://ibrnet.github.io/" target="_blank" rel="noopener noreferrer">IBRNet: Learning Multi-View Image-Based Rendering (2021)</a> (<a href="https://github.com/googleinterns/IBRNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1812.03506" target="_blank" rel="noopener noreferrer">From Coarse to Fine: Robust Hierarchical Localization at Large Scale (2019)</a> (<a href="https://github.com/ethz-asl/hfnet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://roboalgorithms.com/posts/camera-response-function/" target="_blank" rel="noopener noreferrer">Camera Response Function (2021)</a></li><li><a href="https://arxiv.org/abs/2008.03713" target="_blank" rel="noopener noreferrer">I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image (2020)</a> (<a href="https://github.com/mks0601/I2L-MeshNet_RELEASE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1711.09485" target="_blank" rel="noopener noreferrer">SkipNet: Learning Dynamic Routing in Convolutional Networks (2018)</a> (<a href="https://github.com/ucbdrive/skipnet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://mrcal.secretsauce.net/" target="_blank" rel="noopener noreferrer">Mrcal</a> - Camera Calibrations and More. (<a href="https://news.ycombinator.com/item?id=26300118" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/1806.01260" target="_blank" rel="noopener noreferrer">Digging Into Self-Supervised Monocular Depth Estimation (2019)</a> (<a href="https://github.com/nianticlabs/monodepth2" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/pxl-th/Monodepth2.jl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/facebookresearch/vissl" target="_blank" rel="noopener noreferrer">VISSL</a> - FAIR&#x27;s library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. (<a href="https://vissl.ai/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://www.zumolabs.ai/" target="_blank" rel="noopener noreferrer">Zumo Labs</a> - Generate custom synthetic data sets that result in more robust and reliable computer vision models. (<a href="https://github.com/ZumoLabs" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="https://arxiv.org/abs/2008.07043" target="_blank" rel="noopener noreferrer">Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors (2020)</a> (<a href="https://github.com/yijingru/BBAVectors-Oriented-Object-Detection" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.03206" target="_blank" rel="noopener noreferrer">Perceiver: General Perception with Iterative Attention (2021)</a> (<a href="https://github.com/lucidrains/perceiver-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision" target="_blank" rel="noopener noreferrer">SEER: The start of a more powerful, flexible, and accessible era for computer vision (2021)</a></li><li><a href="https://gafniguy.github.io/4D-Facial-Avatars/" target="_blank" rel="noopener noreferrer">NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction (2021)</a></li><li><a href="https://neural-3d-video.github.io/" target="_blank" rel="noopener noreferrer">Neural 3D Video Synthesis</a></li><li><a href="https://arxiv.org/abs/2103.06255" target="_blank" rel="noopener noreferrer">Involution: Inverting the Inherence of Convolution for Visual Recognition (2021)</a> (<a href="https://github.com/d-li14/involution" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Wangt-CN/Awesome-Causality-in-CV" target="_blank" rel="noopener noreferrer">Awesome Causality in Computer Vision</a></li><li><a href="https://arxiv.org/abs/2103.13413" target="_blank" rel="noopener noreferrer">Vision Transformers for Dense Prediction (2021)</a> (<a href="https://github.com/intel-isl/DPT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.00680" target="_blank" rel="noopener noreferrer">LoFTR: Detector-Free Local Feature Matching with Transformers (2021)</a> (<a href="https://github.com/zju3dv/LoFTR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/liuliu/ccv" target="_blank" rel="noopener noreferrer">ccv</a> - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.</li><li><a href="https://arxiv.org/abs/2011.13084" target="_blank" rel="noopener noreferrer">Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (2020)</a> (<a href="https://github.com/zhengqili/Neural-Scene-Flow-Fields" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://xbpeng.github.io/projects/AMP/" target="_blank" rel="noopener noreferrer">AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control (2021)</a> (<a href="https://twitter.com/xbpeng4/status/1379465757688352769" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://healeycodes.com/computer-vision-and-embroidery/" target="_blank" rel="noopener noreferrer">Computer Vision and Embroidery (2021)</a> (<a href="https://github.com/healeycodes/embroidery-vision" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://jonbarron.info/mipnerf/" target="_blank" rel="noopener noreferrer">mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields (2021)</a></li><li><a href="https://twitter.com/svpino/status/1379666495811117062" target="_blank" rel="noopener noreferrer">Python libraries I use every day for computer vision work (2021)</a></li><li><a href="https://github.com/Soldelli/Awesome-Temporal-Language-Grounding-in-Videos" target="_blank" rel="noopener noreferrer">Awesome Temporal Sentence Grounding in Videos</a></li><li><a href="https://authentic.sice.indiana.edu/publications/Su_Crandall-AffectiveGrowthCV-CVPR21.pdf" target="_blank" rel="noopener noreferrer">The Affective Growth of Computer Vision</a></li><li><a href="https://arxiv.org/abs/2008.05711" target="_blank" rel="noopener noreferrer">Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D (2020)</a> (<a href="https://github.com/nv-tlabs/lift-splat-shoot" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2011.14503" target="_blank" rel="noopener noreferrer">End-to-End Video Instance Segmentation with Transformers (2021)</a> (<a href="https://github.com/Epiphqny/VisTR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/obss/sahi" target="_blank" rel="noopener noreferrer">SAHI: Slicing Aided Hyper Inference</a></li><li><a href="https://www.gamasutra.com/blogs/RobertPepperell/20200527/363615/FOVO_A_new_3D_rendering_technique_based_on_human_vision.php" target="_blank" rel="noopener noreferrer">FOVO: A new 3D rendering technique based on human vision (2020)</a> (<a href="https://news.ycombinator.com/item?id=26795290" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2102.05095" target="_blank" rel="noopener noreferrer">Is Space-Time Attention All You Need for Video Understanding? (2021)</a> (<a href="https://github.com/facebookresearch/TimeSformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/dk-liang/Awesome-Visual-Transformer" target="_blank" rel="noopener noreferrer">Awesome Visual-Transformer</a> - Transformer with Computer-Vision (CV) papers.</li><li><a href="https://github.com/facebookresearch/pytorchvideo" target="_blank" rel="noopener noreferrer">PyTorchVideo</a> - Deep learning library for video understanding research. (<a href="https://pytorchvideo.org/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://charigyang.github.io/motiongroup/" target="_blank" rel="noopener noreferrer">Self-supervised Video Object Segmentation by Motion Grouping (2021)</a> (<a href="https://news.ycombinator.com/item?id=26842018" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://github.com/charigyang/motiongrouping" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/torchvideo/torchvideo" target="_blank" rel="noopener noreferrer">torchvideo</a> - Datasets, transforms and samplers for video in PyTorch.</li><li><a href="https://arxiv.org/abs/1701.03077" target="_blank" rel="noopener noreferrer">A General and Adaptive Robust Loss Function (2019)</a> (<a href="https://github.com/jonbarron/robust_loss_pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://geyixiao.com/projects/sfrs" target="_blank" rel="noopener noreferrer">Self-supervising Fine-grained Region Similarities for Large-scale Image Localization (2020)</a> (<a href="https://github.com/yxgeee/OpenIBL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://ai.googleblog.com/2021/04/max-deeplab-dual-path-transformers-for.html" target="_blank" rel="noopener noreferrer">MaX-DeepLab: Dual-Path Transformers for End-to-End Panoptic Segmentation (2021)</a></li><li><a href="https://vizycam.com/" target="_blank" rel="noopener noreferrer">Vizy</a> - AI Camera.</li><li><a href="https://casual-effects.com/research/McGuire2021PixelArt/McGuire2021PixelArt.pdf" target="_blank" rel="noopener noreferrer">MMPX Style-Preserving Pixel Art Magnification (2021)</a> (<a href="https://news.ycombinator.com/item?id=26934973" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://hkchengrex.github.io/MiVOS/" target="_blank" rel="noopener noreferrer">Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion</a> (<a href="https://github.com/hkchengrex/Scribble-to-Mask" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1712.07629" target="_blank" rel="noopener noreferrer">SuperPoint: Self-Supervised Interest Point Detection and Description (2018)</a> (<a href="https://github.com/eric-yyjau/pytorch-superpoint" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2102.02808" target="_blank" rel="noopener noreferrer">Multi-Stage Progressive Image Restoration (2021)</a> (<a href="https://github.com/swz30/MPRNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/colmap/colmap" target="_blank" rel="noopener noreferrer">COLMAP</a> - General-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. (<a href="https://colmap.github.io/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/tzutalin/awesome-visual-slam" target="_blank" rel="noopener noreferrer">Awesome Vision-based SLAM / Visual Odometry</a></li><li><a href="https://arxiv.org/abs/2103.03230" target="_blank" rel="noopener noreferrer">Barlow Twins: Self-Supervised Learning via Redundancy Reduction (2021)</a> (<a href="https://github.com/facebookresearch/barlowtwins" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cpc/hipcl" target="_blank" rel="noopener noreferrer">HIPCL</a> - OpenCL/SPIR-V implementation of HIP.</li><li><a href="https://github.com/open-mmlab/mmcv" target="_blank" rel="noopener noreferrer">MMCV</a> - Foundational library for computer vision research and supports many research projects. (<a href="https://mmcv.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://arxiv.org/abs/2104.12763" target="_blank" rel="noopener noreferrer">MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding (2021)</a> (<a href="https://github.com/ashkamath/mdetr" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.13963" target="_blank" rel="noopener noreferrer">Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples (2021)</a> (<a href="https://github.com/facebookresearch/suncet" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/facebookresearch/msn" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.14294" target="_blank" rel="noopener noreferrer">Emerging Properties in Self-Supervised Vision Transformers (2021)</a> (<a href="https://github.com/facebookresearch/dino" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://twitter.com/i/lists/1351120526220152839" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://twitter.com/schrep/status/1388189398496202752" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://arxiv.org/abs/2104.07652" target="_blank" rel="noopener noreferrer">Geometry-Free View Synthesis: Transformers and no 3D Priors (2021)</a> (<a href="https://github.com/CompVis/geometry-free-view-synthesis" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://minimaxir.com/2021/04/styleclip/" target="_blank" rel="noopener noreferrer">Easily Transform Portraits of People into AI Aberrations Using StyleCLIP (2021)</a></li><li><a href="https://arxiv.org/abs/2102.09105" target="_blank" rel="noopener noreferrer">DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates (2021)</a> (<a href="https://github.com/Colin97/DeepMetaHandles" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/onepanelio/onepanel" target="_blank" rel="noopener noreferrer">Onepanel</a> - Open and extensible integrated development environment (IDE) for computer vision. (<a href="https://docs.onepanel.ai/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://arxiv.org/abs/2104.12229" target="_blank" rel="noopener noreferrer">Vector Neurons: A General Framework for SO(3)-Equivariant Networks (2021)</a> (<a href="https://github.com/FlyingGiraffe/vnn" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2105.00637" target="_blank" rel="noopener noreferrer">ISTR: End-to-End Instance Segmentation with Transformers (2021)</a> (<a href="https://github.com/hujiecpp/ISTR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2105.01601" target="_blank" rel="noopener noreferrer">MLP-Mixer: An all-MLP Architecture for Vision (2021)</a> (<a href="https://github.com/lucidrains/mlp-mixer-pytorch" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/rishikksh20/MLP-Mixer-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/The-AI-Summer/self-attention-cv" target="_blank" rel="noopener noreferrer">Self-attention building blocks for computer vision applications in PyTorch</a></li><li><a href="https://github.com/facebookresearch/LeViT" target="_blank" rel="noopener noreferrer">LeViT: a Vision Transformer in ConvNet&#x27;s Clothing for Faster Inference</a></li><li><a href="https://arxiv.org/abs/2104.14631" target="_blank" rel="noopener noreferrer">Text2Video: Text-driven Talking-head Video Synthesis with Phonetic Dictionary (2021)</a> (<a href="https://sites.google.com/view/sibozhang/text2video" target="_blank" rel="noopener noreferrer">Web</a>) (<a href="https://github.com/sibozhang/Text2Video" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.unite.ai/neural-rendering-low-resolution-input-intel/" target="_blank" rel="noopener noreferrer">Neural Rendering: How Low Can You Go in Terms of Input? (2021)</a></li><li><a href="https://intel-isl.github.io/PhotorealismEnhancement/" target="_blank" rel="noopener noreferrer">Enhancing Photorealism Enhancement (2021)</a> (<a href="https://arxiv.org/abs/2105.04619" target="_blank" rel="noopener noreferrer">Paper</a>) (<a href="https://github.com/intel-isl/PhotorealismEnhancement" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://www.geometrylearning.com/DeepFaceEditing/" target="_blank" rel="noopener noreferrer">DeepFaceEditing: Deep Face Generation and Editing with Disentangled Geometry and Appearance Control (2021)</a> (<a href="https://github.com/IGLICT/DeepFaceEditing-Jittor" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://omnimatte.github.io/" target="_blank" rel="noopener noreferrer">Omnimatte: Associating Objects and Their Effects in Video (2021)</a></li><li><a href="https://arxiv.org/abs/2105.07576" target="_blank" rel="noopener noreferrer">Rethinking &quot;Batch&quot; in BatchNorm (2021)</a></li><li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics" target="_blank" rel="noopener noreferrer">Most popular metrics used to evaluate object detection algorithms</a></li><li><a href="https://arxiv.org/abs/2002.06353" target="_blank" rel="noopener noreferrer">UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation (2020)</a> (<a href="https://github.com/microsoft/UniVL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/unrealcv/synthetic-computer-vision" target="_blank" rel="noopener noreferrer">Synthetic for Computer Vision</a> - List of synthetic dataset and tools for computer vision.</li><li><a href="https://github.com/Cartucho/vision_blender" target="_blank" rel="noopener noreferrer">vision_blender</a> - Blender addon for generating synthetic ground truth data for Computer Vision applications.</li><li><a href="https://github.com/sicara/easy-few-shot-learning" target="_blank" rel="noopener noreferrer">Easy Few-Shot Learning</a> - Ready-to-use code and tutorial notebooks to boost your way into few-shot image classification.</li><li><a href="https://github.com/xinntao/BasicSR" target="_blank" rel="noopener noreferrer">BasicSR (Basic Super Restoration)</a> - Open source image and video restoration toolbox based on PyTorch, such as super-resolution, denoise, deblurring, JPEG artifacts removal, etc.</li><li><a href="https://arxiv.org/abs/2105.10497" target="_blank" rel="noopener noreferrer">Intriguing Properties of Vision Transformers (2021)</a> (<a href="https://www.reddit.com/r/MachineLearning/comments/njm2ru/r_intriguing_properties_of_vision_transformers/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://www.sbxrobotics.com/tutorial" target="_blank" rel="noopener noreferrer">DIY Amazon Go – computer vision tutorial for cashierless checkout</a></li><li><a href="https://matsui528.github.io/cvpr2020_tutorial_retrieval/" target="_blank" rel="noopener noreferrer">Image Retrieval in the Wild (2020)</a></li><li><a href="https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV" target="_blank" rel="noopener noreferrer">Awesome Transformer in CV papers</a></li><li><a href="https://www.tangramvision.com/blog/calibration-from-scratch-using-rust-part-1-of-3" target="_blank" rel="noopener noreferrer">Sensor Calibration from Scratch with Rust (2021)</a></li><li><a href="https://www.tangramvision.com/" target="_blank" rel="noopener noreferrer">Tangram Vision</a> - Integrate, Calibrate Perception Sensors For Robots, Drones &amp; Automation. (<a href="https://www.tangramvision.com/blog" target="_blank" rel="noopener noreferrer">Blog</a>)</li><li><a href="https://github.com/rust-cv/cv" target="_blank" rel="noopener noreferrer">Rust CV</a> - Project to implement computer vision algorithms, abstractions, and systems in Rust.</li><li><a href="http://gvv.mpi-inf.mpg.de/projects/NeuralActor/" target="_blank" rel="noopener noreferrer">Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control (2021)</a> (<a href="https://news.ycombinator.com/item?id=27393047" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2012.02107" target="_blank" rel="noopener noreferrer">Robust Instance Segmentation through Reasoning about Multi-Object Occlusion (2021)</a> (<a href="https://github.com/XD7479/Multi-Object-Occlusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.02636" target="_blank" rel="noopener noreferrer">MERLOT: Multimodal Neural Script Knowledge Models (2021)</a> (<a href="https://twitter.com/jmhessel/status/1401983972272345088" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://arxiv.org/abs/2106.04560" target="_blank" rel="noopener noreferrer">Scaling Vision Transformers (2021)</a></li><li><a href="https://arxiv.org/abs/2004.02788" target="_blank" rel="noopener noreferrer">Self-Supervised Scene De-occlusion (2020)</a> (<a href="https://github.com/XiaohangZhan/deocclusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.05744" target="_blank" rel="noopener noreferrer">Pivotal Tuning for Latent-based Editing of Real Images (2021)</a> (<a href="https://github.com/danielroich/PTI" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://flame.is.tue.mpg.de/" target="_blank" rel="noopener noreferrer">FLAME: Articulated Expressive 3D Head Model</a> (<a href="https://github.com/Rubikplayer/flame-fitting" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.09681" target="_blank" rel="noopener noreferrer">XCiT: Cross-Covariance Image Transformers (2021)</a> (<a href="https://github.com/facebookresearch/xcit" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://robust-cvd.github.io/" target="_blank" rel="noopener noreferrer">Robust Consistent Video Depth Estimation (2021)</a> (<a href="https://github.com/facebookresearch/robust_cvd" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Megvii-BaseDetection/cvpods" target="_blank" rel="noopener noreferrer">cvpods</a> - All-in-one Toolbox for Computer Vision Research.</li><li><a href="https://arxiv.org/abs/2103.10559" target="_blank" rel="noopener noreferrer">CDFI: Compression-Driven Network Design for Frame Interpolation (2021)</a> (<a href="https://github.com/tding1/CDFI" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://nerfmm.active.vision/" target="_blank" rel="noopener noreferrer">NeRF--: Neural Radiance Fields Without Known Camera Parameters (2021)</a> (<a href="https://github.com/ActiveVisionLab/nerfmm" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/ventusff/improved-nerfmm" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.robots.ox.ac.uk/ActiveVision/" target="_blank" rel="noopener noreferrer">Oxford Active Vision Laboratory</a> (<a href="https://github.com/ActiveVisionLab" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="http://szeliski.org/Book/" target="_blank" rel="noopener noreferrer">Computer Vision: Algorithms and Applications, 2nd ed.</a></li><li><a href="https://github.com/ccrisan/motioneyeos" target="_blank" rel="noopener noreferrer">motionEyeOS</a> - Linux distribution that turns your single board computer into a video surveillance system.</li><li><a href="https://arxiv.org/abs/2107.02192" target="_blank" rel="noopener noreferrer">Long-Short Transformer: Efficient Transformers for Language and Vision (2021)</a> (<a href="https://github.com/lucidrains/long-short-transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://distill.pub/2017/feature-visualization/" target="_blank" rel="noopener noreferrer">Feature Visualization – How NNs understand images (2017)</a></li><li><a href="https://arxiv.org/abs/1904.01906" target="_blank" rel="noopener noreferrer">What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis (2019)</a> (<a href="https://github.com/clovaai/deep-text-recognition-benchmark" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.16831" target="_blank" rel="noopener noreferrer">Convolutional Hough Matching Networks (2021)</a> (<a href="https://github.com/juhongm999/chm" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/microsoft/esvit" target="_blank" rel="noopener noreferrer">Efficient Self-Supervised Vision Transformers (EsViT)</a></li><li><a href="https://arxiv.org/abs/2103.10697" target="_blank" rel="noopener noreferrer">ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (2021)</a> (<a href="https://github.com/facebookresearch/convit" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://www.youtube.com/watch?v=QdbieYXn_XM" target="_blank" rel="noopener noreferrer">Paper Read</a>) (<a href="https://www.marktechpost.com/2021/07/20/facebook-ai-introduces-convit-a-computer-vision-model-that-improves-vision-transformers-vit-with-soft-convolutional-inductive-biases/" target="_blank" rel="noopener noreferrer">Article</a>)</li><li><a href="https://github.com/facebookresearch/co3d" target="_blank" rel="noopener noreferrer">CO3D: Common Objects In 3D</a> - Tools for working with the Common Objects in 3D (CO3D) dataset.</li><li><a href="https://arxiv.org/abs/2104.03841" target="_blank" rel="noopener noreferrer">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition (2021)</a> (<a href="https://github.com/microsoft/ORBIT-Dataset" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.13700" target="_blank" rel="noopener noreferrer">Vision Transformer Architecture Search (2021)</a> (<a href="https://github.com/xiusu/ViTAS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2007.12072" target="_blank" rel="noopener noreferrer">TSIT: A Simple and Versatile Framework for Image-to-Image Translation (2020)</a> (<a href="https://github.com/EndlessSora/TSIT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://machinelearning.apple.com/research/recognizing-people-photos" target="_blank" rel="noopener noreferrer">Recognizing People in Photos Through Private On-Device Machine Learning (2021)</a></li><li><a href="https://arxiv.org/abs/2012.02047" target="_blank" rel="noopener noreferrer">CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (2021)</a> (<a href="https://github.com/microsoft/CoCosNet-v2" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2105.10620" target="_blank" rel="noopener noreferrer">HPNet: Deep Primitive Segmentation Using Hybrid Representations (2021)</a> (<a href="https://github.com/SimingYan/HPNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/datature/portal" target="_blank" rel="noopener noreferrer">Portal</a> - Fastest way to load and visualize your deep neural networks on images and videos.</li><li><a href="https://github.com/cbsudux/awesome-human-pose-estimation" target="_blank" rel="noopener noreferrer">Awesome Human Pose Estimation</a></li><li><a href="https://arxiv.org/abs/2004.03791" target="_blank" rel="noopener noreferrer">Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)</a> (<a href="https://github.com/LongguangWang/ArbSR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/omihub777/ViT-CIFAR" target="_blank" rel="noopener noreferrer">PyTorch implementation for Vision Transformer</a></li><li><a href="https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/index.html" target="_blank" rel="noopener noreferrer">Repulsive Curves</a> - Model 2D &amp; 3D curves while avoiding self-intersection. (<a href="https://twitter.com/keenanisalive/status/1422318272800829440" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://github.com/icethrush/repulsive-curves" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://news.ycombinator.com/item?id=31120139" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://chenlin9.github.io/SDEdit/" target="_blank" rel="noopener noreferrer">SDEdit: Image Synthesis and Editing with Stochastic Differential Equations</a> (<a href="https://github.com/ermongroup/SDEdit" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.12902" target="_blank" rel="noopener noreferrer">Region Similarity Representation Learning (2021)</a> (<a href="https://github.com/Tete-Xiao/ReSim" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://nex-mpi.github.io/" target="_blank" rel="noopener noreferrer">NeX: Real-time View Synthesis with Neural Basis Expansion (2021)</a> (<a href="https://github.com/nex-mpi/nex-code" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://pengsongyou.github.io/conv_onet" target="_blank" rel="noopener noreferrer">Convolutional Occupancy Networks (2020)</a> (<a href="https://github.com/autonomousvision/convolutional_occupancy_networks" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.02166" target="_blank" rel="noopener noreferrer">Learning Optical Flow from a Few Matches (2021)</a> (<a href="https://github.com/zacjiang/SCV" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2107.05790" target="_blank" rel="noopener noreferrer">Visual Parser: Representing Part-whole Hierarchies with Transformers (2021)</a> (<a href="https://github.com/kevin-ssy/ViP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://jianghz.me/projects/superslomo/" target="_blank" rel="noopener noreferrer">Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation</a> (<a href="https://github.com/avinashpaliwal/Super-SloMo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.14641" target="_blank" rel="noopener noreferrer">On Generating Transferable Targeted Perturbations (2021)</a> (<a href="https://github.com/Muzammal-Naseer/TTP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/bertjiazheng/awesome-scene-understanding" target="_blank" rel="noopener noreferrer">Awesome Scene Understanding</a> - List of papers for scene understanding.</li><li><a href="https://arxiv.org/abs/2107.07651" target="_blank" rel="noopener noreferrer">Align before Fuse: Vision and Language Representation Learning with Momentum Distillation (2021)</a> (<a href="https://github.com/salesforce/ALBEF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://depthoraclenerf.github.io/" target="_blank" rel="noopener noreferrer">DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks (2021)</a> (<a href="https://github.com/facebookresearch/DONERF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.strayrobots.io/blog/object-detection-in-an-hour" target="_blank" rel="noopener noreferrer">Object Detection in an Hour (2021)</a> (<a href="https://news.ycombinator.com/item?id=28100346" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/1906.06423" target="_blank" rel="noopener noreferrer">Fixing the train-test resolution discrepancy (2020)</a> (<a href="https://github.com/facebookresearch/FixRes" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2008.09397" target="_blank" rel="noopener noreferrer">Align Deep Features for Oriented Object Detection (2020)</a> (<a href="https://github.com/csuhan/s2anet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.05565" target="_blank" rel="noopener noreferrer">Vision-Language Transformer and Query Generation for Referring Segmentation (2021)</a> (<a href="https://github.com/henghuiding/Vision-Language-Transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.cs.cmu.edu/~dsnerf/" target="_blank" rel="noopener noreferrer">Depth-supervised NeRF: Fewer Views and Faster Training for Free (2021)</a> (<a href="https://github.com/dunbar12138/DSNeRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.10257" target="_blank" rel="noopener noreferrer">SwinIR: Image Restoration Using Swin Transformer (2021)</a> (<a href="https://github.com/JingyunLiang/SwinIR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2105.04206" target="_blank" rel="noopener noreferrer">You Only Learn One Representation: Unified Network for Multiple Tasks (2021)</a> (<a href="https://github.com/WongKinYiu/yolor" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.11944" target="_blank" rel="noopener noreferrer">Probabilistic Modeling for Human Mesh Recovery (2021)</a> (<a href="https://github.com/nkolot/ProHMR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/" target="_blank" rel="noopener noreferrer">BARF: Bundle-Adjusting Neural Radiance Fields (2021)</a> (<a href="https://github.com/chenhsuanlin/bundle-adjusting-NeRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://postech-cvlab.github.io/SCNeRF/" target="_blank" rel="noopener noreferrer">Self-Calibrating Neural Radiance Fields (2021)</a> (<a href="https://github.com/POSTECH-CVLab/SCNeRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/NielsRogge/Transformers-Tutorials" target="_blank" rel="noopener noreferrer">Transformers-Tutorials</a> - Demos I made with the Transformers library by HuggingFace.</li><li><a href="https://arxiv.org/abs/2109.02563" target="_blank" rel="noopener noreferrer">3D Human Texture Estimation from a Single Image with Transformers (2021)</a> (<a href="https://github.com/xuxy09/Texformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.08860" target="_blank" rel="noopener noreferrer">CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval (2021)</a> (<a href="https://github.com/ArrowLuo/CLIP4Clip" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2003.12039" target="_blank" rel="noopener noreferrer">RAFT: Recurrent All Pairs Field Transforms for Optical Flow (2020)</a> (<a href="https://github.com/princeton-vl/RAFT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/ventusff/neurecon" target="_blank" rel="noopener noreferrer">Volume rendering + 3D implicit surface = Neural 3D Reconstruction</a></li><li><a href="http://www.contrib.andrew.cmu.edu/~gengshay/cvpr19stereo" target="_blank" rel="noopener noreferrer">Hierarchical Deep Stereo Matching on High-resolution Images (2019)</a> (<a href="https://github.com/gengshan-y/high-res-stereo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://zju3dv.github.io/object_nerf/" target="_blank" rel="noopener noreferrer">Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering (2021)</a> (<a href="https://github.com/zju3dv/object_nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://shepnerd.github.io/scg/" target="_blank" rel="noopener noreferrer">Image Synthesis via Semantic Composition (2021)</a> (<a href="https://github.com/dvlab-research/SCGAN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers" target="_blank" rel="noopener noreferrer">Awesome-Edge-Detection-Papers</a></li><li><a href="https://github.com/MarkMoHR/Awesome-Image-Colorization" target="_blank" rel="noopener noreferrer">Awesome-Image-Colorization</a></li><li><a href="https://longguangwang.github.io/Project/ArbSR/" target="_blank" rel="noopener noreferrer">Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)</a> (<a href="https://github.com/LongguangWang/ArbSR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/1adrianb/face-alignment" target="_blank" rel="noopener noreferrer">Face Recognition</a> - 2D and 3D Face alignment library build using PyTorch.</li><li><a href="https://github.com/willard-yuan/awesome-cbir-papers" target="_blank" rel="noopener noreferrer">Awesome image retrieval papers</a></li><li><a href="https://github.com/aimakerspace/PeekingDuck" target="_blank" rel="noopener noreferrer">PeekingDuck</a> - Modular framework built to simplify Computer Vision inference workloads.</li><li><a href="https://arxiv.org/abs/2104.11225" target="_blank" rel="noopener noreferrer">Pri3D: Can 3D Priors Help 2D Representation Learning? (2021)</a> (<a href="https://github.com/Sekunde/Pri3D" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/xinntao/facexlib" target="_blank" rel="noopener noreferrer">FaceXLib</a> - Aims at providing ready-to-use face-related functions based on current STOA open-source methods.</li><li><a href="https://github.com/open-mmlab/mmaction2" target="_blank" rel="noopener noreferrer">MMAction2</a> - Open-source toolbox for video understanding based on PyTorch.</li><li><a href="https://github.com/jslee02/awesome-collision-detection" target="_blank" rel="noopener noreferrer">Awesome Collision Detection</a></li><li><a href="https://arxiv.org/abs/2106.06847" target="_blank" rel="noopener noreferrer">Video Super-Resolution Transformer (2021)</a> (<a href="https://github.com/caojiezhang/VSR-Transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/JulianKnodt/nerf_atlas" target="_blank" rel="noopener noreferrer">NeRF Atlas</a> - Collection of NeRF extensions for fun and experimentation.</li><li><a href="https://github.com/cszn/KAIR" target="_blank" rel="noopener noreferrer">Training and testing codes for USRNet, DnCNN, FFDNet, SRMD, DPSR, MSRResNet, ESRGAN, BSRGAN, SwinIR</a></li><li><a href="https://arxiv.org/abs/2106.03106" target="_blank" rel="noopener noreferrer">Uformer: A General U-Shaped Transformer for Image Restoration (2021)</a> (<a href="https://github.com/ZhendongWang6/Uformer" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/lucidrains/uformer-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.12718" target="_blank" rel="noopener noreferrer">Self-Supervised Pretraining Improves Self-Supervised Pretraining (2021)</a> (<a href="https://github.com/cjrd/self-supervised-pretraining" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://xuchen-ethz.github.io/snarf/" target="_blank" rel="noopener noreferrer">SNARF: Differentiable Forward Skinning for Animating Non-Rigid Neural Implicit Shapes (2021)</a> (<a href="https://github.com/xuchen-ethz/snarf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/HRNet/HRFormer" target="_blank" rel="noopener noreferrer">HRFormer: High-Resolution Transformer for Dense Prediction, NeurIPS 2021</a></li><li><a href="https://github.com/airctic/icevision" target="_blank" rel="noopener noreferrer">IceVision</a> - Agnostic Computer Vision Framework - Pluggable to any Training Library: Fastai, Pytorch-Lightning with more to come. (<a href="https://airctic.com/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://arxiv.org/abs/2105.03761" target="_blank" rel="noopener noreferrer">e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks (2021)</a> (<a href="https://twitter.com/maximek3/status/1438554571756933127" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/ozan-oktay/Attention-Gated-Networks" target="_blank" rel="noopener noreferrer">Attention Gated Networks (Image Classification &amp; Segmentation) in PyTorch</a></li><li><a href="https://arxiv.org/abs/2108.03151v2" target="_blank" rel="noopener noreferrer">Full-Duplex Strategy for Video Object Segmentation (2021)</a> (<a href="https://github.com/GewelsJI/FSNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://handtracking.io/" target="_blank" rel="noopener noreferrer">YoHa</a> - Practical hand tracking engine. (<a href="https://news.ycombinator.com/item?id=28825820" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://github.com/handtracking-io/yoha" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.14948" target="_blank" rel="noopener noreferrer">Deep Learning for Face Anti-Spoofing: A Survey (2021)</a> (<a href="https://github.com/ZitongYu/DeepFAS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.07645" target="_blank" rel="noopener noreferrer">A-SDF: Learning Disentangled Signed Distance Functions for Articulated Shape Representation (2021)</a> (<a href="https://github.com/JitengMu/A-SDF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://saic-mdal.github.io/lama-project/" target="_blank" rel="noopener noreferrer">Resolution-robust Large Mask Inpainting with Fourier Convolutions (2021)</a> (<a href="https://github.com/saic-mdal/lama" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener noreferrer">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021)</a> (<a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/berniwal/swin-transformer-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.06635" target="_blank" rel="noopener noreferrer">ADOP: Approximate Differentiable One-Pixel Point Rendering (2021)</a> (<a href="https://twitter.com/rodolfor/status/1448655222876741634" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://twitter.com/keenanisalive/status/1448708734511951879" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://github.com/darglein/ADOP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://openreview.net/forum?id=TVHS5Y4dNvM" target="_blank" rel="noopener noreferrer">Patches Are All You Need? (2021)</a> (<a href="https://github.com/tmp-iclr/convmixer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.05258" target="_blank" rel="noopener noreferrer">ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation (2020)</a> (<a href="https://github.com/joe-siyuan-qiao/ViP-DeepLab" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2006.11339" target="_blank" rel="noopener noreferrer">Video Panoptic Segmentation (2020)</a> (<a href="https://github.com/mcahny/vps" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Kobaayyy/Awesome-ICCV2021-Low-Level-Vision" target="_blank" rel="noopener noreferrer">Awesome-ICCV2021-Low-Level-Vision</a> - Collection of Papers and Codes for ICCV2021 Low Level Vision and Image Generation.</li><li><a href="https://arxiv.org/abs/2104.00887" target="_blank" rel="noopener noreferrer">Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts (2021)</a> (<a href="https://github.com/clovaai/mxfont" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.07641" target="_blank" rel="noopener noreferrer">Non-deep Networks (2021)</a> (<a href="https://github.com/imankgoyal/NonDeepNetworks" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/fornaxai/receptivefield" target="_blank" rel="noopener noreferrer">receptivefield</a> - Gradient based receptive field estimation for Convolutional Neural Networks.</li><li><a href="https://igl.ethz.ch/projects/iso-points/" target="_blank" rel="noopener noreferrer">Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations (2021)</a> (<a href="https://github.com/yifita/iso-points" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.03110" target="_blank" rel="noopener noreferrer">Neural Articulated Radiance Field (2021)</a> (<a href="https://github.com/nogu-atsu/NARF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.10957" target="_blank" rel="noopener noreferrer">Efficient Visual Pretraining with Contrastive Detection (2021)</a> (<a href="https://github.com/deepmind/detcon" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/microsoft/VoTT" target="_blank" rel="noopener noreferrer">VoTT (Visual Object Tagging Tool)</a> - Source annotation and labeling tool for image and video assets.</li><li><a href="https://arxiv.org/abs/2110.08059" target="_blank" rel="noopener noreferrer">FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes (2021)</a> (<a href="https://github.com/rjbruin/flexconv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.06864" target="_blank" rel="noopener noreferrer">ByteTrack: Multi-Object Tracking by Associating Every Detection Box (2021)</a> (<a href="https://github.com/ifzhang/ByteTrack" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://iashin.ai/bmt" target="_blank" rel="noopener noreferrer">Dense Video Captioning with Bi-modal Transformer (2020)</a> (<a href="https://github.com/v-iashin/BMT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/zhanghang1989/PyTorch-Encoding" target="_blank" rel="noopener noreferrer">PyTorch-Encoding</a> - CV toolkit for my papers. (<a href="https://hangzhang.org/PyTorch-Encoding/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://arxiv.org/abs/2109.06474" target="_blank" rel="noopener noreferrer">Space Time Recurrent Memory Network (2021)</a> (<a href="https://github.com/lucidrains/spacetime-recurrent-memory-network" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/apple/ml-cvnets" target="_blank" rel="noopener noreferrer">CVNets</a> - Library for training computer vision networks.</li><li><a href="https://github.com/google-research/scenic" target="_blank" rel="noopener noreferrer">Scenic</a> - Jax Library for Computer Vision Research and Beyond. (<a href="https://arxiv.org/abs/2110.11403" target="_blank" rel="noopener noreferrer">Paper</a>)</li><li><a href="http://vincentqin.tech/cv-arxiv-daily/" target="_blank" rel="noopener noreferrer">CV Arxiv Daily</a> (<a href="https://github.com/Vincentqyw/cv-arxiv-daily" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/opencv/open_vision_capsules" target="_blank" rel="noopener noreferrer">OpenVisionCapsules</a> - Set of libraries for encapsulating smart vision algorithms.</li><li><a href="https://medmnist.com/" target="_blank" rel="noopener noreferrer">MedMNIST: Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification</a> (<a href="https://github.com/MedMNIST/MedMNIST" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.15358" target="_blank" rel="noopener noreferrer">Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language (2021)</a> (<a href="https://github.com/dingmyu/VRDP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2011.13495" target="_blank" rel="noopener noreferrer">Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces (2021)</a> (<a href="https://github.com/mabaorui/NeuralPull" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.09672" target="_blank" rel="noopener noreferrer">The 2021 Image Similarity Dataset and Challenge (2021)</a> (<a href="https://github.com/facebookresearch/isc2021" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.14855" target="_blank" rel="noopener noreferrer">K-Net: Towards Unified Image Segmentation (2021)</a> (<a href="https://github.com/ZwwWayne/K-Net" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch" target="_blank" rel="noopener noreferrer">Yolov5 + Deep Sort with PyTorch</a></li><li><a href="https://arxiv.org/abs/2106.03452" target="_blank" rel="noopener noreferrer">Shape As Points: A Differentiable Poisson Solver (2021)</a> (<a href="https://github.com/autonomousvision/shape_as_points" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.05208" target="_blank" rel="noopener noreferrer">Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm (2021)</a> (<a href="https://github.com/Sense-GVT/DeCLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/daqingliu/awesome-vln" target="_blank" rel="noopener noreferrer">Awesome Vision-Language Navigation</a></li><li><a href="http://vision.cs.utexas.edu/projects/exploring-exploration/" target="_blank" rel="noopener noreferrer">An Exploration of Embodied Visual Exploration (2021)</a> (<a href="https://github.com/facebookresearch/exploring_exploration" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1812.00101" target="_blank" rel="noopener noreferrer">DVC: An End-to-end Deep Video Compression Framework (2019)</a> (<a href="https://github.com/GuoLusjtu/DVC" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/dribnet/pixray" target="_blank" rel="noopener noreferrer">Pixray</a> - Neural image generation.</li><li><a href="https://arxiv.org/abs/2111.03042" target="_blank" rel="noopener noreferrer">Unsupervised Learning of Compositional Energy Concepts (2021)</a> (<a href="https://twitter.com/du_yilun/status/1456630363040751616" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://shuquanye.com/PNAL_website/" target="_blank" rel="noopener noreferrer">Learning with Noisy Labels for Robust Point Cloud Segmentation (2021)</a> (<a href="https://github.com/pleaseconnectwifi/PNAL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/yeemachine/kalidoface" target="_blank" rel="noopener noreferrer">Kalidoface</a> - Become a virtual character with just your webcam. (<a href="https://kalidoface.com/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/yeemachine/kalidokit" target="_blank" rel="noopener noreferrer">KalidoKit</a> - Face, Pose, and Hand Tracking Kinematics.</li><li><a href="https://pjreddie.com/courses/computer-vision/" target="_blank" rel="noopener noreferrer">The Ancient Secrets of Computer Vision</a></li><li><a href="https://arxiv.org/abs/2004.01178" target="_blank" rel="noopener noreferrer">Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training (2020)</a> (<a href="https://github.com/ShuhangGu/DASR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.pygaze.org/" target="_blank" rel="noopener noreferrer">PyGaze</a> - Open source eye-tracking software and more. (<a href="https://news.ycombinator.com/item?id=29171416" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2104.13874" target="_blank" rel="noopener noreferrer">Exploring Relational Context for Multi-Task Dense Prediction (2021)</a> (<a href="https://github.com/brdav/atrc" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://light.princeton.edu/publication/neural-scene-graphs/" target="_blank" rel="noopener noreferrer">Neural Scene Graphs for Dynamic Scenes (2021)</a> (<a href="https://github.com/princeton-computational-imaging/neural-scene-graphs" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://iterative-refinement.github.io/" target="_blank" rel="noopener noreferrer">Image Super-Resolution via Iterative Refinement</a> (<a href="https://news.ycombinator.com/item?id=29202899" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://openreview.net/forum?id=nBU_u6DLvoK" target="_blank" rel="noopener noreferrer">UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning (2021)</a> (<a href="https://github.com/lucidrains/uniformer-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.05392" target="_blank" rel="noopener noreferrer">Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers (2021)</a> (<a href="https://github.com/facebookresearch/Motionformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://tianweiy.github.io/mvp/" target="_blank" rel="noopener noreferrer">Multimodal Virtual Point 3D Detection (2021)</a> (<a href="https://github.com/tianweiy/MVP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Sara-Ahmed/SiT" target="_blank" rel="noopener noreferrer">SiT: Self-supervised vIsion Transformer</a></li><li><a href="https://arxiv.org/abs/2111.07624" target="_blank" rel="noopener noreferrer">Attention Mechanisms in Computer Vision: A Survey (2021)</a></li><li><a href="https://github.com/MenghaoGuo/Awesome-Vision-Attentions" target="_blank" rel="noopener noreferrer">Awesome Vision Attention Papers</a></li><li><a href="https://arxiv.org/abs/2103.04524" target="_blank" rel="noopener noreferrer">FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation (2021)</a> (<a href="https://github.com/ltkong218/FastFlowNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.monkeyoverflow.com/#/rendernet-a-cnn-for-differentiable-rendering-from-3d-shapes/" target="_blank" rel="noopener noreferrer">RenderNet: A deep convolutional network for differentiable rendering from 3D shapes (2018)</a> (<a href="https://github.com/thunguyenphuoc/RenderNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.06377" target="_blank" rel="noopener noreferrer">Masked Autoencoders Are Scalable Vision Learners (2021)</a> (<a href="https://github.com/pengzhiliang/MAE-pytorch" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/facebookresearch/mae" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/catalys1/mae-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/compphoto/BoostingMonocularDepth" target="_blank" rel="noopener noreferrer">BoostingMonocularDepth</a></li><li><a href="https://arxiv.org/abs/2111.09162" target="_blank" rel="noopener noreferrer">It&#x27;s About Time: Analog Clock Reading in the Wild (2021)</a> (<a href="https://twitter.com/giffmana/status/1461249563466022913" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://github.com/charigyang/itsabouttime" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://composevisualrelations.github.io/" target="_blank" rel="noopener noreferrer">Learning to Compose Visual Relations (2021)</a> (<a href="https://github.com/nanlliu/compose-visual-relations" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1805.09662" target="_blank" rel="noopener noreferrer">LF-Net: Learning Local Features from Images (2018)</a> (<a href="https://github.com/vcg-uvic/lf-net-release" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.02637" target="_blank" rel="noopener noreferrer">Aligning Pretraining for Detection via Object-Level Contrastive Learning (2021)</a> (<a href="https://github.com/hologerry/SoCo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.04138" target="_blank" rel="noopener noreferrer">Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis (2021)</a> (<a href="https://github.com/fel-thomas/Sobol-Attribution-Method" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cszn/USRNet" target="_blank" rel="noopener noreferrer">Deep unfolding network for image super-resolution (2020)</a></li><li><a href="https://arxiv.org/abs/2106.13112" target="_blank" rel="noopener noreferrer">VOLO: Vision Outlooker for Visual Recognition (2021)</a> (<a href="https://github.com/sail-sg/volo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.04076" target="_blank" rel="noopener noreferrer">Direct Multi-view Multi-person 3D Pose Estimation (2021)</a> (<a href="https://github.com/sail-sg/mvp" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://jhonykaesemodel.com/publication/image2mesh/" target="_blank" rel="noopener noreferrer">Image2Mesh: A learning framework for single image 3D reconstruction (2019)</a> (<a href="https://github.com/jhonykaesemodel/image2mesh" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/PeculiarVentures/GammaCV" target="_blank" rel="noopener noreferrer">GammaCV</a> - WebGL accelerated Computer Vision library for modern web applications. (<a href="https://gammacv.com/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://arxiv.org/abs/2109.14279" target="_blank" rel="noopener noreferrer">Localizing Objects with Self-Supervised Transformers and no Labels (2021)</a> (<a href="https://github.com/valeoai/LOST" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/genicam/harvesters" target="_blank" rel="noopener noreferrer">Harvester</a> - GenICam-based Image Acquisition Python Library.</li><li><a href="https://arxiv.org/abs/2111.12417" target="_blank" rel="noopener noreferrer">NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion (2021)</a> (<a href="https://github.com/microsoft/NUWA" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/lucidrains/nuwa-pytorch" target="_blank" rel="noopener noreferrer">PyTorch Code</a>)</li><li><a href="https://arxiv.org/abs/2102.03334" target="_blank" rel="noopener noreferrer">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision (2021)</a> (<a href="https://github.com/dandelin/ViLT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.11418" target="_blank" rel="noopener noreferrer">MetaFormer is Actually What You Need for Vision (2021)</a> (<a href="https://github.com/sail-sg/poolformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.09432" target="_blank" rel="noopener noreferrer">ARAPReg: An As-Rigid-As Possible Regularization Loss for Learning Deformable Shape Generators (2021)</a> (<a href="https://github.com/GitBoSun/ARAPReg" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.11124" target="_blank" rel="noopener noreferrer">Mesa: A Memory-saving Training Framework for Transformers (2021)</a> (<a href="https://github.com/zhuang-group/Mesa" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/open-mmlab/mmpose" target="_blank" rel="noopener noreferrer">MMPose</a> - Open-source toolbox for pose estimation based on PyTorch. (<a href="https://mmpose.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://arxiv.org/abs/2111.02387" target="_blank" rel="noopener noreferrer">An Empirical Study of Training End-to-End Vision-and-Language Transformers (2021)</a> (<a href="https://github.com/zdou0830/METER" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/hassony2/useful-computer-vision-phd-resources" target="_blank" rel="noopener noreferrer">Useful computer vision PhD resources</a></li><li><a href="https://www.tenyks.ai/" target="_blank" rel="noopener noreferrer">Tenyks</a> - Data-centric Computer Vision.</li><li><a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener noreferrer">Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation (2021)</a> (<a href="https://github.com/facebookresearch/Mask2Former" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://m-niemeyer.github.io/project-pages/giraffe/index.html" target="_blank" rel="noopener noreferrer">GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields (2021)</a> (<a href="https://github.com/autonomousvision/giraffe" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://mbaradad.github.io/learning_with_noise/" target="_blank" rel="noopener noreferrer">Learning to See by Looking at Noise (2021)</a> (<a href="https://github.com/mbaradad/learning_with_noise" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.07832" target="_blank" rel="noopener noreferrer">iBOT: Image BERT Pre-Training with Online Tokenizer (2021)</a> (<a href="https://github.com/bytedance/ibot" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.03857" target="_blank" rel="noopener noreferrer">Grounded Language-Image Pre-training (2021)</a> (<a href="https://github.com/microsoft/GLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1604.00449" target="_blank" rel="noopener noreferrer">3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction (2016)</a> (<a href="https://github.com/chrischoy/3D-R2N2" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://proceedings.mlr.press/v97/lee19d.html" target="_blank" rel="noopener noreferrer">Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks</a> (<a href="https://github.com/juho-lee/set_transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/TheShadow29/awesome-grounding" target="_blank" rel="noopener noreferrer">Awesome Visual Grounding</a></li><li><a href="https://arxiv.org/abs/2111.05464" target="_blank" rel="noopener noreferrer">Are Transformers More Robust Than CNNs? (2021)</a> (<a href="https://github.com/ytongbai/ViTs-vs-CNNs" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://alexyu.net/plenoxels/" target="_blank" rel="noopener noreferrer">Plenoxels: Radiance Fields without Neural Networks (2021)</a> (<a href="https://github.com/sxyu/svox2" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/sarafridov/plenoxels" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/TencentARC/GFPGAN" target="_blank" rel="noopener noreferrer">GFPGAN</a> - Developing Practical Algorithms for Real-world Face Restoration.</li><li><a href="https://github.com/yaochih/awesome-video-stabilization" target="_blank" rel="noopener noreferrer">Awesome Video Stabilization</a></li><li><a href="https://apchenstu.github.io/mvsnerf/" target="_blank" rel="noopener noreferrer">MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo (2021)</a> (<a href="https://github.com/apchenstu/mvsnerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://people.eecs.berkeley.edu/~jathushan/T3DP/" target="_blank" rel="noopener noreferrer">Tracking People with 3D Representations (2021)</a> (<a href="https://github.com/brjathu/T3DP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1908.09492" target="_blank" rel="noopener noreferrer">Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection (2019:)</a> (<a href="https://github.com/poodarchu/Det3D" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://hhsinping.github.io/3d_scene_stylization/" target="_blank" rel="noopener noreferrer">Learning to Stylize Novel Views (2021)</a> (<a href="https://github.com/hhsinping/stylescene" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Megvii-BaseDetection/YOLOX" target="_blank" rel="noopener noreferrer">YOLOX</a> - High-performance anchor-free YOLO. (<a href="https://yolox.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://hongwenzhang.github.io/pymaf/" target="_blank" rel="noopener noreferrer">PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop (2021)</a> (<a href="https://github.com/HongwenZhang/PyMAF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.08275" target="_blank" rel="noopener noreferrer">SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation (2021)</a> (<a href="https://github.com/wjf5203/SeqFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://markboss.me/publication/2021-nerd/" target="_blank" rel="noopener noreferrer">NeRD: Neural Reflectance Decomposition from Image Collections (2021)</a> (<a href="https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.14822" target="_blank" rel="noopener noreferrer">Vector Quantized Diffusion Model for Text-to-Image Synthesis (2021)</a> (<a href="https://github.com/microsoft/VQ-Diffusion" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/cientgu/VQ-Diffusion" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/microsoft/VQ-Diffusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.10741" target="_blank" rel="noopener noreferrer">GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models (2021)</a> (<a href="https://github.com/openai/glide-text2im" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Unity-Technologies/SynthDet" target="_blank" rel="noopener noreferrer">SynthDet</a> - End-to-end object detection pipeline using synthetic data.</li><li><a href="https://arxiv.org/abs/2112.11010" target="_blank" rel="noopener noreferrer">MPViT: Multi-Path Vision Transformer for Dense Prediction (2021)</a> (<a href="https://github.com/youngwanLEE/MPViT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.10762" target="_blank" rel="noopener noreferrer">StyleSwin: Transformer-based GAN for High-resolution Image Generation (2021)</a> (<a href="https://github.com/microsoft/StyleSwin" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.05304" target="_blank" rel="noopener noreferrer">Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline (2021)</a> (<a href="https://github.com/princeton-vl/SimpleView" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.12750" target="_blank" rel="noopener noreferrer">SLIP: Self-supervision meets Language-Image Pre-training (2021)</a> (<a href="https://github.com/facebookresearch/SLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.03109" target="_blank" rel="noopener noreferrer">General Facial Representation Learning in a Visual-Linguistic Manner (2021)</a> (<a href="https://github.com/microsoft/FaRL" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/FacePerceiver/FaRL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://hypernerf.github.io/" target="_blank" rel="noopener noreferrer">HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields</a> (<a href="https://github.com/google/hypernerf" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://news.ycombinator.com/item?id=29698276" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2110.03480" target="_blank" rel="noopener noreferrer">Learning to Regress Bodies from Images using Differentiable Semantic Rendering (2021)</a> (<a href="https://github.com/saidwivedi/DSR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.10752" target="_blank" rel="noopener noreferrer">High-Resolution Image Synthesis with Latent Diffusion Models (2021)</a> (<a href="https://github.com/CompVis/latent-diffusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://richardt.name/publications/audio-dvp/" target="_blank" rel="noopener noreferrer">Photorealistic Audio-driven Video Portraits (2020)</a> (<a href="https://github.com/xinwen-cs/AudioDVP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/xinghaochen/awesome-hand-pose-estimation" target="_blank" rel="noopener noreferrer">Awesome Hand Pose Estimation</a></li><li><a href="https://arxiv.org/abs/2103.15679" target="_blank" rel="noopener noreferrer">Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers (2021)</a> (<a href="https://github.com/hila-chefer/Transformer-MM-Explainability" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.09838" target="_blank" rel="noopener noreferrer">Transformer Interpretability Beyond Attention Visualization (2021)</a> (<a href="https://github.com/hila-chefer/Transformer-Explainability" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.03133" target="_blank" rel="noopener noreferrer">StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Synthesis (2021)</a> (<a href="https://github.com/pschaldenbrand/StyleCLIPDraw" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.07597" target="_blank" rel="noopener noreferrer">Light Field Image Super-Resolution with Transformers (2021)</a> (<a href="https://github.com/ZhengyuLiang24/LFT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.12701" target="_blank" rel="noopener noreferrer">Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes (2021)</a> (<a href="https://github.com/samb-t/unleashing-transformers" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.vision.huji.ac.il/deepsim/" target="_blank" rel="noopener noreferrer">DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample (2021)</a> (<a href="https://github.com/eliahuhorwitz/DeepSIM" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.00726" target="_blank" rel="noopener noreferrer">RAFT-3D: Scene Flow using Rigid-Motion Embeddings (2021)</a> (<a href="https://github.com/princeton-vl/RAFT-3D" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://jwbian.net/unsupervised-indoor-depth" target="_blank" rel="noopener noreferrer">Unsupervised Indoor Depth Estimation (2020)</a> (<a href="https://github.com/JiawangBian/Unsupervised-Indoor-Depth" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2102.06199" target="_blank" rel="noopener noreferrer">A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose (2021)</a> (<a href="https://github.com/LemonATsu/A-NeRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.17263" target="_blank" rel="noopener noreferrer">Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective (2021)</a> (<a href="https://github.com/xvjiarui/VFS#readme" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://gitlab.com/DO-CV/sara" target="_blank" rel="noopener noreferrer">Sara</a> - Easy-to-Use C++ Computer Vision Library.</li><li><a href="https://arxiv.org/abs/2109.07547" target="_blank" rel="noopener noreferrer">RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching (2021)</a> (<a href="https://github.com/princeton-vl/RAFT-Stereo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2005.09007" target="_blank" rel="noopener noreferrer">U-2-Net: Going Deeper with Nested U-Structure for Salient Object Detection (2020)</a> (<a href="https://github.com/Norod/U-2-Net-StyleTransfer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.00487" target="_blank" rel="noopener noreferrer">Language as Queries for Referring Video Object Segmentation (2022)</a> (<a href="https://github.com/wjn922/ReferFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2110.08825" target="_blank" rel="noopener noreferrer">Localization with Sampling-Argmax (2021)</a> (<a href="https://github.com/Jeff-sjtu/sampling-argmax" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://voca.is.tue.mpg.de/" target="_blank" rel="noopener noreferrer">VOCA: Voice Operated Character Animation</a> (<a href="https://github.com/TimoBolkart/voca" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cvzone/cvzone" target="_blank" rel="noopener noreferrer">CVZone</a> - Computer vision package that makes its easy to run Image processing and AI functions.</li><li><a href="https://github.com/serengil/deepface" target="_blank" rel="noopener noreferrer">Deepface</a> - Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python.</li><li><a href="https://arxiv.org/abs/2012.07131" target="_blank" rel="noopener noreferrer">Location-aware Single Image Reflection Removal (2021)</a> (<a href="https://github.com/zdlarr/Location-aware-SIRR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.08223" target="_blank" rel="noopener noreferrer">MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement (2021)</a> (<a href="https://github.com/facebookresearch/meshtalk" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.02605" target="_blank" rel="noopener noreferrer">Detecting Twenty-thousand Classes using Image-level Supervision (2022)</a> (<a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.03546" target="_blank" rel="noopener noreferrer">Language-driven Semantic Segmentation (2022)</a> (<a href="https://github.com/isl-org/lang-seg" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.08459" target="_blank" rel="noopener noreferrer">Rethinking Nearest Neighbors for Visual Classification (2021)</a> (<a href="https://github.com/KMnP/nn-revisit" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.00520" target="_blank" rel="noopener noreferrer">Vision Transformer with Deformable Attention (2022)</a> (<a href="https://github.com/LeapLabTHU/DAT" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/lucidrains/deformable-attention" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/keras-team/keras-cv" target="_blank" rel="noopener noreferrer">KerasCV</a> - Industry-strength Computer Vision workflows with Keras.</li><li><a href="https://github.com/NVlabs/instant-ngp" target="_blank" rel="noopener noreferrer">Instant Neural Graphics Primitives</a> - Lightning fast NeRF and more.</li><li><a href="https://arxiv.org/abs/2106.08322" target="_blank" rel="noopener noreferrer">Dynamic Head: Unifying Object Detection Heads with Attentions (2021)</a> (<a href="https://github.com/microsoft/DynamicHead" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.12786" target="_blank" rel="noopener noreferrer">ELSA: Enhanced Local Self-Attention for Vision Transformer (2021)</a> (<a href="https://github.com/damo-cv/ELSA" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/libffcv/ffcv" target="_blank" rel="noopener noreferrer">FFCV</a> - Fast Forward Computer Vision (and other ML workloads!) (<a href="https://ffcv.io/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/open-mmlab/awesome-vit" target="_blank" rel="noopener noreferrer">Awesome Vit</a> - Curated list and survey of awesome Vision Transformers.</li><li><a href="https://nvlabs.github.io/instant-ngp/" target="_blank" rel="noopener noreferrer">Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (2022)</a> (<a href="https://github.com/ashawkey/torch-ngp" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/yashbhalgat/HashNeRF-pytorch" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://www.youtube.com/watch?v=j8tMk-GE8hY" target="_blank" rel="noopener noreferrer">Video Summary</a>) (<a href="https://news.ycombinator.com/item?id=30408898" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/1711.10684" target="_blank" rel="noopener noreferrer">Road Extraction by Deep Residual U-Net (2017)</a> (<a href="https://github.com/nikhilroxtomar/Deep-Residual-Unet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1911.08324" target="_blank" rel="noopener noreferrer">Single-Stage 6D Object Pose Estimation (2019)</a> (<a href="https://github.com/cvlab-epfl/single-stage-pose" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/google-research/task_adaptation" target="_blank" rel="noopener noreferrer">Visual Task Adaptation Benchmark (VTAB)</a></li><li><a href="https://tadaconv-iclr2022.github.io/" target="_blank" rel="noopener noreferrer">TAda! Temporally-Adaptive Convolutions for Video Understanding (2022)</a> (<a href="https://github.com/alibaba-mmai-research/TAdaConv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://moechsle.github.io/unisurf/" target="_blank" rel="noopener noreferrer">UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction (2021)</a> (<a href="https://github.com/autonomousvision/unisurf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://visual.cs.ucl.ac.uk/pubs/cofusion/index.html" target="_blank" rel="noopener noreferrer">Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects (2020)</a> (<a href="https://github.com/martinruenz/co-fusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.12288" target="_blank" rel="noopener noreferrer">VRT: A Video Restoration Transformer (2021)</a> (<a href="https://github.com/JingyunLiang/VRT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.06796" target="_blank" rel="noopener noreferrer">Unknown Object Segmentation from Stereo Images (2021)</a> (<a href="https://github.com/DLR-RM/instr" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1803.08024" target="_blank" rel="noopener noreferrer">Stacked Cross Attention for Image-Text Matching (2018)</a> (<a href="https://github.com/kuanghuei/SCAN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.12086" target="_blank" rel="noopener noreferrer">BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (2022)</a> (<a href="https://github.com/salesforce/BLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2101.05796" target="_blank" rel="noopener noreferrer">DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows (2021)</a> (<a href="https://github.com/volflow/DeFlow" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.11539" target="_blank" rel="noopener noreferrer">DocFormer: End-to-End Transformer for Document Understanding (2022)</a> (<a href="https://github.com/shabie/docformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.12782" target="_blank" rel="noopener noreferrer">SeMask: Semantically Masked Transformers for Semantic Segmentation (2021)</a> (<a href="https://github.com/Picsart-AI-Research/SeMask-Segmentation" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2004.07728" target="_blank" rel="noopener noreferrer">Image Quality Assessment: Unifying Structure and Texture Similarity (2020)</a> (<a href="https://github.com/dingkeyan93/DISTS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/naver/fire" target="_blank" rel="noopener noreferrer">Learning Super-Features for Image Retrieval (2022)</a></li><li><a href="https://github.com/jinfagang/yolov7" target="_blank" rel="noopener noreferrer">YOLOv7</a> - Framework Beyond Detection.</li><li><a href="https://arxiv.org/abs/2112.14757" target="_blank" rel="noopener noreferrer">A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model (2021)</a> (<a href="https://github.com/MendelXu/zsseg.baseline" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/JudasDie/SOTS" target="_blank" rel="noopener noreferrer">Single/Multiple Object Tracking and Segmentation</a></li><li><a href="https://arxiv.org/abs/2109.07950" target="_blank" rel="noopener noreferrer">Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection (2021)</a> (<a href="https://github.com/meilfang/LMFD-PAD" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.09965" target="_blank" rel="noopener noreferrer">HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping (2021)</a> (<a href="https://github.com/mindslab-ai/hififace" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://waymo.com/research/block-nerf/" target="_blank" rel="noopener noreferrer">Scalable Large Scene Neural View Synthesis (2022)</a> (<a href="https://news.ycombinator.com/item?id=30299498" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/dair-ai/Transformers-Recipe" target="_blank" rel="noopener noreferrer">Transformer Recipe</a> - Quick recipe to learn all about Transformers.</li><li><a href="https://arxiv.org/abs/2201.02533" target="_blank" rel="noopener noreferrer">NeROIC: Neural Rendering of Objects from Online Image Collections (2022)</a> (<a href="https://github.com/snap-research/NeROIC" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.00888" target="_blank" rel="noopener noreferrer">DiffusionNet: Discretization Agnostic Learning on Surfaces (2022)</a> (<a href="https://github.com/nmwsharp/diffusion-net" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://film-net.github.io/" target="_blank" rel="noopener noreferrer">FILM: Frame Interpolation for Large Motion (2022)</a> (<a href="https://github.com/google-research/frame-interpolation" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2108.09964" target="_blank" rel="noopener noreferrer">Learning Signed Distance Field for Multi-view Surface Reconstruction (2021)</a> (<a href="https://github.com/jzhangbs/MVSDF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/bnu-wangxun/Deep_Metric" target="_blank" rel="noopener noreferrer">Deep Metric Learning in PyTorch</a></li><li><a href="https://icon.is.tue.mpg.de/" target="_blank" rel="noopener noreferrer">ICON: Implicit Clothed humans Obtained from Normals (2021)</a> (<a href="https://github.com/YuliangXiu/ICON" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://clipasso.github.io/clipasso/" target="_blank" rel="noopener noreferrer">CLIPasso: Semantically-Aware Object Sketching (2022)</a> (<a href="https://github.com/yael-vinker/CLIPasso" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://banmo-www.github.io/" target="_blank" rel="noopener noreferrer">BANMo: Building Animatable 3D Neural Models from Many Casual Videos (2022)</a> (<a href="https://github.com/facebookresearch/banmo" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/xxxnell/how-do-vits-work" target="_blank" rel="noopener noreferrer">How Do Vision Transformers Work?</a></li><li><a href="https://github.com/louisfb01/top-10-cv-papers-2021" target="_blank" rel="noopener noreferrer">Top 10 Computer Vision Papers of 2021</a></li><li><a href="https://arxiv.org/abs/2006.09603" target="_blank" rel="noopener noreferrer">Exploring Sparsity in Image Super-Resolution for Efficient Inference (2021)</a> (<a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/SMSR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/computational-imaging/automatic-integration" target="_blank" rel="noopener noreferrer">AutoInt: Automatic Integration for Fast Neural Volume Rendering (2021)</a></li><li><a href="https://arxiv.org/abs/2109.01134" target="_blank" rel="noopener noreferrer">Learning to Prompt for Vision-Language Models (2021)</a> (<a href="https://github.com/KaiyangZhou/CoOp" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1812.01969" target="_blank" rel="noopener noreferrer">Summarizing Videos with Attention (2019)</a> (<a href="https://github.com/ok1zjf/VASNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/vkit-dev/vkit" target="_blank" rel="noopener noreferrer">vkit</a> - Toolkit designed for CV (Computer Vision) developers. (<a href="https://vkit-dev.github.io/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://arxiv.org/abs/2110.11191" target="_blank" rel="noopener noreferrer">Generative Adversarial Graph Convolutional Networks for Human Action Synthesis (2021)</a> (<a href="https://github.com/DegardinBruno/Kinetic-GAN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/wchstrife/Awesome-Image-Matting" target="_blank" rel="noopener noreferrer">Awesome Image Matting</a></li><li><a href="http://lstm.seas.harvard.edu/latex/" target="_blank" rel="noopener noreferrer">Image-to-Markup Generation with Coarse-to-Fine Attention</a> (<a href="https://github.com/harvardnlp/im2markup" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://aryanvij02.medium.com/push-ups-with-python-mediapipe-open-a544bd9b4351" target="_blank" rel="noopener noreferrer">Push-ups with Python, mediapipe and OpenCV</a> (<a href="https://news.ycombinator.com/item?id=30402651" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/Sanster/lama-cleaner" target="_blank" rel="noopener noreferrer">Lama-cleaner: Image inpainting tool powered by LaMa</a></li><li><a href="https://arxiv.org/abs/2202.10401" target="_blank" rel="noopener noreferrer">Vision-Language Pre-Training with Triple Contrastive Learning (2022)</a> (<a href="https://github.com/uta-smile/TCL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/timzhang642/3D-Machine-Learning" target="_blank" rel="noopener noreferrer">3D Machine Learning resources/papers</a></li><li><a href="https://github.com/voxel51/fiftyone" target="_blank" rel="noopener noreferrer">FiftyOne</a> - Open-source tool for building high-quality datasets and computer vision models.</li><li><a href="https://arxiv.org/abs/2202.11539" target="_blank" rel="noopener noreferrer">Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut (2022)</a> (<a href="https://github.com/YangtaoWANG95/TokenCut" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/luanshiyinyang/awesome-multiple-object-tracking" target="_blank" rel="noopener noreferrer">Awesome Multiple object Tracking</a></li><li><a href="https://arxiv.org/abs/2108.05054" target="_blank" rel="noopener noreferrer">Rethinking Coarse-to-Fine Approach in Single Image Deblurring (2021)</a> (<a href="https://github.com/chosj95/MIMO-UNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2102.06183" target="_blank" rel="noopener noreferrer">Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling (2021)</a> (<a href="https://github.com/jayleicn/ClipBERT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.11921" target="_blank" rel="noopener noreferrer">As-ViT: Auto-scaling Vision Transformers without Training (2022)</a> (<a href="https://github.com/VITA-Group/AsViT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/3DFaceBody/awesome-3dbody-papers" target="_blank" rel="noopener noreferrer">Awesome 3D Body Papers</a></li><li><a href="https://arxiv.org/abs/2108.00616" target="_blank" rel="noopener noreferrer">RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth (2021)</a> (<a href="https://github.com/MengyangPu/RINDNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/drivendataorg/image-similarity-challenge" target="_blank" rel="noopener noreferrer">Image Similarity Challenge</a></li><li><a href="https://arxiv.org/abs/2111.14818" target="_blank" rel="noopener noreferrer">Blended Diffusion for Text-driven Editing of Natural Images (2021)</a> (<a href="https://github.com/omriav/blended-diffusion" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2006.16241" target="_blank" rel="noopener noreferrer">The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization (2021)</a> (<a href="https://github.com/hendrycks/imagenet-r" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/nkalavak/awesome-object-pose" target="_blank" rel="noopener noreferrer">Awesome Object Pose</a></li><li><a href="https://github.com/yulunzhang/video-enhancement" target="_blank" rel="noopener noreferrer">Video Enhancement papers/resources</a></li><li><a href="https://github.com/ryanxingql/powerqe" target="_blank" rel="noopener noreferrer">PowerQE: An Open Framework for Quality Enhancement of Compressed Visual Data</a></li><li><a href="https://arxiv.org/abs/2203.03884" target="_blank" rel="noopener noreferrer">Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels (2022)</a> (<a href="https://github.com/Haochen-Wang409/U2PL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://magamig.github.io/posts/accurate-image-alignment-and-registration-using-opencv/" target="_blank" rel="noopener noreferrer">Accurate Image Alignment and Registration Using OpenCV (2022)</a> (<a href="https://news.ycombinator.com/item?id=30613745" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/facebookresearch/grounded-video-description" target="_blank" rel="noopener noreferrer">Video Grounding and Captioning</a></li><li><a href="https://github.com/IDEACVR/awesome-detection-transformer" target="_blank" rel="noopener noreferrer">Awesome Detection Transformer</a></li><li><a href="https://arxiv.org/abs/2110.08985" target="_blank" rel="noopener noreferrer">StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis (2021)</a> (<a href="https://github.com/facebookresearch/StyleNeRF" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="http://jiataogu.me/style_nerf/" target="_blank" rel="noopener noreferrer">Web</a>) (<a href="https://news.ycombinator.com/item?id=30637403" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2006.11538" target="_blank" rel="noopener noreferrer">Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition (2020)</a> (<a href="https://github.com/iduta/pyconv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.12707" target="_blank" rel="noopener noreferrer">MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation (2021)</a> (<a href="https://github.com/Vegetebird/MHFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.03605" target="_blank" rel="noopener noreferrer">DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (2022)</a> (<a href="https://github.com/IDEACVR/DINO" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/zubair-irshad/CenterSnap" target="_blank" rel="noopener noreferrer">Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation (2022)</a></li><li><a href="https://arxiv.org/abs/2107.10224" target="_blank" rel="noopener noreferrer">CycleMLP: A MLP-like Architecture for Dense Prediction (2022)</a> (<a href="https://github.com/ShoufaChen/CycleMLP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/weizhou-geek/Image-Quality-Assessment-Benchmark" target="_blank" rel="noopener noreferrer">Image Quality Assessment Benchmark</a></li><li><a href="https://arxiv.org/abs/2112.11427" target="_blank" rel="noopener noreferrer">StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation (2021)</a> (<a href="https://github.com/royorel/StyleSDF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/" target="_blank" rel="noopener noreferrer">Transformers, originally designed to handle language, are taking on vision (2022)</a> (<a href="https://news.ycombinator.com/item?id=30629214" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/1709.00643" target="_blank" rel="noopener noreferrer">Fast Image Processing with Fully-Convolutional Networks (2017)</a> (<a href="https://github.com/nrupatunga/Fast-Image-Filters" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1812.01243" target="_blank" rel="noopener noreferrer">Efficient Attention: Attention with Linear Complexities (2020)</a> (<a href="https://github.com/cmsflash/efficient-attention" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://yandex-research.github.io/ddpm-segmentation/" target="_blank" rel="noopener noreferrer">Label-Efficient Semantic Segmentation with Diffusion Models (2022)</a> (<a href="https://github.com/yandex-research/ddpm-segmentation" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cvg/Hierarchical-Localization" target="_blank" rel="noopener noreferrer">hloc</a> - Modular toolbox for state-of-the-art 6-DoF visual localization.</li><li><a href="https://arxiv.org/abs/2104.10858" target="_blank" rel="noopener noreferrer">All Tokens Matter: Token Labeling for Training Better Vision Transformers (2021)</a> (<a href="https://github.com/zihangJiang/TokenLabeling" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1811.11168" target="_blank" rel="noopener noreferrer">Deformable ConvNets v2: More Deformable, Better Results (2018)</a> (<a href="https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.09881" target="_blank" rel="noopener noreferrer">Restormer: Efficient Transformer for High-Resolution Image Restoration (2021)</a> (<a href="https://github.com/swz30/Restormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://openreview.net/forum?id=O476oWmiNNp" target="_blank" rel="noopener noreferrer">Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice (2022)</a> (<a href="https://github.com/VITA-Group/ViT-Anti-Oversmoothing" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://zju3dv.github.io/neuralrecon/" target="_blank" rel="noopener noreferrer">NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video (2021)</a> (<a href="https://github.com/zju3dv/NeuralRecon" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/rlczddl/awesome-3d-human-reconstruction" target="_blank" rel="noopener noreferrer">Awesome 3D Human Reconstruction</a></li><li><a href="https://github.com/lijiaman/awesome-3d-human" target="_blank" rel="noopener noreferrer">Awesome 3D Human Resources List</a></li><li><a href="https://arxiv.org/abs/2201.03545" target="_blank" rel="noopener noreferrer">A ConvNet for the 2020s (2022)</a> (<a href="https://github.com/facebookresearch/ConvNeXt" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/FrancescoSaverioZuppichini/ConvNext" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/TachibanaYoshino/Remote-sensing-image-semantic-segmentation" target="_blank" rel="noopener noreferrer">Remote-sensing-image-semantic-segmentation</a> - Uses Unet-based improved networks to study Remote sensing image semantic segmentation, which is based on keras.</li><li><a href="https://arxiv.org/abs/2105.02872" target="_blank" rel="noopener noreferrer">Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies (2021)</a> (<a href="https://github.com/zju3dv/animatable_nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.09517" target="_blank" rel="noopener noreferrer">TensoRF: Tensorial Radiance Fields (2022)</a> (<a href="https://github.com/apchenstu/TensoRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.01941" target="_blank" rel="noopener noreferrer">Autoregressive Image Generation using Residual Quantization (2022)</a> (<a href="https://github.com/lucidrains/RQ-Transformer" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/kakaobrain/rq-vae-transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/hmartelb/Pix2Pix-Timbre-Transfer" target="_blank" rel="noopener noreferrer">Pix2Pix Timbre Transfer</a></li><li><a href="https://arxiv.org/abs/2203.09301" target="_blank" rel="noopener noreferrer">One-Shot Adaptation of GAN in Just One CLIP (2022)</a> (<a href="https://github.com/submission6378/OneshotCLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.14635" target="_blank" rel="noopener noreferrer">PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds (2021)</a> (<a href="https://github.com/CVMI-Lab/PAConv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.12602" target="_blank" rel="noopener noreferrer">VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training (2022)</a> (<a href="https://github.com/MCG-NJU/VideoMAE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/ucasligang/awesome-MIM" target="_blank" rel="noopener noreferrer">Awesome Masked Image Modeling</a></li><li><a href="https://arxiv.org/abs/2203.13249" target="_blank" rel="noopener noreferrer">BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training (2022)</a> (<a href="https://github.com/amazon-research/bigdetection" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.01293" target="_blank" rel="noopener noreferrer">A Transformer-Based Siamese Network for Change Detection (2022)</a> (<a href="https://github.com/wgcban/ChangeFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.01486" target="_blank" rel="noopener noreferrer">Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition (2021)</a> (<a href="https://github.com/QVPR/Patch-NetVLAD" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2109.01903" target="_blank" rel="noopener noreferrer">Robust fine-tuning of zero-shot models (2022)</a> (<a href="https://github.com/mlfoundations/wise-ft" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2105.06464" target="_blank" rel="noopener noreferrer">DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision (2021)</a> (<a href="https://github.com/NVlabs/DiscoBox" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.11094" target="_blank" rel="noopener noreferrer">GroupViT: Semantic Segmentation Emerges from Text Supervision (2022)</a> (<a href="https://github.com/NVlabs/GroupViT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.02503" target="_blank" rel="noopener noreferrer">HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening (2022)</a> (<a href="https://github.com/wgcban/HyperTransformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.10489" target="_blank" rel="noopener noreferrer">TVConv: Efficient Translation Variant Convolution for Layout-aware Visual Processing (2022)</a> (<a href="https://github.com/JierunChen/TVConv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/marcoslucianops/DeepStream-Yolo" target="_blank" rel="noopener noreferrer">DeepStream-Yolo</a> - NVIDIA DeepStream SDK 6.0.1 configuration for YOLO models.</li><li><a href="https://arxiv.org/abs/2203.05550" target="_blank" rel="noopener noreferrer">An Empirical Investigation of 3D Anomaly Detection and Segmentation (2022)</a> (<a href="https://github.com/eliahuhorwitz/3D-ADS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.04017" target="_blank" rel="noopener noreferrer">Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation (2021)</a> (<a href="https://github.com/syguan96/DynaBOA" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2109.11418" target="_blank" rel="noopener noreferrer">Layered Neural Atlases for Consistent Video Editing (2021)</a> (<a href="https://github.com/ykasten/layered-neural-atlases" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank" rel="noopener noreferrer">TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution (2020)</a></li><li><a href="https://chenyanglei.github.io/sfpwild/index.html" target="_blank" rel="noopener noreferrer">Shape from Polarization for Complex Scenes in the Wild (2022)</a> (<a href="https://github.com/ChenyangLEI/sfp-wild" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/google-research/pix2seq" target="_blank" rel="noopener noreferrer">Pix2Seq</a> - General framework for turning RGB pixels into semantically meaningful sequences.</li><li><a href="https://gait3d.github.io/" target="_blank" rel="noopener noreferrer">Gait Recognition in the Wild with Dense 3D Representations and A Benchmark (2022)</a> (<a href="https://github.com/Gait3D/Gait3D-Benchmark" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/jaketae/ensemble-transformers" target="_blank" rel="noopener noreferrer">Ensembling Hugging Face Transformers made easy</a></li><li><a href="https://arxiv.org/abs/1904.05068" target="_blank" rel="noopener noreferrer">Relational Knowledge Distillation (2019)</a> (<a href="https://github.com/lenscloth/RKD" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.12130" target="_blank" rel="noopener noreferrer">NICE-SLAM: Neural Implicit Scalable Encoding for SLAM (2021)</a> (<a href="https://github.com/cvg/nice-slam" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1711.07566" target="_blank" rel="noopener noreferrer">Neural 3D Mesh Renderer (2017)</a> (<a href="https://github.com/daniilidis-group/neural_renderer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.14463" target="_blank" rel="noopener noreferrer">Large-scale Bilingual Language-Image Contrastive Learning (2022)</a> (<a href="https://github.com/navervision/KELIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/openMVG/openMVG" target="_blank" rel="noopener noreferrer">OpenMVG</a> - Open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion.</li><li><a href="https://arxiv.org/abs/2112.04148" target="_blank" rel="noopener noreferrer">Neural Points: Point Cloud Representation with Neural Fields (2021)</a> (<a href="https://github.com/WanquanF/NeuralPoints" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/vinissimus/opencv-js-webworker" target="_blank" rel="noopener noreferrer">OpenCV JS Web Worker</a> - Getting started with OpenCV compiled to Webassembly and loaded in a worker.</li><li><a href="https://arxiv.org/abs/2203.14297" target="_blank" rel="noopener noreferrer">Learning Graph Regularisation for Guided Super-Resolution (2022)</a> (<a href="https://github.com/prs-eth/graph-super-resolution" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.14291" target="_blank" rel="noopener noreferrer">Video Polyp Segmentation: A Deep Learning Perspective (2022)</a> (<a href="https://github.com/GewelsJI/VPS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.13664" target="_blank" rel="noopener noreferrer">Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images (2022)</a> (<a href="https://github.com/MathLee/ACCoNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.09035" target="_blank" rel="noopener noreferrer">HybridNets: End-to-End Perception Network (2022)</a> (<a href="https://github.com/datvuthanh/HybridNets" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://shsf0817.github.io/hdr-nerf/" target="_blank" rel="noopener noreferrer">HDR-NeRF: High Dynamic Range Neural Radiance Fields (2022)</a> (<a href="https://github.com/shsf0817/hdr-nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.16507" target="_blank" rel="noopener noreferrer">AdaMixer: A Fast-Converging Query-Based Object Detector (2022)</a> (<a href="https://github.com/MCG-NJU/AdaMixer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.11082" target="_blank" rel="noopener noreferrer">MixFormer: End-to-End Tracking with Iterative Mixed Attention (2022)</a> (<a href="https://github.com/MCG-NJU/MixFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://raywzy.com/Old_Film/" target="_blank" rel="noopener noreferrer">Bringing Old Films Back to Life (2022)</a> (<a href="https://github.com/raywzy/Bringing-Old-Films-Back-to-Life" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://nvlabs.github.io/nvdiffrec/" target="_blank" rel="noopener noreferrer">Extracting Triangular 3D Models, Materials, and Lighting From Images (2022)</a> (<a href="https://github.com/NVlabs/nvdiffrec" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.07991" target="_blank" rel="noopener noreferrer">LiT: Zero-Shot Transfer with Locked-image text Tuning (2021)</a> (<a href="https://twitter.com/giffmana/status/1508400604082806785" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://arxiv.org/abs/2111.13792" target="_blank" rel="noopener noreferrer">LAFITE: Towards Language-Free Training for Text-to-Image Generation (2021)</a> (<a href="https://github.com/drboog/Lafite" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://neural-3d-video.github.io/" target="_blank" rel="noopener noreferrer">Neural 3D Video Synthesis from Multi-view Video (2022)</a> (<a href="https://github.com/facebookresearch/Neural_3D_Video" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/tianyeli/tofu" target="_blank" rel="noopener noreferrer">ToFu: Topologically Consistent Multi-View Face Inference Using Volumetric Sampling (2021)</a></li><li><a href="https://arxiv.org/abs/1904.01786" target="_blank" rel="noopener noreferrer">Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning (2019)</a> (<a href="https://github.com/ShichenLiu/SoftRas" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/facebookresearch/frankmocap" target="_blank" rel="noopener noreferrer">FrankMocap: A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator (2021)</a></li><li><a href="https://github.com/rdeepak2002/reddit-place-script-2022" target="_blank" rel="noopener noreferrer">Reddit Place Script 2022</a> - Script to draw an image onto r/place.</li><li><a href="https://arxiv.org/abs/2108.08536" target="_blank" rel="noopener noreferrer">A Unified Objective for Novel Class Discovery (2021)</a> (<a href="https://github.com/DonkeyShot21/UNO" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/zhulf0804/3D-PointCloud" target="_blank" rel="noopener noreferrer">Papers and Datasets about Point Cloud</a></li><li><a href="https://arxiv.org/abs/2204.00613" target="_blank" rel="noopener noreferrer">On the Importance of Asymmetry for Siamese Representation Learning (2022)</a> (<a href="https://github.com/facebookresearch/asym-siam" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/yewzijian/RegTR" target="_blank" rel="noopener noreferrer">REGTR: End-to-end Point Cloud Correspondences with Transformers</a></li><li><a href="https://arxiv.org/abs/2007.01294" target="_blank" rel="noopener noreferrer">A Closer Look at Local Aggregation Operators in Point Cloud Analysis (2020)</a> (<a href="https://github.com/zeliu98/CloserLook3D" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.15355" target="_blank" rel="noopener noreferrer">Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries (2022)</a> (<a href="https://github.com/clovaai/puridiver" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.00227" target="_blank" rel="noopener noreferrer">Perception Prioritized Training of Diffusion Models (2022)</a> (<a href="https://github.com/jychoi118/P2-weighting" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1908.03557" target="_blank" rel="noopener noreferrer">VisualBERT: A Simple and Performant Baseline for Vision and Language (2019)</a> (<a href="https://github.com/uclanlp/visualbert" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.01678" target="_blank" rel="noopener noreferrer">MultiMAE: Multi-modal Multi-task Masked Autoencoders (2022)</a> (<a href="https://github.com/EPFL-VILAB/MultiMAE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.10689" target="_blank" rel="noopener noreferrer">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (2021)</a> (<a href="https://github.com/Totoro97/NeuS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.02603" target="_blank" rel="noopener noreferrer">Towards Open World Object Detection (2021)</a> (<a href="https://github.com/JosephKJ/OWOD" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/DirtyHarryLYL/Transformer-in-Vision" target="_blank" rel="noopener noreferrer">Transformer in Vision</a> - Recent Transformer-based CV and related works.</li><li><a href="https://arxiv.org/abs/2111.15193" target="_blank" rel="noopener noreferrer">Shunted Self-Attention via Multi-Scale Token Aggregation (2021)</a> (<a href="https://github.com/OliverRensu/Shunted-Transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://ajabri.github.io/videowalk/" target="_blank" rel="noopener noreferrer">Space-Time Correspondence as a Contrastive Random Walk (2020)</a> (<a href="https://github.com/ajabri/videowalk" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.04200" target="_blank" rel="noopener noreferrer">MaskGIT: Masked Generative Image Transformer (2022)</a> (<a href="https://github.com/google-research/maskgit" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/alibaba/EasyCV" target="_blank" rel="noopener noreferrer">EasyCV</a> - All-in-one computer vision toolbox based on PyTorch.</li><li><a href="https://arxiv.org/abs/2204.02964" target="_blank" rel="noopener noreferrer">Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection (2022)</a> (<a href="https://github.com/hustvl/MIMDet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/radekd91/emoca" target="_blank" rel="noopener noreferrer">EMOCA: Emotion Driven Monocular Face Capture and Animation (2022)</a></li><li><a href="https://arxiv.org/abs/2203.13161" target="_blank" rel="noopener noreferrer">Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation (2022)</a> (<a href="https://github.com/alvinliu0/HA2G" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://www.liuyebin.com/faceverse/faceverse.html" target="_blank" rel="noopener noreferrer">FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset</a> (<a href="https://github.com/LizhenWangT/FaceVerse" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.02413" target="_blank" rel="noopener noreferrer">PointCLIP: Point Cloud Understanding by CLIP (2022)</a> (<a href="https://github.com/ZrrSkywalker/PointCLIP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.03645" target="_blank" rel="noopener noreferrer">DaViT: Dual Attention Vision Transformers (2022)</a> (<a href="https://github.com/dingmyu/davit" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.04053" target="_blank" rel="noopener noreferrer">DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers (2022)</a> (<a href="https://github.com/j-min/DallEval" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.01923" target="_blank" rel="noopener noreferrer">Recovering 3D Human Mesh from Monocular Images: A Survey (2022)</a> (<a href="https://github.com/tinatiansjz/hmr-survey" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.03458v1" target="_blank" rel="noopener noreferrer">Video Diffusion Models (2022)</a> (<a href="https://video-diffusion.github.io/" target="_blank" rel="noopener noreferrer">Web</a>) (<a href="https://github.com/lucidrains/video-diffusion-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.01697" target="_blank" rel="noopener noreferrer">MaxViT: Multi-Axis Vision Transformer (2022)</a> (<a href="https://github.com/ChristophReich1996/MaxViT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.03610" target="_blank" rel="noopener noreferrer">Unified Contrastive Learning in Image-Text-Label Space (2022)</a> (<a href="https://github.com/microsoft/UniCL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.00633" target="_blank" rel="noopener noreferrer">RePOSE: Fast 6D Object Pose Refinement via Deep Texture Rendering (2021)</a> (<a href="https://github.com/sh8/RePOSE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.12579" target="_blank" rel="noopener noreferrer">MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition (2021)</a> (<a href="https://github.com/BIT-DA/MetaSAug" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.07615" target="_blank" rel="noopener noreferrer">Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (2022)</a> (<a href="https://github.com/chunbolang/BAM" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.02973" target="_blank" rel="noopener noreferrer">MAXIM: Multi-Axis MLP for Image Processing (2022)</a> (<a href="https://github.com/google-research/maxim" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://k155la3.blog/2022/04/04/tensil-tutorial-for-yolo-v4-tiny-on-ultra96-v2/" target="_blank" rel="noopener noreferrer">Tensil tutorial for YOLO v4 Tiny on Ultra96 V2 (2022)</a></li><li><a href="https://arxiv.org/abs/1909.11740" target="_blank" rel="noopener noreferrer">UNITER: UNiversal Image-TExt Representation Learning (2020)</a> (<a href="https://github.com/ChenRocks/UNITER" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://dynamic-video-depth.github.io/" target="_blank" rel="noopener noreferrer">Consistent Depth of Moving Objects in Video (2021)</a> (<a href="https://github.com/google/dynamic-video-depth" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.04850" target="_blank" rel="noopener noreferrer">Bridging Video-text Retrieval with Multiple Choice Questions (2022)</a> (<a href="https://github.com/TencentARC/MCQ" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2001.08735" target="_blank" rel="noopener noreferrer">Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation (2020)</a> (<a href="https://github.com/hytseng0509/CrossDomainFewShot" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.04645" target="_blank" rel="noopener noreferrer">BACON: Band-limited Coordinate Networks for Multiscale Scene Representation (2022)</a> (<a href="https://github.com/computational-imaging/bacon" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.03475" target="_blank" rel="noopener noreferrer">Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results (2022)</a> (<a href="https://github.com/Alibaba-MIIL/Solving_ImageNet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.vincentsitzmann.com/lfns/" target="_blank" rel="noopener noreferrer">Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering (2021)</a> (<a href="https://github.com/vsitzmann/light-field-networks" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.00928" target="_blank" rel="noopener noreferrer">SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image (2022)</a> (<a href="https://github.com/VITA-Group/SinNeRF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.01530" target="_blank" rel="noopener noreferrer">StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions (2021)</a> (<a href="https://github.com/lukasHoel/stylemesh" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.07143" target="_blank" rel="noopener noreferrer">Neighborhood Attention Transformer (2022)</a> (<a href="https://github.com/SHI-Labs/Neighborhood-Attention-Transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2102.02502" target="_blank" rel="noopener noreferrer">3D Surface Reconstruction From Multi-Date Satellite Images (2021)</a> (<a href="https://github.com/SBCV/SatelliteSurfaceReconstruction" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.02861" target="_blank" rel="noopener noreferrer">Decoupling Makes Weakly Supervised Local Feature Better (2022)</a> (<a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.14447" target="_blank" rel="noopener noreferrer">ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic (2022)</a> (<a href="https://github.com/YoadTew/zero-shot-image-to-text" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/zju3dv/EasyMocap" target="_blank" rel="noopener noreferrer">EasyMocap</a> - Open-source toolbox for markerless human motion capture from RGB videos.</li><li><a href="https://arxiv.org/abs/2203.08483" target="_blank" rel="noopener noreferrer">QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation (2022)</a> (<a href="https://github.com/sapphire497/query-selected-attention" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1909.13226" target="_blank" rel="noopener noreferrer">PolarMask: Single Shot Instance Segmentation with Polar Representation (2019)</a> (<a href="https://github.com/xieenze/PolarMask" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2006.10704" target="_blank" rel="noopener noreferrer">Latent Video Transformer (2020)</a> (<a href="https://github.com/rakhimovv/lvt" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2003.08934" target="_blank" rel="noopener noreferrer">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (2020)</a> (<a href="https://github.com/unixpickle/learn-nerf" target="_blank" rel="noopener noreferrer">JAX Code</a>)</li><li><a href="https://arxiv.org/abs/2106.11895" target="_blank" rel="noopener noreferrer">A Latent Transformer for Disentangled Face Editing in Images and Videos (2021)</a> (<a href="https://github.com/InterDigitalInc/latent-transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1903.09760" target="_blank" rel="noopener noreferrer">Photorealistic Style Transfer via Wavelet Transforms (2019)</a> (<a href="https://github.com/clovaai/WCT2" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/sayakpaul/probing-vits" target="_blank" rel="noopener noreferrer">Probing ViTs</a></li><li><a href="https://arxiv.org/abs/2112.03288" target="_blank" rel="noopener noreferrer">Dense Depth Priors for Neural Radiance Fields from Sparse Input Views (2021)</a> (<a href="https://github.com/barbararoessle/dense_depth_priors_nerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.04215" target="_blank" rel="noopener noreferrer">Self-Supervised Models are Continual Learners (2021)</a> (<a href="https://github.com/DonkeyShot21/cassle" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.vis.xyz/pub/transfiner/" target="_blank" rel="noopener noreferrer">Mask Transfiner for High-Quality Instance Segmentation (2022)</a> (<a href="https://github.com/SysCV/transfiner" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/naver-ai/vidt" target="_blank" rel="noopener noreferrer">An Extendable, Efficient and Effective Transformer-based Object Detector (2022)</a></li><li><a href="https://arxiv.org/abs/2112.11435" target="_blank" rel="noopener noreferrer">Learned Queries for Efficient Local Attention (2021)</a> (<a href="https://github.com/moabarar/qna" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.10455" target="_blank" rel="noopener noreferrer">3D Human Pose Estimation with Spatial and Temporal Transformers (2021)</a> (<a href="https://github.com/zczcwh/PoseFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1811.11742" target="_blank" rel="noopener noreferrer">3D human pose estimation in video with temporal convolutions and semi-supervised training (2019)</a> (<a href="https://github.com/facebookresearch/VideoPose3D" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314221001818" target="_blank" rel="noopener noreferrer">MC-Calib: A generic and robust calibration toolbox for multi-camera systems (2022)</a> (<a href="https://github.com/rameau-fr/MC-Calib" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2204.12451" target="_blank" rel="noopener noreferrer">Understanding The Robustness in Vision Transformers (2022)</a> (<a href="https://github.com/NVlabs/FAN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.14826" target="_blank" rel="noopener noreferrer">Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation (2021)</a> (<a href="https://github.com/liuzechun/Nonuniform-to-Uniform-Quantization" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model" target="_blank" rel="noopener noreferrer">Tackling multiple tasks with a single visual language model (2022)</a> (<a href="https://github.com/lucidrains/flamingo-pytorch" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://twitter.com/DeepMind/status/1519686445258231811" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://arxiv.org/abs/2106.02638" target="_blank" rel="noopener noreferrer">Associating Objects with Transformers for Video Object Segmentation (2021)</a> (<a href="https://github.com/z-x-yang/AOT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/xingyizhou/UniDet" target="_blank" rel="noopener noreferrer">Simple multi-dataset detection</a> - Object detection on multiple datasets with an automatically learned unified label space.</li><li><a href="https://arxiv.org/abs/2006.04139" target="_blank" rel="noopener noreferrer">Learning Texture Transformer Network for Image Super-Resolution (2020)</a> (<a href="https://github.com/researchmm/TTSR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.16427" target="_blank" rel="noopener noreferrer">Balanced MSE for Imbalanced Visual Regression (2022)</a> (<a href="https://github.com/jiawei-ren/BalancedMSE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.17234" target="_blank" rel="noopener noreferrer">Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions (2022)</a> (<a href="https://github.com/nv-nguyen/template-pose" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2104.05670" target="_blank" rel="noopener noreferrer">Action-Conditioned 3D Human Motion Synthesis with Transformer VAE (2021)</a> (<a href="https://github.com/Mathux/ACTOR" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2103.06879" target="_blank" rel="noopener noreferrer">CoMoGAN: continuous model-guided image-to-image translation (2021)</a> (<a href="https://github.com/cv-rits/CoMoGAN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cdcseacave/openMVS" target="_blank" rel="noopener noreferrer">OpenMVS</a> - Open Multi-View Stereo reconstruction library.</li><li><a href="https://arxiv.org/abs/2111.05297" target="_blank" rel="noopener noreferrer">Sliced Recursive Transformer (2021)</a> (<a href="https://github.com/szq0214/SReT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.01999" target="_blank" rel="noopener noreferrer">Neural Dual Contouring (2022)</a> (<a href="https://github.com/czq142857/NDC" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/subeeshvasu/Awesome-Deblurring" target="_blank" rel="noopener noreferrer">Awesome Deblurring</a> - Curated list of resources for Image and Video Deblurring.</li><li><a href="https://arxiv.org/abs/2205.01917" target="_blank" rel="noopener noreferrer">CoCa: Contrastive Captioners are Image-Text Foundation Models (2022)</a> (<a href="https://github.com/lucidrains/CoCa-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.01972" target="_blank" rel="noopener noreferrer">Sequencer: Deep LSTM for Image Classification (2022)</a></li><li><a href="https://arxiv.org/abs/2205.02655" target="_blank" rel="noopener noreferrer">Language Models Can See: Plugging Visual Controls in Text Generation (2022)</a> (<a href="https://github.com/yxuansu/MAGIC" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/davanstrien/flyswot" target="_blank" rel="noopener noreferrer">flyswot</a> - CLI for Hugging Face Transformers image classification models.</li><li><a href="https://zju3dv.github.io/manhattan_sdf/" target="_blank" rel="noopener noreferrer">Neural 3D Scene Reconstruction with the Manhattan-world Assumption (2022)</a> (<a href="https://github.com/zju3dv/manhattan_sdf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.15625" target="_blank" rel="noopener noreferrer">PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision (2022)</a> (<a href="https://github.com/Garfield-kh/PoseTriplet" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://twitter.com/RisingSayak/status/1515918406171914240" target="_blank" rel="noopener noreferrer">What do the Vision Transformers learn? How do they encode anything useful for image recognition? (2022)</a></li><li><a href="https://arxiv.org/abs/2203.15712" target="_blank" rel="noopener noreferrer">Integrative Few-Shot Learning for Classification and Segmentation (2022)</a> (<a href="https://github.com/dahyun-kang/ifsl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.08799" target="_blank" rel="noopener noreferrer">DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus (2022)</a> (<a href="https://github.com/rubenwiersma/deltaconv" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2012.00926" target="_blank" rel="noopener noreferrer">pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis (2021)</a> (<a href="https://github.com/lucidrains/pi-GAN-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.03052" target="_blank" rel="noopener noreferrer">Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (2022)</a> (<a href="https://github.com/OFA-Sys/OFA" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.03892" target="_blank" rel="noopener noreferrer">ConvMAE: Masked Convolution Meets Masked Autoencoders (2022)</a> (<a href="https://github.com/Alpha-VL/ConvMAE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2202.00667" target="_blank" rel="noopener noreferrer">Deep Kernelized Dense Geometric Matching (2022)</a> (<a href="https://github.com/Parskatt/DKM" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.08414" target="_blank" rel="noopener noreferrer">Unsupervised Semantic Segmentation by Distilling Feature Correspondences (2022)</a> (<a href="https://github.com/mhamilton723/STEGO" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.06844" target="_blank" rel="noopener noreferrer">RecursiveMix: Mixed Learning with History (2022)</a> (<a href="https://github.com/implus/RecursiveMix-pytorch" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/open-mmlab/mmdetection3d" target="_blank" rel="noopener noreferrer">MMDetection3d</a> - OpenMMLab&#x27;s next-generation platform for general 3D object detection.</li><li><a href="https://imagen.research.google/" target="_blank" rel="noopener noreferrer">Imagen: Text-to-Image Diffusion Models</a> (<a href="https://twitter.com/JeffDean/status/1528951937948741632" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://github.com/lucidrains/imagen-pytorch" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://news.ycombinator.com/item?id=31484562" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://news.ycombinator.com/item?id=31513919" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2109.08141" target="_blank" rel="noopener noreferrer">An End-to-End Transformer Model for 3D Object Detection (2021)</a> (<a href="https://github.com/facebookresearch/3detr" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.12955" target="_blank" rel="noopener noreferrer">Neural 3D Reconstruction in the Wild (2022)</a> (<a href="https://github.com/zju3dv/NeuralRecon-W" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/maria-korosteleva/Body-Shape-Estimation" target="_blank" rel="noopener noreferrer">Body shape and pose estimation on 3D scans of people in clothing using Ceres Solver</a></li><li><a href="https://arxiv.org/abs/2111.06091" target="_blank" rel="noopener noreferrer">A Survey of Visual Transformers (2021)</a> (<a href="https://github.com/liuyang-ict/awesome-visual-transformers" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://nerfies.github.io/" target="_blank" rel="noopener noreferrer">Nerfies: Deformable Neural Radiance Fields (2021)</a> (<a href="https://github.com/nerfies/nerfies.github.io" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://scienceplusplus.org/visions/index.html" target="_blank" rel="noopener noreferrer">Working notes on the role of vision papers in basic science (2022)</a> (<a href="https://twitter.com/michael_nielsen/status/1530659395453202433" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/THUDM/CogVideo" target="_blank" rel="noopener noreferrer">CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers (2022)</a> (<a href="https://news.ycombinator.com/item?id=31561845" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2205.14865" target="_blank" rel="noopener noreferrer">Prompt-aligned Gradient for Prompt Tuning (2022)</a> (<a href="https://github.com/BeierZhu/Prompt-align" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.15996" target="_blank" rel="noopener noreferrer">Text2Human: Text-Driven Controllable Human Image Generation (2022)</a> (<a href="https://github.com/yumingj/Text2Human" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.12257" target="_blank" rel="noopener noreferrer">OnePose: One-Shot Object Pose Estimation without CAD Models (2022)</a> (<a href="https://github.com/zju3dv/OnePose" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2205.13524" target="_blank" rel="noopener noreferrer">PREF: Phasorial Embedding Fields for Compact Neural Representations (2022)</a> (<a href="https://github.com/hbb1/PREF" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2206.01161" target="_blank" rel="noopener noreferrer">Optimizing Relevance Maps of Vision Transformers Improves Robustness (2022)</a> (<a href="https://github.com/hila-chefer/RobustViT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.17274" target="_blank" rel="noopener noreferrer">Exploring Visual Prompts for Adapting Large-Scale Models (2022)</a> (<a href="https://github.com/hjbahng/visual_prompting" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/sensity-ai/dot" target="_blank" rel="noopener noreferrer">Deepfake Offensive Toolkit</a> - Makes real-time, controllable deepfakes ready for virtual cameras injection. (<a href="https://news.ycombinator.com/item?id=31650797" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2203.12338" target="_blank" rel="noopener noreferrer">Real-time Object Detection for Streaming Perception (2022)</a> (<a href="https://github.com/yancie-yjr/StreamYOLO" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/ZFTurbo/volumentations" target="_blank" rel="noopener noreferrer">Volumentations 3D</a> - Library for 3D augmentations.</li><li><a href="https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise" target="_blank" rel="noopener noreferrer">Awesome Learning with Label Noise</a></li><li><a href="https://ma-xu.github.io/LIVE/" target="_blank" rel="noopener noreferrer">LIVE: Towards Layer-wise Image Vectorization (2022)</a> (<a href="https://github.com/ma-xu/LIVE" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2112.01529" target="_blank" rel="noopener noreferrer">BEVT: BERT Pretraining of Video Transformers (2021)</a> (<a href="https://github.com/xyzforever/BEVT" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://nv-tlabs.github.io/vqad/" target="_blank" rel="noopener noreferrer">Variable Bitrate Neural Fields (2022)</a> (<a href="https://github.com/nv-tlabs/vqad" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1907.05740" target="_blank" rel="noopener noreferrer">Gated-SCNN: Gated Shape CNNs for Semantic Segmentation (2019)</a> (<a href="https://github.com/nv-tlabs/GSCNN" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2206.02967" target="_blank" rel="noopener noreferrer">Masked Unsupervised Self-training for Zero-shot Image Classification (2022)</a> (<a href="https://github.com/salesforce/MUST" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.04127" target="_blank" rel="noopener noreferrer">HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video (2022)</a> (<a href="https://github.com/chungyiweng/humannerf" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics" target="_blank" rel="noopener noreferrer">Awesome Implicit NeRF Robotics</a></li><li><a href="https://arxiv.org/abs/2206.01191" target="_blank" rel="noopener noreferrer">EfficientFormer: Vision Transformers at MobileNet Speed (2022)</a> (<a href="https://github.com/snap-research/EfficientFormer" target="_blank" rel="noopener noreferrer">Code</a>)</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/ecioran/kinderheim/docs/computer-graphics/computer-vision/computer-vision.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vbeJ"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/kinderheim/computer-graphics/bezier-curves"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Bézier curves</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/kinderheim/computer-graphics/computer-vision/ocr"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Optical character recognition</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#links" class="table-of-contents__link toc-highlight">Links</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/kinderheim/assets/js/runtime~main.92f61fd9.js"></script>
<script src="/kinderheim/assets/js/main.b95d4106.js"></script>
</body>
</html>
<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-machine-learning/reinforcement-learning">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.21">
<title data-rh="true">Reinforcement learning | Learning Resources</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://github.com/kinderheim/machine-learning/reinforcement-learning"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Reinforcement learning | Learning Resources"><meta data-rh="true" name="description" content="Acme, TorchRL &amp; Ray seem nice. Hugging Face Deep Reinforcement Learning Class is great intro."><meta data-rh="true" property="og:description" content="Acme, TorchRL &amp; Ray seem nice. Hugging Face Deep Reinforcement Learning Class is great intro."><link data-rh="true" rel="icon" href="/kinderheim/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://github.com/kinderheim/machine-learning/reinforcement-learning"><link data-rh="true" rel="alternate" href="https://github.com/kinderheim/machine-learning/reinforcement-learning" hreflang="en"><link data-rh="true" rel="alternate" href="https://github.com/kinderheim/machine-learning/reinforcement-learning" hreflang="x-default"><link rel="stylesheet" href="/kinderheim/assets/css/styles.45761c4f.css">
<link rel="preload" href="/kinderheim/assets/js/runtime~main.1ffb19eb.js" as="script">
<link rel="preload" href="/kinderheim/assets/js/main.b238a0af.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/kinderheim/"><div class="navbar__logo"><img src="/kinderheim/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/kinderheim/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Resources</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/ecioran/kinderheim" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/3d-printing/">3D Printing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/analytics/">Analytics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Analytics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/anki/">Anki</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/api/">API</a><button aria-label="Toggle the collapsible sidebar category &#x27;API&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/art/">Art</a><button aria-label="Toggle the collapsible sidebar category &#x27;Art&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/augmented-reality/">Augmented Reality</a><button aria-label="Toggle the collapsible sidebar category &#x27;Augmented Reality&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/automation/">Automation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Automation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/backups/">Backups</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/biology/">Biology</a><button aria-label="Toggle the collapsible sidebar category &#x27;Biology&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/books/">Books</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/business/">Business</a><button aria-label="Toggle the collapsible sidebar category &#x27;Business&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/chemistry/">Chemistry</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cli/">Command Line Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Command Line Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cloud-computing/">Cloud computing</a><button aria-label="Toggle the collapsible sidebar category &#x27;Cloud computing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/code/">Code</a><button aria-label="Toggle the collapsible sidebar category &#x27;Code&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/compilers/">Compilers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Compilers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/computer-graphics/">Computer graphics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer graphics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/computer-science/">Computer Science</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer Science&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/consciousness/">Consciousness</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/courses/">Courses</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/cryptocurrencies/">Cryptocurrencies</a><button aria-label="Toggle the collapsible sidebar category &#x27;Cryptocurrencies&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/data-science/">Data Science</a><button aria-label="Toggle the collapsible sidebar category &#x27;Data Science&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/databases/">Databases</a><button aria-label="Toggle the collapsible sidebar category &#x27;Databases&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/design/">Design</a><button aria-label="Toggle the collapsible sidebar category &#x27;Design&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/devops/">DevOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/distributed-systems/">Distributed systems</a><button aria-label="Toggle the collapsible sidebar category &#x27;Distributed systems&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/documentaries/">Documentaries</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/education/">Education</a><button aria-label="Toggle the collapsible sidebar category &#x27;Education&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/future/">Future</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/hardware/">Hardware</a><button aria-label="Toggle the collapsible sidebar category &#x27;Hardware&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/history/">History</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/">Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/latex/">LaTeX</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/kinderheim/machine-learning/">Machine learning</a><button aria-label="Toggle the collapsible sidebar category &#x27;Machine learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/artificial-intelligence">Artificial intelligence</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/autonomous-driving">Autonomous driving</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/datasets">Datasets</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/kinderheim/machine-learning/libraries/jax">libraries</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/ml-models">ML Models</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/kinderheim/machine-learning/neural-networks/">Neural networks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Neural networks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/kinderheim/machine-learning/reinforcement-learning">Reinforcement learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/transfer-learning">Transfer learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kinderheim/machine-learning/unsupervised-learning">Unsupervised learning</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/math/">Math</a><button aria-label="Toggle the collapsible sidebar category &#x27;Math&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/networking/">Networking</a><button aria-label="Toggle the collapsible sidebar category &#x27;Networking&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/neuroscience/">Neuroscience</a><button aria-label="Toggle the collapsible sidebar category &#x27;Neuroscience&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/nlp/">Natural language processing</a><button aria-label="Toggle the collapsible sidebar category &#x27;Natural language processing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/philosophy/">Philosophy</a><button aria-label="Toggle the collapsible sidebar category &#x27;Philosophy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/physics/">Physics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Physics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/privacy/">Privacy</a><button aria-label="Toggle the collapsible sidebar category &#x27;Privacy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/programming/">Programming</a><button aria-label="Toggle the collapsible sidebar category &#x27;Programming&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/research/">Research</a><button aria-label="Toggle the collapsible sidebar category &#x27;Research&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/research-papers/">Research papers</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/robots/">Robots</a><button aria-label="Toggle the collapsible sidebar category &#x27;Robots&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/security/">Security</a><button aria-label="Toggle the collapsible sidebar category &#x27;Security&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/space/">Space</a><button aria-label="Toggle the collapsible sidebar category &#x27;Space&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/kinderheim/virtual-reality/">Virtual reality</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/kinderheim/web/">Web</a><button aria-label="Toggle the collapsible sidebar category &#x27;Web&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_GujU"><div class="docItemContainer_Adtb"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/kinderheim/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/kinderheim/machine-learning/"><span itemprop="name">Machine learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Reinforcement learning</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_aoJ5"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1><a href="http://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank" rel="noopener noreferrer">Reinforcement learning</a></h1><p><a href="https://github.com/deepmind/acme" target="_blank" rel="noopener noreferrer">Acme</a>, <a href="https://github.com/facebookresearch/rl" target="_blank" rel="noopener noreferrer">TorchRL</a> &amp; <a href="https://github.com/ray-project/ray" target="_blank" rel="noopener noreferrer">Ray</a> seem nice. <a href="https://github.com/huggingface/deep-rl-class" target="_blank" rel="noopener noreferrer">Hugging Face Deep Reinforcement Learning Class</a> is great intro.</p><p><a href="https://dannydriess.github.io/nerf-rl/" target="_blank" rel="noopener noreferrer">Reinforcement Learning with Neural Radiance Fields</a> is fascinating.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="links">Links<a class="hash-link" href="#links" title="Direct link to heading">​</a></h2><ul><li><a href="https://www.reddit.com/r/MachineLearning/comments/7ui8jv/d_where_to_start_learning_reinforcement_learning/" target="_blank" rel="noopener noreferrer">Where to start learning Reinforcement Learning in 2018?</a></li><li><a href="https://mitpress.mit.edu/books/reinforcement-learning-second-edition" target="_blank" rel="noopener noreferrer">Reinforcement Learning, An Introduction Book</a> - Significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. (<a href="http://incompleteideas.net/book/the-book-2nd.html" target="_blank" rel="noopener noreferrer">Web</a>) (<a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningAnIntroduction.jl" target="_blank" rel="noopener noreferrer">Julia Code</a>) (<a href="https://www.youtube.com/playlist?list=PLerZSPM4UM7LMM52BQh0dhcMnjk9qpaRl" target="_blank" rel="noopener noreferrer">Video Summary</a>)</li><li><a href="https://github.com/dennybritz/reinforcement-learning" target="_blank" rel="noopener noreferrer">Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, TensorFlow. Exercises and Solutions to accompany Sutton&#x27;s Book and David Silver&#x27;s course.</a></li><li><a href="https://www.youtube.com/watch?v=WFCzLZKVs44" target="_blank" rel="noopener noreferrer">Learning to Learn for Robotic Control - Prof. Pieter Abbeel</a></li><li><a href="https://www.youtube.com/watch?v=9EN_HoEk3KY" target="_blank" rel="noopener noreferrer">MIT AGI: OpenAI Meta-Learning and Self-Play (Ilya Sutskever)</a></li><li><a href="https://mpatacchiola.github.io/blog/2016/12/09/dissecting-reinforcement-learning.html" target="_blank" rel="noopener noreferrer">Dissecting Reinforcement Learning: Part 1</a></li><li><a href="https://blog.openai.com/learning-dexterity/" target="_blank" rel="noopener noreferrer">Learning Dexterity (2018)</a></li><li><a href="https://github.com/google/dopamine" target="_blank" rel="noopener noreferrer">Dopamine</a> - Research framework for fast prototyping of reinforcement learning algorithms.</li><li><a href="https://github.com/openai/spinningup" target="_blank" rel="noopener noreferrer">Spinning Up in Deep RL</a> - Educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL). (<a href="https://spinningup.openai.com/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>) (<a href="https://news.ycombinator.com/item?id=24184270" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://github.com/Kaixhin/spinning-up-basic" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs" target="_blank" rel="noopener noreferrer">Advanced Deep Learning &amp; Reinforcement Learning Course (2018)</a></li><li><a href="https://github.com/openai/gym" target="_blank" rel="noopener noreferrer">OpenAI Gym</a> - Toolkit for developing and comparing reinforcement learning algorithms.</li><li><a href="https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python" target="_blank" rel="noopener noreferrer">Hands-On Reinforcement Learning With Python book</a></li><li><a href="https://github.com/dalmia/David-Silver-Reinforcement-learning" target="_blank" rel="noopener noreferrer">David Silver Reinforcement learning</a> - Notes for the Reinforcement Learning course by David Silver along with implementation of various algorithms.</li><li><a href="https://github.com/LantaoYu/MARL-Papers" target="_blank" rel="noopener noreferrer">Paper Collection of Multi-Agent Reinforcement Learning (MARL)</a></li><li><a href="https://github.com/r0zetta/MARL" target="_blank" rel="noopener noreferrer">MARL (Multi-Agent Reinforcement Learning Experiments)</a></li><li><a href="https://ray.readthedocs.io/en/latest/rllib.html" target="_blank" rel="noopener noreferrer">RLlib</a> - Open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications.</li><li><a href="https://github.com/hill-a/stable-baselines" target="_blank" rel="noopener noreferrer">Stable Baselines</a> - Set of improved implementations of reinforcement learning algorithms based on OpenAI Baselines.</li><li><a href="https://github.com/ikostrikov/pytorch-a3c" target="_blank" rel="noopener noreferrer">pytorch-a3c</a> - PyTorch implementation of Asynchronous Advantage Actor Critic (A3C) from &quot;Asynchronous Methods for Deep Reinforcement Learning&quot;.</li><li><a href="https://www.youtube.com/watch?v=3N9phq_yZP0" target="_blank" rel="noopener noreferrer">The Power of Self-Learning Systems (2019)</a></li><li><a href="https://github.com/jason718/awesome-self-supervised-learning" target="_blank" rel="noopener noreferrer">Awesome Self-Supervised Learning</a></li><li><a href="https://github.com/Kaixhin/PlaNet" target="_blank" rel="noopener noreferrer">PlaNet</a> - Deep Planning Network: Control from pixels by latent planning with learned dynamics.</li><li><a href="https://github.com/hzwer/LearningToPaint" target="_blank" rel="noopener noreferrer">Learning to Paint</a> - Painting AI that can reproduce paintings stroke by stroke using deep reinforcement learning.</li><li><a href="https://project.inria.fr/paiss/files/2018/07/zisserman-self-supervised.pdf" target="_blank" rel="noopener noreferrer">Self-Supervised Learning</a> (<a href="https://news.ycombinator.com/item?id=20195575" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/araffin/rl-baselines-zoo" target="_blank" rel="noopener noreferrer">RL Baselines Zoo</a> - Collection of 100+ pre-trained RL agents using Stable Baselines, training and hyperparameter optimization included.</li><li><a href="https://github.com/deepmind/bsuite" target="_blank" rel="noopener noreferrer">bsuite</a> - Collection of carefully-designed experiments that investigate core capabilities of a reinforcement learning (RL) agent.</li><li><a href="https://github.com/deepmind/open_spiel" target="_blank" rel="noopener noreferrer">OpenSpiel</a> - Collection of environments and algorithms for research in general reinforcement learning and search/planning in games.</li><li><a href="https://github.com/facebookresearch/slbo" target="_blank" rel="noopener noreferrer">Stochastic Lower Bound Optimization</a> - Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees.</li><li><a href="https://github.com/lightvector/KataGo" target="_blank" rel="noopener noreferrer">KataGo</a> - Research and experimentation with self-play training in Go.</li><li><a href="https://github.com/catalyst-team/catalyst" target="_blank" rel="noopener noreferrer">Catalyst</a> - Reproducible and fast DL &amp; RL.</li><li><a href="https://www.youtube.com/watch?v=rOiaZ1hVb-A" target="_blank" rel="noopener noreferrer">The Mathematics of AlphaGo (2019)</a></li><li><a href="https://arxiv.org/abs/1707.03497" target="_blank" rel="noopener noreferrer">Value Prediction Network (2017)</a></li><li><a href="https://arxiv.org/abs/1911.08265" target="_blank" rel="noopener noreferrer">Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (2019)</a> (<a href="https://www.reddit.com/r/MachineLearning/comments/dzakrs/r_191108265_mastering_atari_go_chess_and_shogi_by/" target="_blank" rel="noopener noreferrer">Reddit</a>) (<a href="https://venturebeat.com/2019/11/20/deepminds-muzero-teaches-itself-how-to-win-at-atari-chess-shogi-and-go/" target="_blank" rel="noopener noreferrer">Article</a>)</li><li><a href="https://github.com/sfujim/BCQ" target="_blank" rel="noopener noreferrer">BCQ</a> - PyTorch implementation of BCQ for &quot;Off-Policy Deep Reinforcement Learning without Exploration&quot;.</li><li><a href="https://rltheorybook.github.io/" target="_blank" rel="noopener noreferrer">Reinforcement Learning: Theory and Algorithms</a> (<a href="https://news.ycombinator.com/item?id=27565421" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/facebookresearch/torchbeast" target="_blank" rel="noopener noreferrer">TorchBeast</a> - PyTorch Platform for Distributed RL.</li><li><a href="https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/" target="_blank" rel="noopener noreferrer">The Promise of Hierarchical Reinforcement Learning (2019)</a></li><li><a href="https://github.com/astooke/rlpyt" target="_blank" rel="noopener noreferrer">rlpyt</a> - Reinforcement Learning in PyTorch.</li><li><a href="https://github.com/astooke/accel_rl" target="_blank" rel="noopener noreferrer">Accelerated Methods for Deep Reinforcement Learning</a></li><li><a href="https://blog.acolyer.org/2020/01/15/programmatically-interpretable-reinforcement-learning/" target="_blank" rel="noopener noreferrer">Programmatically interpretable reinforcement learning (2020)</a></li><li><a href="https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html" target="_blank" rel="noopener noreferrer">Curriculum for Reinforcement Learning (2020)</a></li><li><a href="https://github.com/deepmind/rlax" target="_blank" rel="noopener noreferrer">RLax</a> - Library built on top of JAX that exposes useful building blocks for implementing reinforcement learning agents.</li><li><a href="https://github.com/kristery/Awesome-Imitation-Learning" target="_blank" rel="noopener noreferrer">Curated list of awesome imitation learning resources and publications</a></li><li><a href="https://github.com/medipixel/rl_algorithms" target="_blank" rel="noopener noreferrer">Structural implementation of RL key algorithms</a></li><li><a href="https://github.com/williamFalcon/DeepRLHacks" target="_blank" rel="noopener noreferrer">DeepRLHacks</a> - Hacks for training RL systems from John Schulman&#x27;s lecture at Deep RL Bootcamp.</li><li><a href="https://github.com/Machine-Learning-Tokyo/AI_Curriculum" target="_blank" rel="noopener noreferrer">Open Deep Learning and Reinforcement Learning lectures from top Universities like Stanford University, MIT, UC Berkeley</a></li><li><a href="https://github.com/pranz24/pytorch-soft-actor-critic" target="_blank" rel="noopener noreferrer">PyTorch implementation of soft actor critic</a></li><li><a href="https://github.com/RobertTLange/deep-rl-tutorial" target="_blank" rel="noopener noreferrer">Tutorial on Deep Reinforcement Learning in PyTorch</a></li><li><a href="https://github.com/mcgillmrl/prob_mbrl" target="_blank" rel="noopener noreferrer">prob_mbrl</a> - Library of probabilistic model based RL algorithms in pytorch.</li><li><a href="https://github.com/Tencent/PhoenixGo" target="_blank" rel="noopener noreferrer">PhoenixGo</a> - Go AI program which implements the AlphaGo Zero paper.</li><li><a href="https://github.com/tensortrade-org/tensortrade" target="_blank" rel="noopener noreferrer">TensorTrade</a> - Trade Efficiently with Reinforcement Learning.</li><li><a href="https://towardsdatascience.com/en-lightning-reinforcement-learning-a155c217c3de" target="_blank" rel="noopener noreferrer">En-Lightning Reinforcement Learning (2020)</a> - Building a DQN with PyTorch Lightning.</li><li><a href="https://github.com/lvwerra/trl" target="_blank" rel="noopener noreferrer">Transformer Reinforcement Learning</a> - Train transformer language models with reinforcement learning.</li><li><a href="https://www.youtube.com/watch?v=x5Q79XCxMVc" target="_blank" rel="noopener noreferrer">David Silver - Deep Reinforcement Learning from AlphaGo to AlphaStar (2020)</a></li><li><a href="https://github.com/jonathan-laurent/AlphaZero.jl" target="_blank" rel="noopener noreferrer">AlphaZero.jl</a> - Generic, simple and fast implementation of Deepmind&#x27;s AlphaZero algorithm. (<a href="https://news.ycombinator.com/item?id=23599278" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/openai/multiagent-particle-envs" target="_blank" rel="noopener noreferrer">Multi-Agent Particle Environment</a></li><li><a href="https://arxiv.org/abs/2004.04136" target="_blank" rel="noopener noreferrer">CURL: Contrastive Unsupervised Representations for Reinforcement Learning (2020)</a> (<a href="https://github.com/MishaLaskin/curl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="http://www.cs.cmu.edu/%7Eninamf/pubs-by-year.html" target="_blank" rel="noopener noreferrer">Maria-Florina Balcan&#x27;s publications</a></li><li><a href="https://ai.googleblog.com/2020/04/an-optimistic-perspective-on-offline.html" target="_blank" rel="noopener noreferrer">An Optimistic Perspective on Offline Reinforcement Learning (2020)</a></li><li><a href="https://bair.berkeley.edu/blog/2020/12/07/offline/" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning: How Conservative Algorithms Can Enable New Applications (2020)</a></li><li><a href="https://github.com/TensorSwarm/TensorSwarm" target="_blank" rel="noopener noreferrer">TensorSwarm</a> - Framework for reinforcement learning of robot swarms.</li><li><a href="https://github.com/leonardblier/alrao" target="_blank" rel="noopener noreferrer">Learning with Random Learning Rates in PyTorch</a></li><li><a href="https://github.com/optimass/continual_learning_papers" target="_blank" rel="noopener noreferrer">Continual Learning Literature</a></li><li><a href="https://arxiv.org/abs/2002.11523" target="_blank" rel="noopener noreferrer">Using Reinforcement Learning in the Algorithmic Trading Problem (2020)</a> (<a href="https://news.ycombinator.com/item?id=23022864" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://bair.berkeley.edu/blog/2020/05/01/umrl/" target="_blank" rel="noopener noreferrer">Unsupervised Meta-Learning: Learning to Learn without Supervision (2020)</a></li><li><a href="https://github.com/scikit-learn-contrib/metric-learn" target="_blank" rel="noopener noreferrer">metric-learn</a> - Metric Learning in Python.</li><li><a href="https://sites.google.com/view/data-regularized-q" target="_blank" rel="noopener noreferrer">Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels</a> (<a href="https://github.com/denisyarats/drq" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/tensorlayer/RLzoo" target="_blank" rel="noopener noreferrer">Reinforcement Learning Zoo</a> - Collection of the most practical reinforcement learning algorithms, frameworks and applications.</li><li><a href="https://blog.einstein.ai/the-ai-economist/" target="_blank" rel="noopener noreferrer">The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies (2020)</a> (<a href="https://arxiv.org/abs/2004.13332" target="_blank" rel="noopener noreferrer">Paper</a>) (<a href="https://twitter.com/RichardSocher/status/1255554801510674432" target="_blank" rel="noopener noreferrer">Twitter</a>)</li><li><a href="https://github.com/doerlbh/mentalRL" target="_blank" rel="noopener noreferrer">mentalRL</a> - A Story of Two Streams: Reinforcement Learning Models from Human Behavior and Neuropsychiatry.</li><li><a href="https://github.com/rolyatmax/tictactoe" target="_blank" rel="noopener noreferrer">Reinforcement Learning With TicTacToe</a></li><li><a href="https://github.com/NervanaSystems/coach" target="_blank" rel="noopener noreferrer">Coach</a> - Python reinforcement learning framework containing implementation of many state-of-the-art algorithms.</li><li><a href="https://papers.nips.cc/paper/9556-reinforcement-learning-with-convex-constraints.pdf" target="_blank" rel="noopener noreferrer">Reinforcement Learning with Convex Constraints (2019)</a> (<a href="https://github.com/xkianteb/ApproPO" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://deepmind.com/research/publications/Acme" target="_blank" rel="noopener noreferrer">Acme: A new framework for distributed reinforcement learning | DeepMind (2020)</a> (<a href="https://github.com/deepmind/acme" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://towardsdatascience.com/deepminds-reinforcement-learning-framework-acme-87934fa223bf" target="_blank" rel="noopener noreferrer">Intro</a>)</li><li><a href="https://github.com/hardmaru/slimevolleygym" target="_blank" rel="noopener noreferrer">Slime Volleyball Gym Environment</a> - Simple OpenAI Gym environment for single and multi-agent reinforcement learning.</li><li><a href="https://github.com/eleurent/phd-bibliography" target="_blank" rel="noopener noreferrer">References on Optimal Control, Reinforcement Learning and Motion Planning</a></li><li><a href="https://github.com/facebookresearch/nle" target="_blank" rel="noopener noreferrer">NetHack Learning Environment (NLE)</a> - Reinforcement Learning environment based on NetHack 3.6.</li><li><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Rao_RL-CycleGAN_Reinforcement_Learning_Aware_Simulation-to-Real_CVPR_2020_paper.pdf" target="_blank" rel="noopener noreferrer">RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real (2020)</a></li><li><a href="https://arxiv.org/abs/2004.07928" target="_blank" rel="noopener noreferrer">MARLeME: A Multi-Agent Reinforcement Learning Model Extraction Library (2020)</a></li><li><a href="https://github.com/maximecb/gym-minigrid" target="_blank" rel="noopener noreferrer">Minimalistic Gridworld Environment (MiniGrid)</a></li><li><a href="https://github.com/mfranzs/meta-learning-curiosity-algorithms" target="_blank" rel="noopener noreferrer">Meta-Learning Curiosity Algorithms</a></li><li><a href="https://github.com/eaplatanios/swift-rl" target="_blank" rel="noopener noreferrer">Reinforcement Learning in Swift</a></li><li><a href="https://github.com/deepmind/dm_env" target="_blank" rel="noopener noreferrer">dm_env</a> - DeepMind RL Environment API.</li><li><a href="https://github.com/SurrealAI/surreal" target="_blank" rel="noopener noreferrer">SURREAL</a> - Fully integrated framework that runs state-of-the-art distributed reinforcement learning (RL) algorithms.</li><li><a href="https://www.reddit.com/r/reinforcementlearning/comments/hnebb8/i_need_suggestions_on_good_rl_courses/" target="_blank" rel="noopener noreferrer">Suggestions of good RL courses (2020)</a></li><li><a href="https://arxiv.org/abs/2006.04734" target="_blank" rel="noopener noreferrer">Reinforcement Learning Under Moral Uncertainty (2020)</a> (<a href="https://www.reddit.com/r/MachineLearning/comments/hslstp/r_reinforcement_learning_under_moral_uncertainty/" target="_blank" rel="noopener noreferrer">Reddit</a>) (<a href="https://github.com/uber-research/normative-uncertainty" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1901.10995" target="_blank" rel="noopener noreferrer">Go-Explore: a New Approach for Hard-Exploration Problems (2019)</a> (<a href="https://github.com/uber-research/go-explore" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html" target="_blank" rel="noopener noreferrer">Neural Architecture Search (2020)</a></li><li><a href="https://github.com/fabiopardo/qmap" target="_blank" rel="noopener noreferrer">Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks</a></li><li><a href="https://github.com/fabiopardo/tonic" target="_blank" rel="noopener noreferrer">Tonic</a> - Deep reinforcement learning library.</li><li><a href="https://github.com/WilsonWangTHU/mbbl" target="_blank" rel="noopener noreferrer">Model Based Reinforcement Learning Benchmarking Library (MBBL)</a></li><li><a href="https://github.com/tensorflow/agents" target="_blank" rel="noopener noreferrer">TF-Agents</a> - Reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.</li><li><a href="https://www.coursera.org/specializations/reinforcement-learning" target="_blank" rel="noopener noreferrer">Reinforcement Learning Specialization by University of Alberta</a></li><li><a href="https://github.com/deepmind/optax" target="_blank" rel="noopener noreferrer">Optax</a> - Gradient processing and optimization library for JAX.</li><li><a href="https://github.com/deepmind/chex" target="_blank" rel="noopener noreferrer">Chex</a> - Library of utilities for helping to write reliable JAX code.</li><li><a href="https://arxiv.org/abs/2003.03600" target="_blank" rel="noopener noreferrer">Reinforcement Learning for Combinatorial Optimization: A Survey (2020)</a></li><li><a href="https://github.com/SforAiDl/genrl" target="_blank" rel="noopener noreferrer">GenRL</a> - PyTorch reinforcement learning library centered around reproducible and generalizable algorithm implementations. (<a href="https://news.ycombinator.com/item?id=24292339" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://genrl.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>) (<a href="https://genrl.readthedocs.io/en/latest/usage/tutorials/index.html" target="_blank" rel="noopener noreferrer">Tutorials</a>) (<a href="https://www.reddit.com/r/reinforcementlearning/comments/ihibey/genrl_pytorchfirst_reinforcement_learning_library/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://github.com/DLR-RM/stable-baselines3" target="_blank" rel="noopener noreferrer">Stable Baselines3</a> - PyTorch version of Stable Baselines, improved implementations of reinforcement learning algorithms.</li><li><a href="https://github.com/tensorflow/minigo" target="_blank" rel="noopener noreferrer">Minigo</a> - Minimalist Go engine modeled after AlphaGo Zero, built on MuGo.</li><li><a href="https://flowing.systems/2020/09/15/reinforcement-learning-non-markov-memory.html" target="_blank" rel="noopener noreferrer">Reinforcement learning, non-Markov environments, and memory (2020)</a></li><li><a href="https://mathy.ai/" target="_blank" rel="noopener noreferrer">Mathy</a> - Platform for using computer algebra systems to solve math problems step-by-step with reinforcement learning. (<a href="https://github.com/justindujardin/mathy/" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/microsoft/maro" target="_blank" rel="noopener noreferrer">Multi-Agent Resource Optimization (MARO)</a> - Instance of Reinforcement Learning as a Service (RaaS) for real-world resource optimization.</li><li><a href="https://hunch.net/?p=13762683" target="_blank" rel="noopener noreferrer">Homer: Provable Exploration in Reinforcement Learning (2020)</a></li><li><a href="https://github.com/datamllab/rlcard" target="_blank" rel="noopener noreferrer">RLCard</a> - Toolkit for Reinforcement Learning in Card Games.</li><li><a href="https://simoninithomas.github.io/deep-rl-course/" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Course (2020)</a> (<a href="https://github.com/simoninithomas/Deep_reinforcement_learning_Course" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/cool-RR/grid_royale" target="_blank" rel="noopener noreferrer">GridRoyale</a> - Life simulation for exploring social dynamics. (<a href="https://news.ycombinator.com/item?id=24744437" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/RchalYang/torchrl" target="_blank" rel="noopener noreferrer">TorchRL</a> - PyTorch Implementation of Reinforcement Learning Algorithms.</li><li><a href="https://bair.berkeley.edu/blog/2020/10/13/supervised-rl/" target="_blank" rel="noopener noreferrer">Reinforcement learning is supervised learning on optimized data (2020)</a> (<a href="https://news.ycombinator.com/item?id=24771856" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/TianhongDai/reinforcement-learning-algorithms" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Algorithms</a></li><li><a href="https://www.youtube.com/watch?v=xMZE-9WECQE" target="_blank" rel="noopener noreferrer">Introduction to Reinforcement Learning (2020)</a> (<a href="https://colab.research.google.com/github/psc-g/intro_to_rl/blob/master/Introduction_to_reinforcement_learning.ipynb" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/deepmind/ai-safety-gridworlds" target="_blank" rel="noopener noreferrer">AI safety gridworlds</a> - Suite of reinforcement learning environments illustrating various safety properties of intelligent agents.</li><li><a href="https://github.com/EliorBenYosef/reinforcement-learning" target="_blank" rel="noopener noreferrer">RL and Deep-RL implementations</a></li><li><a href="https://npdeep.github.io/cartpole-without-reinforcement-learning.html" target="_blank" rel="noopener noreferrer">You don&#x27;t need reinforcement learning when you have basic physics (2020)</a> (<a href="https://news.ycombinator.com/item?id=24795953" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/tensorlayer/tensorlayer" target="_blank" rel="noopener noreferrer">TensorLayer</a> - Deep Learning and Reinforcement Learning Library for Scientists and Engineers. (<a href="https://tensorlayer.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/FitMachineLearning/FitML" target="_blank" rel="noopener noreferrer">FitML</a> - Collection of python Machine Learning articles and examples.</li><li><a href="https://github.com/greentfrapp/pysc2-RLagents" target="_blank" rel="noopener noreferrer">Notes and scripts for SC2LE released by DeepMind and Blizzard</a></li><li><a href="https://github.com/pfnet/pfrl" target="_blank" rel="noopener noreferrer">PFRL</a> - PyTorch-based deep reinforcement learning library.</li><li><a href="https://github.com/muupan/deep-reinforcement-learning-papers" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Papers</a></li><li><a href="https://github.com/chainer/chainerrl" target="_blank" rel="noopener noreferrer">ChainerRL</a> - Deep reinforcement learning library built on top of Chainer.</li><li><a href="https://github.com/facebookresearch/impact-driven-exploration" target="_blank" rel="noopener noreferrer">RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments</a></li><li><a href="https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses" target="_blank" rel="noopener noreferrer">Best Reinforcement Learning Tutorials, Examples, Projects, and Courses (2020)</a></li><li><a href="https://github.com/rasmusbergpalm/evostrat" target="_blank" rel="noopener noreferrer">EvoStrat</a> - Library that makes Evolutionary Strategies (ES) simple to use.</li><li><a href="https://github.com/cgreer/alpha-zero-boosted" target="_blank" rel="noopener noreferrer">Alpha Zero Boosted</a> - &quot;build to learn&quot; implementation of the Alpha Zero algorithm written in Python that uses LightGBM (Gradient Boosted Decision Trees) in place of a Deep Neural Network for value/policy functions.</li><li><a href="https://github.com/huawei-noah/xingtian" target="_blank" rel="noopener noreferrer">XingTian</a> - Componentized library for the development and verification of reinforcement learning algorithms.</li><li><a href="https://www.youtube.com/watch?v=_-aeyeBYz1s" target="_blank" rel="noopener noreferrer">Theoretical Foundations of Reinforcement Learning (2020)</a></li><li><a href="https://github.com/zuoxingdong/mazelab" target="_blank" rel="noopener noreferrer">mazelab</a> - Customizable framework to create maze and gridworld environments.</li><li><a href="https://github.com/sfujim/TD3" target="_blank" rel="noopener noreferrer">Addressing Function Approximation Error in Actor-Critic Methods</a> - PyTorch implementation of Twin Delayed Deep Deterministic Policy Gradients (TD3).</li><li><a href="https://arxiv.org/abs/2007.08794" target="_blank" rel="noopener noreferrer">Discovering Reinforcement Learning Algorithms (2020)</a></li><li><a href="https://github.com/mila-iqia/spr" target="_blank" rel="noopener noreferrer">Data-Efficient Reinforcement Learning with Self-Predictive Representations</a></li><li><a href="https://github.com/deepmind/lab2d" target="_blank" rel="noopener noreferrer">DeepMind Lab2D</a> - Flexible and fast engine for rapidly creating 2D environments. Built for RL, and well suited for the needs of multi-agent research. (<a href="https://arxiv.org/abs/2011.07027" target="_blank" rel="noopener noreferrer">Paper</a>) (<a href="https://news.ycombinator.com/item?id=25122080" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://distill.pub/2020/understanding-rl-vision/" target="_blank" rel="noopener noreferrer">Understanding RL Vision (2020)</a></li><li><a href="https://github.com/PettingZoo-Team/PettingZoo" target="_blank" rel="noopener noreferrer">PettingZoo</a> - Python library for conducting research in multi-agent reinforcement learning. It&#x27;s akin to a multi-agent version of OpenAI&#x27;s Gym library.</li><li><a href="https://github.com/deepmind/dm_hard_eight" target="_blank" rel="noopener noreferrer">DeepMind Hard Eight Tasks</a> - Set of 8 diverse machine-learning tasks that require exploration in partially observable environments to solve.</li><li><a href="https://github.com/jaybutera/tetrisRL" target="_blank" rel="noopener noreferrer">TetrisRL</a> - Tetris environment to train machine learning agents.</li><li><a href="https://karpathy.github.io/2016/05/31/rl/" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning: Pong from Pixels (2016)</a></li><li><a href="https://github.com/deepmind/dm_env_rpc" target="_blank" rel="noopener noreferrer">dm_env_rpc</a> - Networking protocol for agent-environment communication.</li><li><a href="https://github.com/facebookresearch/phyre" target="_blank" rel="noopener noreferrer">PHYRE</a> - Benchmark for physical reasoning. (<a href="https://phyre.ai/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/PettingZoo-Team/SuperSuit" target="_blank" rel="noopener noreferrer">SuperSuit</a> - Easy-to-use micro-wrappers for Gym and PettingZoo based RL Environments.</li><li><a href="https://github.com/mwydmuch/ViZDoom" target="_blank" rel="noopener noreferrer">ViZDoom</a> - Doom-based AI Research Platform for Reinforcement Learning from Raw Visual Information. (<a href="http://vizdoom.cs.put.edu.pl/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://www.microsoft.com/en-us/research/blog/research-collection-reinforcement-learning-at-microsoft/" target="_blank" rel="noopener noreferrer">Reinforcement Learning at Microsoft</a></li><li><a href="https://github.com/banditml/banditml" target="_blank" rel="noopener noreferrer">banditml</a> - Lightweight contextual bandit &amp; reinforcement learning library designed to be used in production Python services.</li><li><a href="https://github.com/LucasAlegre/sumo-rl" target="_blank" rel="noopener noreferrer">SUMO-RL</a> - Provides a simple interface to instantiate Reinforcement Learning environments with SUMO for Traffic Signal Control.</li><li><a href="https://github.com/Project-DC/pygeneses" target="_blank" rel="noopener noreferrer">PyGeneses</a> - PyTorch based DeepRL framework to train and study artificial species in bio-inspired environments. (<a href="https://project-dc.github.io/docs/doc.html" target="_blank" rel="noopener noreferrer">Docs</a>) (<a href="https://medium.com/pytorch/pygeneses-a-deep-reinforcement-learning-framework-to-understand-complex-behaviour-b53aed0181f9" target="_blank" rel="noopener noreferrer">Article</a>)</li><li><a href="http://amid.fish/reproducing-deep-rl" target="_blank" rel="noopener noreferrer">Lessons Learned Reproducing a Deep Reinforcement Learning Paper (2018)</a></li><li><a href="https://github.com/facebookresearch/CompilerGym" target="_blank" rel="noopener noreferrer">CompilerGym</a> - Reinforcement learning toolkit for compiler optimizations. (<a href="https://facebookresearch.github.io/CompilerGym/getting_started.html" target="_blank" rel="noopener noreferrer">Docs</a>) (<a href="https://news.ycombinator.com/item?id=26001480" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver" target="_blank" rel="noopener noreferrer">Introduction to Reinforcement Learning with David Silver</a></li><li><a href="https://github.com/werner-duvaud/muzero-general" target="_blank" rel="noopener noreferrer">MuZero General</a> - Commented and documented implementation of MuZero based on the Google DeepMind paper (Nov 2019) and the associated pseudocode.</li><li><a href="https://www.packtpub.com/product/deep-reinforcement-learning-hands-on-second-edition/9781838826994" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Hands-On (2020)</a> (<a href="https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/facebookresearch/rebel" target="_blank" rel="noopener noreferrer">ReBeL</a> - Algorithm that generalizes the paradigm of self-play reinforcement learning and search to imperfect-information games.</li><li><a href="https://github.com/simondlevy/neat-gym" target="_blank" rel="noopener noreferrer">NEAT Gym</a> - Learn OpenAI Gym environments using NEAT.</li><li><a href="https://github.com/facebookresearch/rlstructures" target="_blank" rel="noopener noreferrer">RLStructures</a> - Library to facilitate the implementation of new reinforcement learning algorithms.</li><li><a href="https://github.com/AI4Finance-Foundation/FinRL" target="_blank" rel="noopener noreferrer">FinRL</a> - Deep Reinforcement Learning Library for Quantitative Finance. (<a href="https://news.ycombinator.com/item?id=30819436" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/facebookresearch/ReAgent" target="_blank" rel="noopener noreferrer">ReAgent</a> - Platform for Reasoning systems (Reinforcement Learning, Contextual Bandits, etc.). (<a href="https://reagent.ai/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/RITCHIEHuang/DeepRL_Algorithms" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Algorithms</a></li><li><a href="https://github.com/MishaLaskin/curl" target="_blank" rel="noopener noreferrer">CURL: Contrastive Unsupervised Representation Learning for Sample-Efficient Reinforcement Learning</a></li><li><a href="https://github.com/seungeunrho/minimalRL" target="_blank" rel="noopener noreferrer">minimalRL PyTorch</a> - Implementations of basic RL algorithms with minimal lines of code.</li><li><a href="https://github.com/seungjaeryanlee/awesome-rl-competitions" target="_blank" rel="noopener noreferrer">Awesome RL Competitions</a></li><li><a href="https://github.com/ntasfi/PyGame-Learning-Environment" target="_blank" rel="noopener noreferrer">PyGame Learning Environment</a> - Reinforcement Learning Environment in Python.</li><li><a href="https://github.com/lusob/gym-ple" target="_blank" rel="noopener noreferrer">OpenAI PLE environment</a> - Learning environment, mimicking the Arcade Learning Environment interface.</li><li><a href="https://github.com/AboudyKreidieh/h-baselines" target="_blank" rel="noopener noreferrer">h-baselines</a> - High-performing hierarchical reinforcement learning models and algorithms.</li><li><a href="https://aihabitat.org/" target="_blank" rel="noopener noreferrer">AI Habitat</a> - Simulation platform for research in Embodied AI. (<a href="https://github.com/facebookresearch/habitat-challenge" target="_blank" rel="noopener noreferrer">Habitat Challenge 2020 Code</a>)</li><li><a href="http://jmvidal.cse.sc.edu/papers/mas.pdf" target="_blank" rel="noopener noreferrer">Fundamentals of Multiagent Systems (2010)</a></li><li><a href="https://github.com/vwxyzjn/cleanrl" target="_blank" rel="noopener noreferrer">CleanRL</a> - High-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features.</li><li><a href="https://github.com/Curt-Park/rainbow-is-all-you-need" target="_blank" rel="noopener noreferrer">Rainbow is all you need</a> - Step-by-step tutorial from DQN to Rainbow.</li><li><a href="https://github.com/facebookresearch/mtenv" target="_blank" rel="noopener noreferrer">MTEnv</a> - MultiTask Environments for Reinforcement Learning.</li><li><a href="https://ai.googleblog.com/2021/02/mastering-atari-with-discrete-world.html" target="_blank" rel="noopener noreferrer">Mastering Atari with Discrete World Models (2021)</a></li><li><a href="https://github.com/denisyarats/proto" target="_blank" rel="noopener noreferrer">Proto-RL: Reinforcement Learning with Prototypical Representations</a></li><li><a href="https://openreview.net/pdf?id=CGQ6ENUMX6" target="_blank" rel="noopener noreferrer">Task-Agnostic Morphology Optimization (2021)</a> (<a href="https://github.com/jhejna/morphology-opt" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/sisl/MADRL" target="_blank" rel="noopener noreferrer">MADRL</a> - Code for multi-agent deep reinforcement learning.</li><li><a href="https://arxiv.org/abs/2103.02886" target="_blank" rel="noopener noreferrer">Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings (2021)</a> (<a href="https://github.com/lili-chen/SEER" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence" target="_blank" rel="noopener noreferrer">Self-supervised learning: The dark matter of intelligence (2021)</a> (<a href="https://twitter.com/ylecun/status/1367516830542270467" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://www.reddit.com/r/reinforcementlearning/comments/lx50ao/examples_of_rl_applied_to_problems_that_arent/" target="_blank" rel="noopener noreferrer">Examples of RL applied to problems that aren’t gaming/robotics? (2021)</a></li><li><a href="https://arxiv.org/abs/2007.04309" target="_blank" rel="noopener noreferrer">Self-Supervised Policy Adaptation during Deployment (2020)</a> (<a href="https://www.reddit.com/r/reinforcementlearning/comments/lxdiye/exploring_selfsupervised_policy_adaptation_to/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://www.youtube.com/watch?v=SaJL4SLfrcY&amp;t=2532s" target="_blank" rel="noopener noreferrer">Self-Supervised Learning - Yann LeCun (2019)</a></li><li><a href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf" target="_blank" rel="noopener noreferrer">Reinforcement Learning: Introduction by Sutton and Barto</a></li><li><a href="https://andyljones.com/posts/rl-debugging.html" target="_blank" rel="noopener noreferrer">Debugging Reinforcement Learning Systems (2021)</a></li><li><a href="https://clemenswinter.com/2021/03/24/mastering-real-time-strategy-games-with-deep-reinforcement-learning-mere-mortal-edition/" target="_blank" rel="noopener noreferrer">Mastering Real-Time Strategy Games with Deep Reinforcement Learning: Mere Mortal Edition (2021)</a></li><li><a href="https://github.com/heronsystems/adeptRL" target="_blank" rel="noopener noreferrer">adeptRL</a> - Reinforcement learning framework to accelerate research.</li><li><a href="https://github.com/openai/baselines" target="_blank" rel="noopener noreferrer">OpenAI Baselines</a> - Set of high-quality implementations of reinforcement learning algorithms.</li><li><a href="https://github.com/ikostrikov/jaxrl" target="_blank" rel="noopener noreferrer">Jax (Flax) RL</a> - Jax (Flax) implementation of algorithms for Deep Reinforcement Learning with continuous action spaces.</li><li><a href="https://www.youtube.com/watch?v=my207WNoeyA" target="_blank" rel="noopener noreferrer">Markov Decision Processes (MDPs) - Structuring a Reinforcement Learning Problem (2018)</a></li><li><a href="http://rail.eecs.berkeley.edu/deeprlcourse/" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Berkeley Course</a> (<a href="https://github.com/berkeleydeeprlcourse/homework_fall2020" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/berkeleydeeprlcourse" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li><a href="https://github.com/hanjuku-kaso/awesome-offline-rl" target="_blank" rel="noopener noreferrer">Awesome Offline RL</a> - Collection of research and review papers for offline reinforcement learning.</li><li><a href="https://arxiv.org/abs/2104.06272" target="_blank" rel="noopener noreferrer">Podracer architectures for scalable Reinforcement Learning (2021)</a> (<a href="https://twitter.com/jekbradbury/status/1382203188489588741" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/DLR-RM/rl-baselines3-zoo" target="_blank" rel="noopener noreferrer">RL Baselines3 Zoo</a> - Training Framework for Stable Baselines3 Reinforcement Learning Agents.</li><li><a href="https://github.com/clvrai/awesome-rl-envs" target="_blank" rel="noopener noreferrer">Awesome RL environments</a></li><li><a href="https://github.com/kengz/awesome-deep-rl" target="_blank" rel="noopener noreferrer">Awesome Deep RL</a></li><li><a href="https://www.notion.so/Paper-Notes-by-Vitaly-Kurin-97827e14e5cd4183815cfe3a5ecf2f4c" target="_blank" rel="noopener noreferrer">Large collection of machine learning / RF paper notes</a></li><li><a href="https://github.com/ds4dm/ecole" target="_blank" rel="noopener noreferrer">Ecole</a> - Extensible Combinatorial Optimization Learning Environments. (<a href="https://www.ecole.ai/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/facebookresearch/mbrl-lib" target="_blank" rel="noopener noreferrer">MBRL-Lib</a> - Library for Model Based RL.</li><li><a href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/" target="_blank" rel="noopener noreferrer">Towards a Theory of Generalization in Reinforcement Learning (2021)</a></li><li><a href="https://ai.googleblog.com/2021/04/evolving-reinforcement-learning.html" target="_blank" rel="noopener noreferrer">Evolving Reinforcement Learning Algorithms (2021)</a></li><li><a href="https://ai.googleblog.com/2021/04/model-based-rl-for-decentralized-multi.html" target="_blank" rel="noopener noreferrer">Model-Based RL for Decentralized Multi-agent Navigation (2021)</a></li><li><a href="https://danijar.com/project/dreamerv2/" target="_blank" rel="noopener noreferrer">Mastering Atari with Discrete World Models (2021)</a> (<a href="https://github.com/danijar/dreamerv2" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://github.com/jurgisp/pydreamer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/google-research/robodesk" target="_blank" rel="noopener noreferrer">RoboDesk</a> - Multi-Task Reinforcement Learning Benchmark.</li><li><a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl" target="_blank" rel="noopener noreferrer">ReinforcementLearning.jl</a> - Reinforcement learning package for Julia. (<a href="https://juliareinforcementlearning.org/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://arxiv.org/abs/1906.02771" target="_blank" rel="noopener noreferrer">Improving Exploration in Soft-Actor-Critic with Normalizing Flows Policies (2019)</a> (<a href="https://github.com/joeybose/FloRL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/learnables/cherry" target="_blank" rel="noopener noreferrer">Cherry</a> - PyTorch Library for Reinforcement Learning Research.</li><li><a href="https://sites.google.com/berkeley.edu/decision-transformer" target="_blank" rel="noopener noreferrer">Decision Transformer: Reinforcement Learning via Sequence Modeling (2021)</a> (<a href="https://www.reddit.com/r/MachineLearning/comments/nqqle6/r_decision_transformer_reinforcement_learning_via/" target="_blank" rel="noopener noreferrer">Reddit</a>) (<a href="https://www.reddit.com/r/reinforcementlearning/comments/nqp9nh/decision_transformer_reinforcement_learning_via/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://github.com/Miffyli/rl-human-prior-tricks" target="_blank" rel="noopener noreferrer">Reinforcement Learning Tricks, Index</a></li><li><a href="http://web.stanford.edu/class/cs234/index.html" target="_blank" rel="noopener noreferrer">CS234: Reinforcement Learning Course</a> (<a href="https://github.com/Huixxi/CS234-Reinforcement-Learning-Winter-2019" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2106.01345" target="_blank" rel="noopener noreferrer">Decision Transformer: Reinforcement Learning via Sequence Modeling (2021)</a> (<a href="https://github.com/kzl/decision-transformer" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://rll.berkeley.edu/" target="_blank" rel="noopener noreferrer">UC Berkeley Robot Learning Lab</a></li><li><a href="https://github.com/kzl/lifelong_rl" target="_blank" rel="noopener noreferrer">lifelong_rl</a> - PyTorch implementations of RL algorithms.</li><li><a href="https://arxiv.org/abs/2106.03273" target="_blank" rel="noopener noreferrer">Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation (2021)</a> (<a href="https://github.com/evgenii-nikishin/omd" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.youtube.com/watch?v=4lthJd3DNTM" target="_blank" rel="noopener noreferrer">Yann LeCun | The Energy-Based Learning Model (2021)</a></li><li><a href="https://lilianweng.github.io/lil-log/" target="_blank" rel="noopener noreferrer">Lil&#x27;Log</a> - Blog about RL.</li><li><a href="https://github.com/Khrylx/PyTorch-RL" target="_blank" rel="noopener noreferrer">PyTorch implementation of reinforcement learning algorithms</a></li><li><a href="https://github.com/rail-berkeley/d4rl" target="_blank" rel="noopener noreferrer">D4RL: Datasets for Deep Data-Driven Reinforcement Learning</a></li><li><a href="https://github.com/rlworkgroup/metaworld" target="_blank" rel="noopener noreferrer">Meta-World</a> - Open source robotics benchmark for meta- and multi-task reinforcement learning. (<a href="https://meta-world.github.io/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://github.com/rlworkgroup/garage" target="_blank" rel="noopener noreferrer">garage</a> - Toolkit for reproducible reinforcement learning research.</li><li><a href="https://arxiv.org/abs/2106.02039" target="_blank" rel="noopener noreferrer">Reinforcement Learning as One Big Sequence Modeling Problem (2021)</a></li><li><a href="https://www.davidsilver.uk/teaching/" target="_blank" rel="noopener noreferrer">David Silver&#x27;s UCL Course on RL</a></li><li><a href="https://github.com/instadeepai/Mava" target="_blank" rel="noopener noreferrer">Mava</a> - Research framework for distributed multi-agent reinforcement learning. (<a href="https://arxiv.org/pdf/2107.01460.pdf" target="_blank" rel="noopener noreferrer">Paper</a>)</li><li><a href="https://github.com/dredwardhyde/reinforcement-learning" target="_blank" rel="noopener noreferrer">Reinforcement Learning Examples</a> - Policy Gradients, PPO+GAE, and DDQN Using OpenAI Gym and PyTorch.</li><li><a href="https://openreview.net/forum?id=r-gPPHEjpmw" target="_blank" rel="noopener noreferrer">Hierarchical Reinforcement Learning by Discovering Intrinsic Options</a> (<a href="https://github.com/jesbu1/hidio" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://bair.berkeley.edu/blog/2021/07/08/basalt/" target="_blank" rel="noopener noreferrer">BASALT: A Benchmark for Learning from Human Feedback (2021)</a> (<a href="https://twitter.com/rohinmshah/status/1413185489335734277" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/google/brax" target="_blank" rel="noopener noreferrer">BRAX</a> - Massively parallel rigidbody physics simulation on accelerator hardware.</li><li><a href="https://arxiv.org/abs/2106.01151" target="_blank" rel="noopener noreferrer">Towards Deeper Deep Reinforcement Learning (2021)</a></li><li><a href="https://github.com/facebookresearch/deep_bisim4control" target="_blank" rel="noopener noreferrer">Learning Invariant Representations for Reinforcement Learning without Reconstruction</a></li><li><a href="https://github.com/oxwhirl/pymarl" target="_blank" rel="noopener noreferrer">Python MARL</a> - Python Multi-Agent Reinforcement Learning framework.</li><li><a href="https://github.com/alex-petrenko/sample-factory" target="_blank" rel="noopener noreferrer">Sample Factory</a> - High throughput asynchronous reinforcement learning.</li><li><a href="https://deepmind.com/blog/article/generally-capable-agents-emerge-from-open-ended-play" target="_blank" rel="noopener noreferrer">Generally capable agents emerge from open-ended play (2021)</a> (<a href="https://news.ycombinator.com/item?id=27972950" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/1912.01588" target="_blank" rel="noopener noreferrer">Leveraging Procedural Generation to Benchmark Reinforcement Learning (2020)</a> (<a href="https://github.com/openai/procgen" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.freecodecamp.org/news/intro-to-advanced-actor-critic-methods-reinforcement-learning-course/" target="_blank" rel="noopener noreferrer">Intro to Advanced Actor-Critic Methods: Reinforcement Learning Course (2021)</a></li><li><a href="https://github.com/thu-ml/tianshou" target="_blank" rel="noopener noreferrer">Tianshou</a> - Elegant PyTorch deep reinforcement learning library. (<a href="https://tianshou.readthedocs.io/en/master/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/lkwate/neural-question-generation" target="_blank" rel="noopener noreferrer">Reinforcement Learning Generator-Evaluator Architecture for Question Generation</a></li><li><a href="https://github.com/fabricerosay/AlphaGPU" target="_blank" rel="noopener noreferrer">AlphaGPU</a> - Alphazero on GPU thanks to CUDA.jl.</li><li><a href="https://papers.nips.cc/paper/1999/hash/464d828b85b0bed98e80ade0a5c43b0f-Abstract.html" target="_blank" rel="noopener noreferrer">Policy Gradient Methods for Reinforcement Learning with Function Approximation (1999)</a></li><li><a href="https://www.reddit.com/r/reinforcementlearning/comments/p8rd7z/for_a_beginner_what_are_the_most_influential/" target="_blank" rel="noopener noreferrer">For a beginner, what are the most influential papers in the history of RL? (2021)</a></li><li><a href="https://github.com/google-research/rliable" target="_blank" rel="noopener noreferrer">rliable</a> - Open-source library for reliable evaluation on reinforcement learning and machine learnings benchmarks.</li><li><a href="https://github.com/takuseno/d3rlpy" target="_blank" rel="noopener noreferrer">d3rlpy</a> - Offline deep reinforcement learning library. (<a href="https://takuseno.github.io/d3rlpy/" target="_blank" rel="noopener noreferrer">Web</a>)</li><li><a href="https://towardsdatascience.com/why-you-shouldnt-use-reinforcement-learning-163bae193da8" target="_blank" rel="noopener noreferrer">Why You Shouldn’t Use Reinforcement Learning (2021)</a></li><li><a href="https://mishalaskin.github.io/rad/" target="_blank" rel="noopener noreferrer">Reinforcement Learning with Augmented Data</a> (<a href="https://github.com/MishaLaskin/rad" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://spectrum.ieee.org/reinforcement-learning" target="_blank" rel="noopener noreferrer">Greedy AI agents learn to cooperate (2021)</a> (<a href="https://news.ycombinator.com/item?id=28437797" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/spiceai/spiceai" target="_blank" rel="noopener noreferrer">Spice.ai</a> - Open source, portable runtime for training and using deep learning on time series data. (<a href="https://news.ycombinator.com/item?id=28449182" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://deepmind.com/learning-resources/reinforcement-learning-series-2021" target="_blank" rel="noopener noreferrer">Reinforcement Learning Lecture Series 2021 | DeepMind</a> (<a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm" target="_blank" rel="noopener noreferrer">Videos</a>) (<a href="https://twitter.com/DeepMind/status/1435974267112464385" target="_blank" rel="noopener noreferrer">Tweet</a>) (<a href="https://www.reddit.com/r/reinforcementlearning/comments/pl4opb/new_deepminducl_rl_lecture_series_on_youtube/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://github.com/nikhilbarhate99/PPO-PyTorch" target="_blank" rel="noopener noreferrer">PPO-PyTorch</a> - Minimal implementation of clipped objective Proximal Policy Optimization (PPO) in PyTorch.</li><li><a href="https://github.com/rlberry-py/rlberry" target="_blank" rel="noopener noreferrer">rlberry</a> - Easy-to-use reinforcement learning library for research and education.</li><li><a href="https://github.com/google-research/seed_rl" target="_blank" rel="noopener noreferrer">SEED RL</a> - Scalable and Efficient Deep-RL with Accelerated Central Inference. Implements IMPALA and R2D2 algorithms in TF2 with SEED&#x27;s architecture.</li><li><a href="https://github.com/facebookresearch/minihack" target="_blank" rel="noopener noreferrer">MiniHack</a> - Sandbox for Open-Ended Reinforcement Learning Research.</li><li><a href="http://www.argmin.net/2018/06/25/outsider-rl/" target="_blank" rel="noopener noreferrer">An Outsider&#x27;s Tour of Reinforcement Learning (2018)</a></li><li><a href="https://arxiv.org/abs/2010.02193" target="_blank" rel="noopener noreferrer">Mastering Atari with Discrete World Models (2020)</a> (<a href="https://github.com/RajGhugare19/dreamerv2" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/google-research/falken" target="_blank" rel="noopener noreferrer">Falken</a> - Provides developers with a service that allows them to train AI that can play their games.</li><li><a href="https://github.com/yrlu/irl-imitation" target="_blank" rel="noopener noreferrer">irl-imitation</a> - Implementation of Inverse Reinforcement Learning (IRL) algorithms in python/Tensorflow. Deep MaxEnt, MaxEnt, LPIRL.</li><li><a href="https://www.reddit.com/r/reinforcementlearning/comments/q6vlav/best_rl_papers_from_the_past_year_or_two/" target="_blank" rel="noopener noreferrer">Best RL papers from the past year or two (2021)</a></li><li><a href="https://arxiv.org/abs/2110.05038" target="_blank" rel="noopener noreferrer">Recurrent Model-Free RL is a Strong Baseline for Many POMDPs (2021)</a></li><li><a href="https://github.com/edbeeching/godot_rl_agents" target="_blank" rel="noopener noreferrer">Godot RL Agents</a> (<a href="https://www.reddit.com/r/MachineLearning/comments/q8sx0g/p_introducing_godot_rl_agents/" target="_blank" rel="noopener noreferrer">Reddit</a>)</li><li><a href="https://arxiv.org/abs/2110.07910" target="_blank" rel="noopener noreferrer">SaLinA: Sequential Learning of Agents (2021)</a> - Flexible and Simple Library for Learning Sequential Agents (including Reinforcement Learning). (<a href="https://github.com/facebookresearch/salina" target="_blank" rel="noopener noreferrer">Code</a>) (<a href="https://twitter.com/LudovicDenoyer/status/1450003583609544704" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/deepmind/envlogger" target="_blank" rel="noopener noreferrer">EnvironmentLogger</a> - Tool for recording RL trajectories.</li><li><a href="https://github.com/facebookresearch/drqv2" target="_blank" rel="noopener noreferrer">DrQ-v2</a> - Improved Data-Augmented Reinforcement Learning.</li><li><a href="https://github.com/mgbellemare/Arcade-Learning-Environment" target="_blank" rel="noopener noreferrer">Arcade Learning Environment (ALE)</a> - Simple framework that allows researchers and hobbyists to develop AI agents for Atari 2600 games.</li><li><a href="https://evjang.com/2021/07/30/rl-qa.html" target="_blank" rel="noopener noreferrer">ML Mentorship: Some Q/A about RL (2021)</a></li><li><a href="https://github.com/StepNeverStop/RLs" target="_blank" rel="noopener noreferrer">RLs</a> - Reinforcement Learning Algorithms Based on PyTorch.</li><li><a href="https://github.com/deepmind/dm_alchemy" target="_blank" rel="noopener noreferrer">DeepMind Alchemy environment</a> - Meta-reinforcement learning benchmark.</li><li><a href="https://github.com/thomashirtz/gym-hybrid" target="_blank" rel="noopener noreferrer">gym-hybrid</a> - Collection of environment for reinforcement learning task possessing discrete-continuous hybrid action space.</li><li><a href="https://github.com/jakegrigsby/deep_control" target="_blank" rel="noopener noreferrer">Simple PyTorch Implementations of Deep RL Algorithms for Continuous Control Research</a></li><li><a href="https://arxiv.org/abs/2110.15349" target="_blank" rel="noopener noreferrer">Learning to Ground Multi-Agent Communication with Autoencoders (2021)</a></li><li><a href="https://mihdalal.github.io/raps/" target="_blank" rel="noopener noreferrer">Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives (2021)</a> (<a href="https://github.com/mihdalal/raps" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/rll-research/url_benchmark" target="_blank" rel="noopener noreferrer">Unsupervised Reinforcement Learning Benchmark (URLB)</a></li><li><a href="https://arxiv.org/abs/2111.00210" target="_blank" rel="noopener noreferrer">Mastering Atari Games with Limited Data (2021)</a> (<a href="https://github.com/YeWR/EfficientZero" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/lcswillems/rl-starter-files" target="_blank" rel="noopener noreferrer">RL Starter Files</a> - RL starter files in order to immediately train, visualize and evaluate an agent without writing any line of code.</li><li><a href="https://github.com/kakaoenterprise/JORLDY" target="_blank" rel="noopener noreferrer">JORLDY</a> - Open Source Reinforcement Learning Framework.</li><li><a href="https://github.com/jajimer/sinergym" target="_blank" rel="noopener noreferrer">sinergym</a> - Gym environment for building simulation and control using reinforcement learning.</li><li><a href="https://github.com/decisionforce/metadrive" target="_blank" rel="noopener noreferrer">MetaDrive</a> - Composing Diverse Driving Scenarios for Generalizable RL.</li><li><a href="https://github.com/danijar/crafter" target="_blank" rel="noopener noreferrer">Crafter</a> - Benchmarking the Spectrum of Agent Capabilities.</li><li><a href="https://github.com/google-research/rlds" target="_blank" rel="noopener noreferrer">RLDS</a> - Reinforcement Learning Datasets.</li><li><a href="https://bair.berkeley.edu/blog/2021/11/05/epistemic-pomdp/" target="_blank" rel="noopener noreferrer">Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability (2021)</a> (<a href="https://arxiv.org/abs/2107.06277" target="_blank" rel="noopener noreferrer">Paper</a>)</li><li><a href="https://www.youtube.com/watch?v=k08N5a0gG0A" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning: BayLearn 2021 Keynote Talk</a></li><li><a href="https://github.com/WhatIThinkAbout/BabyRobot" target="_blank" rel="noopener noreferrer">Baby Robot&#x27;s Guide to Reinforcement Learning</a></li><li><a href="https://arxiv.org/abs/2008.10066" target="_blank" rel="noopener noreferrer">Learning Off-Policy with Online Planning (2020)</a> (<a href="https://github.com/hari-sikchi/LOOP" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2011.04709" target="_blank" rel="noopener noreferrer">f-IRL: Inverse Reinforcement Learning via State Marginal Matching (2020)</a> (<a href="https://github.com/twni2016/f-IRL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/sfujim/TD3_BC" target="_blank" rel="noopener noreferrer">TD3+BC</a> - Minimalist Approach to Offline Reinforcement Learning.</li><li><a href="https://github.com/upb-lea/reinforcement_learning_course_materials" target="_blank" rel="noopener noreferrer">Reinforcement Learning Course Materials</a></li><li><a href="https://arxiv.org/abs/2111.00876" target="_blank" rel="noopener noreferrer">On the Expressivity of Markov Reward (2021)</a> (<a href="https://twitter.com/dabelcs/status/1460575866212212739" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/NVIDIA-Omniverse/IsaacGymEnvs" target="_blank" rel="noopener noreferrer">Isaac Gym Benchmark Environments</a> - Contains example RL environments for the NVIDIA Isaac Gym high performance environments.</li><li><a href="https://arxiv.org/abs/2110.06169" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning with Implicit Q-Learning (2021)</a> (<a href="https://github.com/ikostrikov/implicit_q_learning" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.09794" target="_blank" rel="noopener noreferrer">A Survey of Generalisation in Deep Reinforcement Learning (2021)</a> (<a href="https://twitter.com/OriolVinyalsML/status/1461729731301167112" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://ai.googleblog.com/2021/11/permutation-invariant-neural-networks.html" target="_blank" rel="noopener noreferrer">Permutation-Invariant Neural Networks for Reinforcement Learning (2021)</a></li><li><a href="https://github.com/sail-sg/envpool" target="_blank" rel="noopener noreferrer">EnvPool</a> - C++-based high-performance parallel environment execution engine for general RL environments. (<a href="https://envpool.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Docs</a>)</li><li><a href="https://github.com/ethanluoyc/magi" target="_blank" rel="noopener noreferrer">Magi RL library in JAX</a></li><li><a href="https://github.com/salesforce/warp-drive" target="_blank" rel="noopener noreferrer">WarpDrive</a> - Extremely Fast End-to-End Deep Multi-Agent Reinforcement Learning Framework on a GPU.</li><li><a href="https://github.com/danijar/embodied" target="_blank" rel="noopener noreferrer">Embodied</a> - Fast reinforcement learning research.</li><li><a href="https://blog.otoro.net/2021/11/18/attentionneuron/" target="_blank" rel="noopener noreferrer">Permutation-Invariant Neural Networks for Reinforcement Learning (2021)</a> (<a href="https://news.ycombinator.com/item?id=29364890" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://twitter.com/jacobmbuckman/status/1464327006489829378" target="_blank" rel="noopener noreferrer">Only RL setting worth studying is the MDP (2021)</a> (<a href="https://twitter.com/luisa_zintgraf/status/1465359423061307400" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3690996" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy (2020)</a> (<a href="https://github.com/AI4Finance-Foundation/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Algorithms with PyTorch</a></li><li><a href="https://github.com/Rohan138/marl-baselines3" target="_blank" rel="noopener noreferrer">MARL-Baselines3</a> - Multi-Agent Reinforcement Learning with Stable-Baselines3.</li><li><a href="https://github.com/HorizonRobotics/alf" target="_blank" rel="noopener noreferrer">ALF</a> - Reinforcement learning framework emphasizing on the flexibility and easiness of implementing complex algorithms involving many different components.</li><li><a href="https://arxiv.org/abs/2112.00478" target="_blank" rel="noopener noreferrer">On the Practical Consistency of Meta-Reinforcement Learning Algorithms (2021)</a> (<a href="https://twitter.com/luisa_zintgraf/status/1470349932972421124" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://github.com/Limmen/awesome-rl-for-cybersecurity" target="_blank" rel="noopener noreferrer">Awesome Reinforcement Learning for Cyber Security</a></li><li><a href="https://github.com/google/balloon-learning-environment" target="_blank" rel="noopener noreferrer">Balloon Learning Environment</a> - Flying stratospheric balloons with deep reinforcement learning.</li><li><a href="https://lorenzopieri.com/rl_transformers/" target="_blank" rel="noopener noreferrer">The potential of transformers in reinforcement learning (2021)</a> (<a href="https://news.ycombinator.com/item?id=29617087" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/scottemmons/rvs" target="_blank" rel="noopener noreferrer">rvs</a> - Reinforcement Learning via Supervised Learning.</li><li><a href="https://github.com/chandar-lab/RLHive" target="_blank" rel="noopener noreferrer">RLHive</a> - Framework designed to facilitate research in reinforcement learning.</li><li><a href="https://github.com/robinhenry/gym-anm" target="_blank" rel="noopener noreferrer">Gym-ANM</a> - Design Reinforcement Learning environments that model Active Network Management (ANM) tasks in electricity distribution networks.</li><li><a href="https://arxiv.org/abs/1908.04942" target="_blank" rel="noopener noreferrer">Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation (2020)</a></li><li><a href="https://github.com/keras-rl/keras-rl" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning for Keras</a></li><li><a href="https://github.com/ShangtongZhang/DeepRL" target="_blank" rel="noopener noreferrer">DeepRL</a> - Modularized Implementation of Deep RL Algorithms in PyTorch.</li><li><a href="https://github.com/sadighian/crypto-rl" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning Toolkit for Cryptocurrencies</a> - Record and replay cryptocurrency limit order book data &amp; train a DDQN agent.</li><li><a href="https://arxiv.org/abs/1910.08285" target="_blank" rel="noopener noreferrer">Multi-View Reinforcement Learning (2019)</a> (<a href="https://github.com/mlii/mvrl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1802.05438" target="_blank" rel="noopener noreferrer">Mean Field Multi-Agent Reinforcement Learning (2019)</a> (<a href="https://github.com/mlii/mfrl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/1907.04543" target="_blank" rel="noopener noreferrer">An Optimistic Perspective on Offline Reinforcement Learning (2020)</a> (<a href="https://github.com/google-research/batch_rl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://alger.id.au/pdfs/irl.pdf" target="_blank" rel="noopener noreferrer">Deep Inverse Reinforcement Learning</a> (<a href="https://github.com/MatthewJA/Inverse-Reinforcement-Learning" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/facebookresearch/rlmeta" target="_blank" rel="noopener noreferrer">RLMeta</a> - Light-weight flexible framework for Distributed Reinforcement Learning Research.</li><li><a href="https://github.com/DeNA/HandyRL" target="_blank" rel="noopener noreferrer">HandyRL</a> - Handy and simple framework based on Python and PyTorch for distributed reinforcement learning that is applicable to your own environments.</li><li><a href="https://arxiv.org/abs/1803.07055" target="_blank" rel="noopener noreferrer">Simple random search provides a competitive approach to reinforcement learning (2018)</a> (<a href="https://github.com/erwincoumans/ARS" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://ankeshanand.com/blog/2022/01/08/rl-fine-tuning.html" target="_blank" rel="noopener noreferrer">Reinforcement Learning as a fine-tuning paradigm (2022)</a></li><li><a href="https://github.com/facebookresearch/mtrl" target="_blank" rel="noopener noreferrer">MTRL</a> - Multi Task RL Baselines.</li><li><a href="https://github.com/Farama-Foundation/MAgent" target="_blank" rel="noopener noreferrer">MAgent</a> - Library for creating 2D environments with very large numbers of agents for conducting research in Multi-Agent Reinforcement Learning.</li><li><a href="https://github.com/rail-berkeley/rlkit" target="_blank" rel="noopener noreferrer">RLkit</a> - Reinforcement learning framework and algorithms implemented in PyTorch.</li><li><a href="https://arxiv.org/abs/2201.12122" target="_blank" rel="noopener noreferrer">Can Wikipedia Help Offline Reinforcement Learning? (2022)</a> (<a href="https://github.com/machelreid/can-wikipedia-help-offline-rl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2201.13425" target="_blank" rel="noopener noreferrer">Don&#x27;t Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning (2021)</a> (<a href="https://github.com/denisyarats/exorl" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2010.01062" target="_blank" rel="noopener noreferrer">Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning (2021)</a> (<a href="https://github.com/lmzintgraf/hyperx" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/fuyw/RepL4RL" target="_blank" rel="noopener noreferrer">Representation Learning for Reinforcement Learning</a></li><li><a href="https://github.com/montrealrobotics/DeepRLInTheWorld" target="_blank" rel="noopener noreferrer">Deep Reinforcement Learning in The Real World</a></li><li><a href="https://arxiv.org/abs/1905.11623" target="_blank" rel="noopener noreferrer">Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero (2019)</a> (<a href="https://github.com/xuzijian629/combopt-zero" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2011.03506" target="_blank" rel="noopener noreferrer">The Value Equivalence Principle for Model-Based Reinforcement Learning (2020)</a> (<a href="https://github.com/RajGhugare19/VE-principle-for-model-based-RL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/laszukdawid/ai-traineree" target="_blank" rel="noopener noreferrer">ai-traineree</a> - PyTorch agents and tools for (Deep) Reinforcement Learning.</li><li><a href="https://github.com/Denys88/rl_games" target="_blank" rel="noopener noreferrer">RL Games: High performance RL library</a></li><li><a href="https://deepmind.com/blog/article/MuZeros-first-step-from-research-into-the-real-world" target="_blank" rel="noopener noreferrer">MuZero’s first step from research into the real world (2022)</a> (<a href="https://news.ycombinator.com/item?id=30468546" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://github.com/cypypccpy/Isaac-ManipulaRL" target="_blank" rel="noopener noreferrer">Isaac-ManipulaRL</a> - Manipulator Reinforcement Learning based on Isaac-gym.</li><li><a href="https://github.com/coax-dev/coax" target="_blank" rel="noopener noreferrer">coax</a> - Plug-n-Play Reinforcement Learning in Python with OpenAI Gym and JAX.</li><li><a href="https://github.com/chagmgang/distributed_reinforcement_learning" target="_blank" rel="noopener noreferrer">Implementation of Distributed Reinforcement Learning with TensorFlow</a></li><li><a href="https://github.com/aunum/gold" target="_blank" rel="noopener noreferrer">Gold</a> - Reinforcement Learning in Go.</li><li><a href="https://github.com/PaddlePaddle/MetaGym" target="_blank" rel="noopener noreferrer">MetaGym</a> - Collection of Reinforcement Learning / Meta Reinforcement Learning Environments.</li><li><a href="https://github.com/deepmind/meltingpot" target="_blank" rel="noopener noreferrer">Melting Pot</a> - Suite of test scenarios for multi-agent reinforcement learning.</li><li><a href="https://github.com/young-geng/CQL" target="_blank" rel="noopener noreferrer">CQL</a> - Simple and modular implementation of the Conservative Q Learning and Soft Actor Critic algorithm in PyTorch.</li><li><a href="https://arxiv.org/abs/1706.02275" target="_blank" rel="noopener noreferrer">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (2017)</a> (<a href="https://github.com/xuehy/pytorch-maddpg" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/facebookresearch/rl" target="_blank" rel="noopener noreferrer">TorchRL</a> - Modular, primitive-first, python-first PyTorch library for Reinforcement Learning.</li><li><a href="https://sites.google.com/view/mappo" target="_blank" rel="noopener noreferrer">The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games</a> (<a href="https://github.com/marlbenchmark/on-policy" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2111.04714" target="_blank" rel="noopener noreferrer">Understanding the Effects of Dataset Characteristics on Offline Reinforcement Learning (2021)</a> (<a href="https://github.com/kschweig/OfflineRL" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/hubbs5/or-gym" target="_blank" rel="noopener noreferrer">or-gym</a> - Environments for OR and RL Research.</li><li><a href="https://github.com/TJU-DRL-LAB/AI-Optimizer" target="_blank" rel="noopener noreferrer">AI-Optimizer</a> - Next generation deep reinforcement learning tookit.</li><li><a href="https://github.com/HuantWang/SUPERSONIC" target="_blank" rel="noopener noreferrer">SuperSonic</a> - Automating reinforcement learning architecture design for code optimization.</li><li><a href="https://github.com/qgallouedec/panda-gym" target="_blank" rel="noopener noreferrer">panda-gym</a> - OpenAI/gym robotic environments based on PyBullet physics engine.</li><li><a href="https://github.com/danaugrs/huskarl" target="_blank" rel="noopener noreferrer">Huskarl</a> - Deep Reinforcement Learning Framework + Algorithms.</li><li><a href="https://github.com/gsverhoeven/gt_rl_course" target="_blank" rel="noopener noreferrer">Resources and material for an internal course on Reinforcement Learning</a></li><li><a href="https://github.com/LucasAlegre/mo-gym" target="_blank" rel="noopener noreferrer">MO-Gym: Multi-Objective Reinforcement Learning Environments</a></li><li><a href="https://xbpeng.github.io/projects/DeepMimic/index.html" target="_blank" rel="noopener noreferrer">DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills (2018)</a> (<a href="https://github.com/xbpeng/DeepMimic" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://github.com/Sentdex/SC2RL" target="_blank" rel="noopener noreferrer">SC2RL</a> - Reinforcement Learning + Starcraft 2.</li><li><a href="https://github.com/0xangelo/raylab" target="_blank" rel="noopener noreferrer">raylab</a> - Reinforcement learning algorithms in RLlib and PyTorch.</li><li><a href="https://github.com/huggingface/deep-rl-class" target="_blank" rel="noopener noreferrer">Hugging Face Deep Reinforcement Learning Class</a></li><li><a href="https://github.com/mareo1208/Drone-2d-custom-gym-env-for-reinforcement-learning" target="_blank" rel="noopener noreferrer">OpenAI Gym environment designed for training RL agents to control the flight of a two-dimensional drone</a></li><li><a href="https://github.com/Paulescu/hands-on-rl" target="_blank" rel="noopener noreferrer">Hands-on Reinforcement Learning course</a></li><li><a href="https://github.com/lucas-emery/rocket-league-gym" target="_blank" rel="noopener noreferrer">Rocket League Gym</a> - Gym-like environment for Reinforcement Learning in Rocket League.</li><li><a href="https://github.com/kengz/SLM-Lab" target="_blank" rel="noopener noreferrer">SLM Lab</a> - Modular Deep Reinforcement Learning framework in PyTorch. Companion library of the book &quot;Foundations of Deep Reinforcement Learning&quot;.</li><li><a href="https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines" target="_blank" rel="noopener noreferrer">Safe Reinforcement Learning Baseline</a></li><li><a href="https://github.com/google-research/circuit_training" target="_blank" rel="noopener noreferrer">Circuit Training: An open-source framework for generating chip floor plans with distributed deep reinforcement learning</a></li><li><a href="https://arxiv.org/abs/2204.07531" target="_blank" rel="noopener noreferrer">Understanding Game-Playing Agents with Natural Language Annotations (2022)</a> (<a href="https://twitter.com/NickATomlin/status/1521551621678899200" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="https://brachiation-rl.github.io/brachiation/" target="_blank" rel="noopener noreferrer">Learning to Brachiate via Simplified Model Imitation (2022)</a> (<a href="https://github.com/brachiation-rl/brachiation" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://www.deepmind.com/publications/a-generalist-agent" target="_blank" rel="noopener noreferrer">DeepMind: A Generalist Agent (2022)</a> (<a href="https://news.ycombinator.com/item?id=31355657" target="_blank" rel="noopener noreferrer">HN</a>) (<a href="https://twitter.com/DeepMind/status/1524770016259887107" target="_blank" rel="noopener noreferrer">Tweet</a>)</li><li><a href="http://joshvarty.github.io/AlphaZero/" target="_blank" rel="noopener noreferrer">Alpha Zero and Monte Carlo Tree Search</a> - Absolute most basic example of AlphaZero and Monte Carlo Tree Search. (<a href="https://github.com/JoshVarty/AlphaZeroSimple" target="_blank" rel="noopener noreferrer">Code</a>)</li><li><a href="https://arxiv.org/abs/2203.11973" target="_blank" rel="noopener noreferrer">Scalable Deep Reinforcement Learning Algorithms for Mean Field Games (2022)</a></li><li><a href="https://github.com/BetsyHJ/RL4Rec" target="_blank" rel="noopener noreferrer">RL4Rec</a> - Toolkit of Reinforcement Learning based Recommendation.</li><li><a href="https://github.com/kakaobrain/brain_agent" target="_blank" rel="noopener noreferrer">Brain Agent</a> - Large-Scale and Multi-Task Agent Learning.</li><li><a href="https://github.com/fabio-4/JuliaRL" target="_blank" rel="noopener noreferrer">Julia Reinforcement Learning Algorithms</a></li><li><a href="https://github.com/taku-y/border" target="_blank" rel="noopener noreferrer">Border</a> - Reinforcement learning library in Rust.</li><li><a href="https://arxiv.org/abs/2205.14953" target="_blank" rel="noopener noreferrer">Multi-Agent Reinforcement Learning is a Sequence Modeling Problem (2022)</a> (<a href="https://news.ycombinator.com/item?id=31628359" target="_blank" rel="noopener noreferrer">HN</a>)</li><li><a href="https://arxiv.org/abs/2206.01634" target="_blank" rel="noopener noreferrer">Reinforcement Learning with Neural Radiance Fields (2022)</a> (<a href="https://dannydriess.github.io/nerf-rl/" target="_blank" rel="noopener noreferrer">Web</a>)</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/ecioran/kinderheim/docs/machine-learning/reinforcement-learning.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vbeJ"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/kinderheim/machine-learning/neural-networks/graph-neural-networks"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Graph neural networks</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/kinderheim/machine-learning/transfer-learning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Transfer learning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#links" class="table-of-contents__link toc-highlight">Links</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/kinderheim/assets/js/runtime~main.1ffb19eb.js"></script>
<script src="/kinderheim/assets/js/main.b238a0af.js"></script>
</body>
</html>
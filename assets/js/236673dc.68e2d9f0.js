"use strict";(self.webpackChunkkinderheim=self.webpackChunkkinderheim||[]).push([[4309],{3905:function(e,t,a){a.d(t,{Zo:function(){return s},kt:function(){return u}});var i=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},r=Object.keys(e);for(i=0;i<r.length;i++)a=r[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)a=r[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=i.createContext({}),h=function(e){var t=i.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},s=function(e){var t=h(e.components);return i.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var a=e.components,n=e.mdxType,r=e.originalType,l=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),m=h(a),u=n,g=m["".concat(l,".").concat(u)]||m[u]||c[u]||r;return a?i.createElement(g,o(o({ref:t},s),{},{components:a})):i.createElement(g,o({ref:t},s))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=a.length,o=new Array(r);o[0]=m;var p={};for(var l in t)hasOwnProperty.call(t,l)&&(p[l]=t[l]);p.originalType=e,p.mdxType="string"==typeof e?e:n,o[1]=p;for(var h=2;h<r;h++)o[h]=a[h];return i.createElement.apply(null,o)}return i.createElement.apply(null,a)}m.displayName="MDXCreateElement"},4787:function(e,t,a){a.r(t),a.d(t,{assets:function(){return s},contentTitle:function(){return l},default:function(){return u},frontMatter:function(){return p},metadata:function(){return h},toc:function(){return c}});var i=a(7462),n=a(3366),r=(a(7294),a(3905)),o=["components"],p={title:"Speech recognition"},l="[Speech recognition](https://github.com/daanzu/kaldi-active-grammar)",h={unversionedId:"nlp/speech-recognition",id:"nlp/speech-recognition",title:"Speech recognition",description:"Links",source:"@site/docs/nlp/speech-recognition.md",sourceDirName:"nlp",slug:"/nlp/speech-recognition",permalink:"/kinderheim/nlp/speech-recognition",draft:!1,editUrl:"https://github.com/ecioran/kinderheim/docs/nlp/speech-recognition.md",tags:[],version:"current",frontMatter:{title:"Speech recognition"},sidebar:"tutorialSidebar",previous:{title:"Sentiment analysis",permalink:"/kinderheim/nlp/sentiment-analysis"},next:{title:"Speech synthesis",permalink:"/kinderheim/nlp/speech-synthesis"}},s={},c=[{value:"Links",id:"links",level:2}],m={toc:c};function u(e){var t=e.components,a=(0,n.Z)(e,o);return(0,r.kt)("wrapper",(0,i.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"speech-recognition"},(0,r.kt)("a",{parentName:"h1",href:"https://github.com/daanzu/kaldi-active-grammar"},"Speech recognition")),(0,r.kt)("h2",{id:"links"},"Links"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=18736116"},"HN: Facebook open-sources a speech-recognition system and a machine learning library (2018)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/mozilla/DeepSpeech"},"DeepSpeech")," - Open source Speech-To-Text engine, using a model trained by machine learning techniques, based on Baidu's Deep Speech research paper. (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/mozilla/DeepSpeech-examples"},"Examples"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/"},"Online speech recognition with wav2letter@anywhere (2020)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/wav2letter"},"wav2letter++")," - Fast, open source speech processing toolkit from the Speech team at Facebook AI Research built to facilitate research in end-to-end models for speech recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/kaldi-asr/kaldi"},"Kaldi")," - Speech Recognition Toolkit."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch"},"Building an end-to-end Speech Recognition model in PyTorch")," (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=22899107"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/CorentinJ/Real-Time-Voice-Cloning"},"Real-Time Voice Cloning")," - Clone a voice in 5 seconds to generate arbitrary speech in real-time."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/daanzu/kaldi-active-grammar"},"Kaldi Active Grammar")," - Python Kaldi speech recognition with grammars that can be set active/inactive dynamically at decode-time."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/zcaceres/spec_augment"},"SpecAugment with PyTorch")," - PyTorch Implementation of GoogleBrain's SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/dictation-toolbox/dragonfly"},"Dragonfly")," - Speech recognition framework for Python that makes it convenient to create custom commands to use with speech recognition software."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/lowerquality/gentle"},"Gentle")," - Robust yet lenient forced-aligner built on Kaldi. A tool for aligning speech with text."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Picovoice/porcupine"},"Porcupine")," - On-device wake word detection powered by deep learning."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/srvk/eesen"},"Eesen")," - End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23497756"},"Ask HN: Is there any work being done in speech-to-code with deep learning? (2020)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/snakers4/silero-models"},"Silero Models")," - Pre-trained STT models and benchmarks made embarrassingly simple."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pytorch.org/hub/snakers4_silero-models_stt/"},"High-quality pre-trained speech-to-text models now available on Torch Hub")," (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24565831"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/drethage/speech-denoising-wavenet"},"Wavenet For Speech Denoising"),' - Neural network for end-to-end speech denoising, as described in: "A Wavenet For Speech Denoising".'),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/wzhd/vosk-rs"},"Vosk")," - Speech recognition toolkit with state-of-the-art accuracy and low latency in Rust."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.voicegain.ai/"},"Voicegain")," - Speech-to-text Platform and APIs. Speech Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/iceychris/LibreASR"},"LibreASR")," - On-Premises, Streaming Speech Recognition System. (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25099847"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/mmorise/World"},"WORLD")," - High-quality speech analysis, manipulation and synthesis system. (",(0,r.kt)("a",{parentName:"li",href:"http://www.isc.meiji.ac.jp/~mmorise/world/english/"},"Web"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/espnet/espnet"},"ESPnet")," - End-to-end speech processing toolkit. (",(0,r.kt)("a",{parentName:"li",href:"https://espnet.github.io/espnet/"},"Docs"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/sehgal-simran/Spk-Dzn"},"Speaker Diarization")," - Process to answer the question of 'who spoke when?' in an audio file."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/OAID/SpeechRecognition"},"SpeechRecognition")," - Local auto speech recognition project based on Kaldi and ALSA."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/athena-team/athena"},"Athena")," - Open-source implementation of sequence-to-sequence based speech processing engine."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/1ytic/open_stt_e2e"},"PyTorch end-to-end speech recognition")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Picovoice/cheetah"},"Cheetah")," - On-device streaming speech-to-text engine powered by deep learning."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/fatchord/WaveRNN"},"WaveRNN")," - PyTorch implementation of Deepmind's WaveRNN model from Efficient Neural Audio Synthesis."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/sooftware/conformer"},"Conformer")," - PyTorch implementation of Conformer: Convolution-augmented Transformer for Speech Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021"},"A Review of End-to-End Architectures for Speech Recognition (2021)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/dpirch/libfvad"},"libfvad")," - Voice activity detection (VAD) library, based on WebRTC's VAD engine."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/jinserk/pytorch-asr"},"ASR with PyTorch")," - Experimental code for speech recognition using PyTorch and Kaldi."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/yandexdataschool/speech_course"},"YSDA Speech Processing Course")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/dqqcasia/awesome-speech-translation"},"Paper List for Speech Translation")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1912.01679"},"Deep Contextualized Acoustic Representations For Semi-Supervised Speech Recognition (2020)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/awslabs/speech-representations"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2021/02/lyra-new-very-low-bitrate-codec-for.html"},"Lyra: A New Very Low-Bitrate Codec for Speech Compression (2021)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/chaosparrot/parrot.py"},"Parrot.PY")," - Computer interaction using audio and speech recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/speechbrain/speechbrain"},"SpeechBrain Toolkit")," - PyTorch-based Speech Toolkit. (",(0,r.kt)("a",{parentName:"li",href:"https://speechbrain.github.io/"},"Web"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/alphacep/vosk-api"},"Vosk API")," - Offline open source speech recognition toolkit."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/google/lyra"},"Lyra")," - Very Low-Bitrate Codec for Speech Compression."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/sooftware/lasr"},"lasr")," - PyTorch Lightning implementation of Automatic Speech Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing"},"Speech Recognition from Scratch")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://commonvoice.mozilla.org/en"},"Common Voice")," - Mozilla's initiative to help teach machines how real people speak."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2010.15508"},"FullSubNet: A Full-Band and Sub-Band Fusion Model for Real-Time Single-Channel Speech Enhancement (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/haoxiangsnr/FullSubNet"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/SeanNaren/deepspeech.pytorch"},"DeepSpeech2 in PyTorch using PyTorch Lightning")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://web.stanford.edu/~jurafsky/slp3/"},"Speech and Language Processing Book (2021)")," - Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. (",(0,r.kt)("a",{parentName:"li",href:"https://web.stanford.edu/~jurafsky/slp3/ed3book_dec302020.pdf"},"2020 Version"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/synesthesiam/voice2json"},"voice2json")," - Command-line tools for speech and intent recognition on Linux. (",(0,r.kt)("a",{parentName:"li",href:"https://voice2json.org/"},"Web"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision/"},"wav2vec Unsupervised: Speech recognition without supervision (2021)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/theblackcat102/edgedict"},"Online Speech recognition using RNN-Transducer")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/sooftware/openspeech"},"Openspeech")," - Open-Source Toolkit for End-to-End Speech Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.11284"},"Unsupervised Speech Decomposition via Triple Information Bottleneck (2020)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/auspicious3000/SpeechSplit"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.13043"},"AudioCLIP: Extending CLIP to Image, Text and Audio (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/AndreyGuzhov/AudioCLIP"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://vaclavkosar.com/ml/Wav2vec2-Semi-and-Unsupervised-Speech-Recognition"},"Wav2vec: Semi and Unsupervised Speech Recognition")," (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=27722333"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/wenet-e2e/wenet"},"WeNet")," - Production First and Production Ready End-to-End Speech Recognition Toolkit. (",(0,r.kt)("a",{parentName:"li",href:"https://wenet-e2e.github.io/wenet/"},"Docs"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.speechly.com/blog/real-time-voice-user-interfaces/"},"Why Hasn\u2019t the iPhone Moment Happened Yet for Voice UIs (2021)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/LeBenchmark/Interspeech2021"},"LeBenchmark: a reproducible framework for assessing SSL from speech")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.interspeech2021.org/"},"INTERSPEECH 2021")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/syhw/wer_are_we"},"WER are we?")," - Tracking states of the art(s) and recent results on speech recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/SpeechColab/GigaSpeech"},"GigaSpeech")," - Large, modern dataset for speech recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/coqui-ai/STT"},"Coqui STT")," - Deep learning toolkit for Speech-to-Text, battle-tested in research and production. (",(0,r.kt)("a",{parentName:"li",href:"https://stt.readthedocs.io/en/latest/"},"Docs"),") (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/tazz4843/coqui-stt"},"Rust lib"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://coqui.ai/"},"Coqui")," - Startup providing open speech tech for everyone. (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/coqui-ai"},"GitHub"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/coqui-ai/open-speech-corpora"},"Open Speech Corpora")," - List of accessible speech corpora for ASR, TTS, and other Speech Technologies."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://jrmeyer.github.io/asr/2020/03/21/overview-mtl-in-asr.html"},"An Overview of Multi-Task Learning in Speech Recognition (2020)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/coqui-ai/inference-engine"},"Coqui Inference Engine")," - Library for efficiently deploying speech models."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/CypherousSkies/pdf-to-speech"},"PDF to Speech")," - Deep-learning powered accessibility application which turns PDFs into audio files."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Snowdar/asv-subtools"},"ASV-Subtools")," - Open Source Tools for Speaker Recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/haoheliu/voicefixer"},"VoiceFixer")," - General Speech Restoration."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/aliutkus/speechmetrics"},"speechmetrics")," - Wrapper around speech quality metrics MOSNet, BSSEval, STOI, PESQ, SRMR, SISDR."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/snakers4/silero-vad"},"Silero VAD")," - Pre-trained enterprise-grade Voice Activity Detector, Language Classifier and Spoken Number Detector."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://medium.com/a-new-ai-lexicon/a-new-ai-lexicon-voice-340316c30d87"},"A New AI Lexicon: Voice (2021)")," - The Legacies and Limits of Automated Voice Analysis."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Picovoice/octopus"},"Octopus")," - On-device speech-to-index engine powered by deep learning."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/openaudiosearch/openaudiosearch"},"Open Audio Search")," - Full text search engine with automatic speech recognition for podcasts."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://jonathanbgn.com/2021/10/30/hubert-visually-explained.html"},"HuBERT: How to Apply BERT to Speech, Visually Explained (2021)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.happyscribe.com/"},"Happy Scribe")," - Audio Transcription & Video Subtitles."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/wenet-e2e/speech-recognition-papers"},"Speech Recognition Papers")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.02926"},"Steerable discovery of neural audio effects (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/csteinmetz1/steerable-nafx"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/audapolis/audapolis"},"audapolis")," - Editor for spoken-word media with transcription."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/bootphon/shennong"},"Shennong")," - Python toolbox for speech features extraction."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/fgnt/paderbox"},"Paderbox")," - Collection of utilities for audio / speech processing."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/k2-fsa/icefall"},"Icefall")," - Speech recognition recipes using k2. (",(0,r.kt)("a",{parentName:"li",href:"https://icefall.readthedocs.io/en/latest/"},"Docs"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/k2-fsa/k2"},"k2")," - FSA/FST algorithms, differentiable, with PyTorch compatibility."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/google/visqol"},"ViSQOL (Virtual Speech Quality Objective Listener)")," - Objective, full-reference metric for perceived audio quality."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/freewym/espresso"},"Espresso")," - Fast End-to-End Neural Speech Recognition Toolkit."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/microsoft/UniSpeech"},"UniSpeech - Large Scale Self-Supervised Learning for Speech")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/gabrielmittag/NISQA"},"NISQA: Speech Quality and Naturalness Assessment")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/csukuangfj/optimized_transducer"},"Optimization techniques proposed in Improving RNN Transducer Modeling for End-to-End Speech Recognition")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.08100"},"Conformer: Convolution-augmented Transformer for Speech Recognition (2020)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/conformer"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/thu-spmi/CAT"},"CAT: Crf-based Asr Toolkit")," - Complete workflow for CRF-based data-efficient end-to-end speech recognition."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.13320"},"Neural HMMs are all you need (for high-quality attention-free TTS) (2022)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/shivammehta007/Neural-HMM"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/kahne/SpeechTransProgress"},"End-to-End Speech Translation Progress")," - Tracking the progress in end-to-end speech translation."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.03500"},"EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture (2020)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/liusongxiang/efficient_tts"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/s3prl/s3prl"},"S3PRL")," - Self-Supervised Speech Pre-training and Representation Learning Toolkit."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/pyannote/pyannote-audio"},"pyannote-audio")," - Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.02446"},"DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/MoonInTheRiver/DiffSinger"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/speechly/speech-recognition-polyfill"},"Speech recognition polyfill")," - Polyfill for the SpeechRecognition standard on web, using Speechly as the underlying API."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/Picovoice/speech-to-text-benchmark"},"Speech-to-Text Benchmark")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/hyperion-ml/hyperion"},"Hyperion")," - Speaker Recognition Toolkit based on PyTorch and numpy."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/textlesslib"},"textlesslib")," - Library for Textless Spoken Language Processing."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.04558v1"},"FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/ming024/FastSpeech2"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/jonatasgrosman/huggingsound"},"HuggingSound")," - Toolkit for speech-related tasks based on HuggingFace's tools."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/sveinbjornt/hear"},"hear")," - macOS speech recognition via the command line."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/PaddlePaddle/PaddleSpeech"},"PaddleSpeech")," - Easy-to-use Speech Toolkit including SOTA ASR pipeline, influential TTS with text frontend and End-to-End Speech Simultaneous Translation."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.06695"},"BYOL for Audio: Self-Supervised Learning for General-Purpose Audio Representation (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/nttcslab/byol-a"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/festvox/speech_tools"},"Edinburgh Speech Tools")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/zhenghuatan/rVADfast"},"rVADfast")," - Python library for an unsupervised, fast method for robust voice activity detection."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/microsoft/NeuralSpeech"},"NeuralSpeech")," - Research project in Microsoft Research Asia focusing on neural network based speech processing, including automatic speech recognition (ASR), text to speech (TTS), etc."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/haoheliu/ssr_eval"},"Speech Super-resolution Evaluation and Benchmarking")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://gradio.app/real_time_speech_recognition/"},"Real Time Speech Recognition with Gradio")," (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30850596"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.00931"},"Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/assem-vc"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/covost"},"CoVoST: A Large-Scale Multilingual Speech-To-Text Translation Corpus")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.02184"},"Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction (2022)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/av_hubert"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.12847"},"Real Time Speech Enhancement in the Waveform Domain (2020)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/denoiser"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/ccoreilly/vosk-browser"},"Vosk-Browser")," - Opinionated speech recognition library for the browser using a WebAssembly build of Vosk."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/YuanGongND/vocalsound"},"VocalSound: A Dataset for Improving Human Vocal Sounds Recognition")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/qiuqiangkong/audioset_tagging_cnn"},"PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.04421"},"NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality (2022)")," (",(0,r.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31416098"},"HN"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=IkI5WJyEcCc"},"George Hotz | Programming | speech recognition (2022)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.04421"},"NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality (2022)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/natural-speech-pytorch"},"Code"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.a2p.it/tech-stuff/coquistt-signal-love-death-to-voice-messages/"},"CoquiSTT + Signal = Love (death to voice messages) (2022)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/neonbjb/ocotillo"},"ocotillo")," - PyTorch-based ML model that does state-of-the-art English speech transcription."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.07205"},"SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing (2021)")," (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/microsoft/SpeechT5"},"Code"),")")))}u.isMDXComponent=!0}}]);
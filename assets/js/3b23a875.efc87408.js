"use strict";(self.webpackChunkkinderheim=self.webpackChunkkinderheim||[]).push([[37383],{3905:function(e,t,a){a.d(t,{Zo:function(){return m},kt:function(){return g}});var r=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=r.createContext({}),p=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=p(a),g=i,c=u["".concat(s,".").concat(g)]||u[g]||h[g]||n;return a?r.createElement(c,o(o({ref:t},m),{},{components:a})):r.createElement(c,o({ref:t},m))}));function g(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,o=new Array(n);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var p=2;p<n;p++)o[p]=a[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}u.displayName="MDXCreateElement"},14363:function(e,t,a){a.r(t),a.d(t,{assets:function(){return m},contentTitle:function(){return s},default:function(){return g},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return h}});var r=a(87462),i=a(63366),n=(a(67294),a(3905)),o=["components"],l={},s="Natural language processing",p={unversionedId:"nlp/nlp",id:"nlp/nlp",title:"Natural language processing",description:"spaCy & Fairseq are interesting libraries. Natural Language Processing with Transformers Book is nice book. Hugging Face NLP Course is probably the best NLP intro out there.",source:"@site/docs/nlp/nlp.md",sourceDirName:"nlp",slug:"/nlp/",permalink:"/kinderheim/nlp/",draft:!1,editUrl:"https://github.com/ecioran/kinderheim/docs/nlp/nlp.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Cognition",permalink:"/kinderheim/neuroscience/cognition"},next:{title:"Bots",permalink:"/kinderheim/nlp/bots"}},m={},h=[{value:"Links",id:"links",level:2}],u={toc:h};function g(e){var t=e.components,a=(0,i.Z)(e,o);return(0,n.kt)("wrapper",(0,r.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"natural-language-processing"},"Natural language processing"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://spacy.io/"},"spaCy")," & ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/pytorch/fairseq"},"Fairseq")," are interesting libraries. ",(0,n.kt)("a",{parentName:"p",href:"https://transformersbook.com/"},"Natural Language Processing with Transformers Book")," is nice book. ",(0,n.kt)("a",{parentName:"p",href:"https://huggingface.co/course/chapter1/1"},"Hugging Face NLP Course")," is probably the best NLP intro out there."),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://openai.com/dall-e-2/"},"DALL\xb7E 2")," is fascinating. Trying to understand ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/lucidrains/DALLE-pytorch"},"DALL-E in PyTorch")," implementation."),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/"},"Getting started with NLP for absolute beginners")," is a nice intro."),(0,n.kt)("h2",{id:"links"},"Links"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spaCy"},"SpaCy")," - Industrial-strength Natural Language Processing (NLP) with Python and Cython. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25988702"},"HN: SpaCy 3.0 (2021)"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/hackers-at-cambridge/adding-voice-control-to-your-projects-7096fdee7c45"},"Adding voice control to your projects")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=jB1-NukGZm0"},"Increasing data science productivity; founders of spaCy & Prodigy")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jacobeisenstein/gt-nlp-class"},'Course materials for "Natural Language" course')),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sebastianruder/NLP-progress"},"NLP progress")," - Track the progress in Natural Language Processing (NLP) and give an overview of the state-of-the-art across the most common NLP tasks and their corresponding datasets. (",(0,n.kt)("a",{parentName:"li",href:"https://nlpprogress.com/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NaturalNode/natural"},"Natural")," - General natural language facilities for Node."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yandexdataschool/nlp_course"},"YSDA Natural Language Processing course (2018)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pytext"},"PyText")," - Natural language modeling framework based on PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vi3k6i5/flashtext"},"FlashText")," - Extract Keywords from sentence or Replace keywords in sentences."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/codertimo/BERT-pytorch"},"BERT PyTorch implementation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/LASER"},"LASER Language-Agnostic SEntence Representations")," - Library to calculate and use multilingual sentence embeddings."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stanfordnlp/stanfordnlp"},"StanfordNLP")," - Python NLP Library for Many Human Languages."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/graykode/nlp-tutorial"},"nlp-tutorial")," - Tutorial for who is studying NLP(Natural Language Processing) using TensorFlow and PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.openai.com/better-language-models/"},"Better Language Models and Their Implications (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/gpt-2"},"gpt-2")," - Code for the paper ",(0,n.kt)("a",{parentName:"li",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},'"Language Models are Unsupervised Multitask Learners"'),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tensorflow/lingvo"},"Lingvo")," - Framework for building neural networks in Tensorflow, particularly sequence models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/pytorch/fairseq"},"Fairseq")," - Facebook AI Research Sequence-to-Sequence Toolkit written in Python."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=8rXD5-xhemo"},"Stanford CS224N: NLP with Deep Learning (2019)")," - ",(0,n.kt)("a",{parentName:"li",href:"https://web.stanford.edu/class/cs224n/"},"Course page"),". (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=19569883"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ines/spacy-course"},"Advanced NLP with spaCy: Free Course")," (",(0,n.kt)("a",{parentName:"li",href:"https://course.spacy.io/en/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29511488"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cgpotts/cs224u"},"Code for Stanford Natural Language Understanding course, CS224u (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/adityathakker/awesome-rl-nlp"},"Awesome Reinforcement Learning for Natural Language Processing")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/ParlAI"},"ParlAI")," - Framework for training and evaluating AI models on a variety of openly available dialogue datasets."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1905.09922"},"Training language GANs from Scratch (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/olivia-ai/olivia"},"Olivia")," - Your new best friend built with an artificial neural network."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/llSourcell/Learn-Natural-Language-Processing-Curriculum"},"Learn-Natural-Language-Processing-Curriculum")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/makcedward/nlp"},"This repository recorded my NLP journey")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bjoernkarmann/project_alias"},"Project Alias")," - Open-source parasite to train custom wake-up names for smart home devices while disturbing their built-in microphone."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://rush-nlp.com/code/"},"Cornell Tech NLP Code")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://rush-nlp.com/papers/"},"Cornell Tech NLP Publications")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/thinc/"},"Thinc")," - SpaCy's Machine Learning library for NLP in Python. (",(0,n.kt)("a",{parentName:"li",href:"https://thinc.ai/docs"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=KybSRPC3e64"},"Knowledge is embedded in language neural networks but can they reason? (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/nlp"},"NLP Best Practices")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/feedly/transfer-nlp"},"Transfer NLP library")," - Framework built on top of PyTorch to promote reproducible experimentation and Transfer Learning in NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/deepset-ai/FARM"},"FARM")," - Fast & easy transfer learning for NLP. Harvesting language models for the industry."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/transformers"},"Transformers")," - State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/graykode/nlp-roadmap"},"NLP Roadmap 2019")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zalandoresearch/flair"},"Flair")," - Very simple framework for state-of-the-art NLP. Developed by Zalando Research."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/uda"},"Unsupervised Data Augmentation")," - Semi-supervised learning method which achieves state-of-the-art results on a wide variety of language and vision tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/RasaHQ/rasa"},"Rasa")," - Open source machine learning framework to automate text-and voice-based conversations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/text-to-text-transfer-transformer"},"T5")," - Text-To-Text Transfer Transformer."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mhagiwara/100-nlp-papers"},"100 Must-Read NLP Papers")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24377223"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/keon/awesome-nlp"},"Awesome NLP")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mihail911/nlp-library"},"NLP Library")," - Curated collection of papers for the NLP practitioner."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spacy-transformers"},"spacy-transformers")," - spaCy pipelines for pre-trained BERT, XLNet and GPT-2."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/allenai/allennlp"},"AllenNLP")," - Open-source NLP research library, built on PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://medium.com/ai2-blog/allennlp-1-0-df0327445509"},"Announcing AllenNLP 1.0"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stanfordnlp/GloVe"},"GloVe")," - Global Vectors for Word Representation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/botpress/botpress"},"Botpress")," - Open-source Virtual Assistant platform."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MycroftAI/mycroft-core"},"Mycroft")," - Hackable open source voice assistant. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=22702195"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/vizseq"},"VizSeq")," - Visual Analysis Toolkit for Text Generation Tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tokenmill/awesome-nlg"},"Awesome Natural Language Generation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/do-the-keywords-in-your-resume-aptly-represent-what-type-of-data-scientist-you-are-59134105ba0d"},"How I used NLP (Spacy) to screen Data Science Resume (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://mitpress.mit.edu/books/introduction-natural-language-processing"},"Introduction to Natural Language Processing book")," - Survey of computational methods for understanding, generating, and manipulating human language, which offers a synthesis of classical representations and algorithms with contemporary machine learning techniques."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nlproc.info/"},"Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/joosthub/PyTorchNLPBook"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/tokenizers"},"Tokenizers")," - Fast State-of-the-Art Tokenizers optimized for Research and Production. (",(0,n.kt)("a",{parentName:"li",href:"https://medium.com/dair-ai/hugging-face-introduces-tokenizers-d792482db360"},"Article"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/random_forests/status/1216125213760532480"},"Example Notebook using BERT for NLP with Keras (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/omarsar/nlp_highlights"},"NLP 2019/2020 Highlights")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/omarsar/nlp_overview"},"Overview of Modern Deep Learning Techniques Applied to Natural Language Processing")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://machinelearning.apple.com/2019/07/24/language-identification-from-very-short-strings.html"},"Language Identification from Very Short Strings (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/fh295/SentenceRepresentation"},"SentenceRepresentation")," - Code acompanies the paper 'Learning Sentence Representations from Unlabelled Data' Felix Hill, KyungHyun Cho and Anna Korhonen 2016."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://fh295.github.io/teaching.html"},"Deep Learning for Language Processing course")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/Megatron-LM"},"Megatron LM")," - Ongoing research training transformer language models at scale, including: BERT & GPT-2. (",(0,n.kt)("a",{parentName:"li",href:"https://www.bodunhu.com/blog/posts/megatron-with-fastmoe/"},"Megatron with FastMoE"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/Megatron-DeepSpeed"},"Fork"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zihangdai/xlnet"},"XLNet")," - New unsupervised language representation learning method based on a novel generalized permutation language modeling objective."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/ALBERT"},"ALBERT")," - Lite BERT for Self-supervised Learning of Language Representations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/bert"},"BERT")," - TensorFlow code and pre-trained models for BERT."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2001.08210.pdf"},"Multilingual Denoising Pre-training for Neural Machine Translation (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lyeoni/nlp-tutorial"},"List of NLP tutorials built on PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stickeritis/sticker"},"sticker")," - Sequence labeler that uses either recurrent neural networks, transformers, or dilated convolution networks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stickeritis/sticker-transformers"},"sticker-transformers")," - Pretrained transformer models for sticker."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/boudinfl/pke"},"pke")," - Python Keyphrase Extraction module."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/blog/how-to-train"},"How to train a new language model from scratch using Transformers and Tokenizers (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/SIDN-IAP/attnvis"},"Interactive Attention Visualization")," - Small example of an interactive visualization for attention values as being used by transformer language models like GPT2 and BERT."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://amaarora.github.io/2020/02/18/annotatedGPT2.html"},"The Annotated GPT-2 (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dmlc/gluon-nlp"},"GluonNLP")," - Toolkit that enables easy text preprocessing, datasets loading and neural models building to help you speed up your NLP research."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/IndicoDataSolutions/finetune"},"Finetune")," - Scikit-learn style model finetuning for NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2003.07082"},"Stanza: A Python Natural Language Processing Toolkit for Many Human Languages (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=22663322"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dair-ai/nlp_newsletter"},"NLP Newsletter")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dair-ai/nlp_paper_summaries"},"NLP Paper Summaries")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://course.spacy.io/"},"Advanced NLP with spaCy")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://myleott.com/"},"Myle Ott's research")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nltk/nltk"},"Natural Language Toolkit (NLTK)")," - Suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing. (",(0,n.kt)("a",{parentName:"li",href:"http://www.nltk.org/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.nltk.org/book/"},"Book"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nlp100.github.io/en/"},"NLP 100 Exercise")," - Bootcamp designed for learning skills for programming, data analysis, and research activities. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nlp100/nlp100.github.io"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html"},"The Transformer Family (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ricardorei/lightning-text-classification"},"Minimalist Implementation of a BERT Sentence Classifier")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://fasttext.cc/"},"fastText")," - Library for efficient text classification and representation learning. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/fastText/"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://rolisz.com/the-best-text-classification-library-for-a-quick-baseline/"},"Article"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=27583185"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/floret"},"Fork"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/awesome-papers"},"Awesome NLP Paper Discussions")," - Papers & presentations from Hugging Face's weekly science day."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dojoteef/synst"},"SynST: Syntactically Supervised Transformers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.08900"},"The Cost of Training NLP Models: A Concise Overview (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://dev.fast.ai/tutorial.transformers"},"Tutorial - Transformers")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/GuggerSylvain/status/1254837525274865664"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mozilla/TTS"},"TTS")," - Deep learning for Text to Speech."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://public.ukp.informatik.tu-darmstadt.de/MAD-X/paper.pdf"},"MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/minimaxir/gpt-2-simple"},"gpt-2-simple")," - Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Tiiiger/bert_score"},"BERTScore")," - BERT score for text generation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dair-ai/ml-nlp-paper-discussions"},"ML and NLP Paper Discussions")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://index.quantumstat.com/"},"NLP Index")," - Collection of NLP resources."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://datasets.quantumstat.com/"},"NLP Datasets")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=5PL0TmQhItY"},"Word Embeddings (2017)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://teddykoker.com/2020/02/nlp-from-scratch-annotated-attention/"},"NLP from Scratch: Annotated Attention (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.thisworddoesnotexist.com/"},"This Word Does Not Exist")," - Allows people to train a variant of GPT-2 that makes up words, definitions and examples from scratch. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/turtlesoupy/this-word-does-not-exist"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23169962"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/MachineLearning/comments/ghrjfs/d_ultimate_guide_to_choosing_an_online_course/"},"Ultimate guide to choosing an online course covering practical NLP (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://colab.research.google.com/github/huggingface/nlp/blob/master/notebooks/Overview.ipynb"},"HuggingFace ",(0,n.kt)("inlineCode",{parentName:"a"},"nlp")," library - Quick overview (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/Thom_Wolf/status/1261264437220081667"},"Twitter"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/minimaxir/aitextgen"},"aitextgen")," - Robust Python tool for text-based AI training and generation using GPT-2. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23223358"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://amitness.com/2020/05/self-supervised-learning-nlp/"},"Self Supervised Representation Learning in NLP (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23292885"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1711.02173"},"Synthetic and Natural Noise Both Break Neural Machine Translation (2017)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/uclnlp/inferbeddings"},"Inferbeddings")," - Injecting Background Knowledge in Neural Models via Adversarial Set Regularisation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://nlp.cs.ucl.ac.uk/"},"UCL Natural Language Processing group")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/uclnlp/stat-nlp-book"},"Interactive Lecture Notes, Slides and Exercises for Statistical NLP")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/marcotcr/checklist"},"Beyond Accuracy: Behavioral Testing of NLP models with CheckList")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/neubig/lowresource-nlp-bootcamp-2020"},"CMU LTI Low Resource NLP Bootcamp 2020")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.14165"},"GPT-3: Language Models Are Few-Shot Learners (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23345379"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/gpt-3"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/nlp"},"nlp")," - Lightweight and extensible library to easily share and access datasets and evaluation metrics for NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.notion.so/634eba1a37d34e2baec1bb574a8a5482"},"Brainsources for NLP enthusiasts")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/transformers/tree/master/examples/movement-pruning"},"Movement Pruning: Adaptive Sparsity by Fine-Tuning")," (",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.07683"},"Paper"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lyeoni/nlp-resources"},"NLP Resources")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/TaBERT"},"TaBERT: Learning Contextual Representations for Natural Language Utterances and Structured Tables")," (",(0,n.kt)("a",{parentName:"li",href:"https://ai.facebook.com/blog/tabert-a-new-model-for-understanding-queries-over-tabular-data/"},"Article"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23725829"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rth/vtext"},"vtext")," - NLP in Rust with Python bindings."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://ltl.mml.cam.ac.uk/"},"Language Technology Lab @ University of Cambridge")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.cse.unsw.edu.au/~billw/nlpdict.html"},"The Natural Language Processing Dictionary")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://harish3110.github.io/through-tinted-lenses/natural%20language%20processing/sentiment%20analysis/2020/06/27/Introduction-to-NLP-using-Fastai.html"},"Introduction to NLP using Fastai (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.gwern.net/newsletter/2020/05#gpt-3"},"Gwern on GPT-3")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23623845"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.semanticmachines.com/"},"Semantic Machines")," - Solving conversational artificial intelligence. Part of Microsoft."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://colab.research.google.com/drive/15oP52_7W5dRcAnbgX3tYADsu4R3cjMIf?usp=sharing"},"The Reformer \u2013 Pushing the limits of language modeling")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23718475"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.gwern.net/GPT-3"},"GPT-3 Creative Fiction (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23722635"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://salt.agency/blog/nlp-and-stuff/"},"Classifying 200k articles in 7 hours using NLP (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23760109"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23821411"},"HN: Using GPT-3 to generate user interfaces (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/xuenay/status/1283312640199196673"},"Thread of GPT-3 use cases (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/minimaxir/gpt-3-experiments"},"GPT-3 Code Experiments")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/minimaxir/gpt-3-experiments/tree/master/examples"},"Examples"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jalammar.github.io/how-gpt3-works-visualizations-animations/"},"How GPT3 Works - Visualizations and Animations (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://lobste.rs/s/j54rgh/how_gpt3_works_visualizations"},"Lobsters"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23967887"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://tinkeredthinking.com/index.php?id=841"},"What is GPT-3? written in layman's terms (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23923799"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gpt3examples.com/"},"GPT3 Examples")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23993251"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.00816"},"DQI: Measuring Data Quality in NLP (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://humanloop.com/"},"Humanloop")," - Train and deploy NLP. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23987353"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ruder.io/nlp-beyond-english/"},"Do NLP Beyond English (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24026511"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html"},"Giving GPT-3 a Turing Test (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23887637"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?cPath=22&products_id=1056"},"Neural Network Methods for Natural Language Processing (2017)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://minimaxir.com/2020/07/gpt3-expectations/"},"Tempering Expectations for GPT-3 and OpenAI\u2019s API (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://dailynous.com/2020/07/30/philosophers-gpt-3/"},"Philosophers on GPT-3 (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24003384"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://belay-labs.github.io/gpt-explorer/introducing-gpt-explorer"},"GPT-3 Explorer")," - Power tool for experimenting with GPT-3. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/belay-labs/gpt-explorer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://deponysum.com/2020/01/16/recent-advances-in-natural-language-processing-some-woolly-speculations/"},"Recent Advances in Natural Language Processing (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24179795"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/abhimishra91/insight"},"Project Insight")," - NLP as a Service. (",(0,n.kt)("a",{parentName:"li",href:"https://discuss.streamlit.io/t/project-insight-streamlit-fastapi-huggingface-and-all-the-goodness/4978"},"Forum post"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=mL-hWbwVphk"},"Bob Coecke: Quantum Natural Language Processing (QNLP) (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://medium.com/cambridge-quantum-computing/quantum-natural-language-processing-748d6f27b31d"},"Article"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html"},"Language-Agnostic BERT Sentence Embedding (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/pair-code/lit/"},"Language Interpretability Tool (LIT)")," - Interactively analyze NLP models for model understanding in an extensible and framework agnostic interface."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.booste.io/pretrained-models"},"Booste Pre Trained Models")," - Free-to-use GPT-2 API. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24561214"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2009.10542"},"Context-theoretic Semantics for Natural Language: an Algebraic Framework (2007)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp"},"THUNLP (Natural Language Processing Lab at Tsinghua University) research")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.infoq.com/news/2020/10/training-exceeds-gpt3/"},"AI training method exceeds GPT-3 performance with fewer parameters (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24704952"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/clarkkev/attention-analysis"},"BERT Attention Analysis")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/pytorch/nvidia-nemo-neural-modules-and-models-for-conversational-ai-d660480d9696"},"Neural Modules and Models for Conversational AI (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MaartenGr/BERTopic"},"BERTopic")," - Topic modeling technique that leverages BERT embeddings and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ivan-bilan/The-NLP-Pandect"},"NLP Pandect")," - Comprehensive reference for all topics related to Natural Language Processing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.practicalnlp.ai/"},"Practical Natural Language Processing book")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/practical-nlp/practical-nlp"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://bkkaggle.github.io/blog/nlp-research-part-1/"},"NLP Reseach Project: Best Practices for Finetuning Large Transformer Language models (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://strikingloo.github.io/wiki-articles/machine-learning/deep_learning_NLP"},"Deep Learning for NLP notes (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jmugan/modern_practical_nlp"},"Modern Practical Natural Language Processing course")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/airsplay/lxmert"},"LXMERT: Learning Cross-Modality Encoder Representations from Transformers in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/oskar-j/awesome-text-ml"},"Awesome software for Text ML")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2010.06467"},"Pretrained Transformers for Text Ranking: BERT and Beyond (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://explosion.ai/blog/spacy-v3-nightly"},"SpaCy v3.0 Nightly (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24789981"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/spacy_io/status/1316769056108818432"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://share.streamlit.io/ines/spacy-streamlit-demo/master/app.py"},"Explore trained spaCy v3.0 pipelines")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spacy-streamlit"},"spacy-streamlit")," - sGpaCy building blocks for Streamlit apps. (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/_inesmontani/status/1316781893791158273"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ankane/informers"},"Informers")," - State-of-the-art natural language processing for Ruby."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://neptune.ai/blog/how-to-structure-and-manage-nlp-projects-templates"},"How to Structure and Manage Natural Language Processing (NLP) Projects (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MartinoMensio/spacy-sentence-bert"},"Sentence-BERT for spaCy")," - Wraps sentence-transformers (also known as sentence-BERT) directly in spaCy."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MycroftAI/lingua-franca"},"Lingua Franca")," - Mycroft's multilingual text parsing and formatting library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ThilinaRajapakse/simpletransformers"},"Simple Transformers")," - Based on the Transformers library by HuggingFace. Lets you quickly train and evaluate Transformer models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=j9toSIRf4RI"},"Deep Bidirectional Transformers for Language Understanding (2020)")," - Explains a legendary paper, BERT. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24826599"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alibaba/EasyTransfer"},"EasyTransfer")," - Designed to make the development of transfer learning in NLP applications easier."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/gsarti/lambda-bert"},"LambdaBERT")," - Transformers-style implementation of BERT using LambdaNetworks instead of self-attention."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/DialoGPT"},"DialoGPT")," - State-of-the-Art Large-scale Pretrained Response Generation Model."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/danqi/thesis/blob/master/thesis.pdf"},"Neural reading comprehension and beyond - Danqi Chen's Thesis (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/danqi/thesis"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/LAMA"},"LAMA: LAnguage Model Analysis")," - Probe for analyzing the factual and commonsense knowledge contained in pretrained language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MaxwellRebo/awesome-2vec"},"awesome-2vec")," - Curated list of 2vec-type embedding models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html"},"Rethinking Attention with Performers (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24878116"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://mccormickml.com/2019/11/11/bert-research-ep-1-key-concepts-and-sources/"},"BERT Research - Key Concepts & Sources (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/The-Pile"},"The Pile")," - Large, diverse, open source language modelling data set that consists of many smaller datasets combined together."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alexa/bort"},"Bort"),' - Companion code for the paper "Optimal Subarchitecture Extraction for BERT."'),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://getvectorai.com/"},"Vector AI")," - Encode And Deploy Vectors At The Edge. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/vector-ai/vectorhub"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MaartenGr/KeyBERT/"},"KeyBERT")," - Minimal keyword extraction with BERT. (",(0,n.kt)("a",{parentName:"li",href:"https://maartengr.github.io/KeyBERT/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yaohungt/Multimodal-Transformer"},"Multimodal Transformer for Unaligned Multimodal Language Sequences")," - In PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://jalammar.github.io/illustrated-gpt2/"},"The Illustrated GPT-2 (Visualizing Transformer Language Models) (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2002.12327"},"A Primer in BERTology: What we know about how BERT works (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25043280"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/gpt-neo/"},"GPT Neo")," - Open-source GPT model, with pretrained 1.3B & 2.7B weight models. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26534000"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://textsynth.com/"},"TextSynth")," - Bellard's free GPT-NeoX-20B, GPT-J playground and paid API. (",(0,n.kt)("a",{parentName:"li",href:"https://textsynth.com/playground.html"},"Playground"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31175291"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://x.ai/how-to-go-from-nlp-in-1-language-to-nlp-in-n-languages-in-one-shot/"},"How to Go from NLP in 1 Language to NLP in N Languages in One Shot (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MilaNLProc/contextualized-topic-models"},"Contextualized Topic Models")," - Family of topic models that use pre-trained representations of language (e.g., BERT) to support topic modeling."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/shentianxiao/language-style-transfer"},"Language Style Transfer")," - Code for ",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1705.09655"},"Style Transfer from Non-Parallel Text by Cross-Alignment")," paper."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JohnSnowLabs/nlu"},"NLU")," - Power of Spark NLP, the Simplicity of Python. 1 line for hundreds of NLP models and algorithms."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dhlee347/pytorchic-bert"},"PyTorch Implementation of Google BERT")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://gabrielilharco.com/publications/EMNLP_2020_Tutorial__High_Performance_NLP.pdf"},"High Performance Natural Language Processing (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/castorini/duobert"},"duoBERT")," - Multi-stage passage ranking: monoBERT + duoBERT."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/elyase/awesome-gpt3"},"Awesome GPT-3")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/automl/SMAC3"},"SMAC3")," - Sequential Model-based Algorithm Configuration."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://research.google.com/semanticexperiences/"},"Semantic Experiences by Google")," - Experiments in understanding language."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/long-range-arena"},"Long-Range Arena")," - Systematic evaluation of efficient transformer models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PaddlePaddle/PaddleHub"},"PaddleHub")," - Awesome pre-trained models toolkit based on PaddlePaddle."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://deep-spin.github.io/"},"DeepSPIN (Deep Structured Prediction in Natural Language Processing)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/deep-spin"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jg8610/multi-task-learning"},"Multi-Task Learning in NLP")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/fastseq"},"FastSeq")," - Provides efficient implementation of popular sequence models (e.g. Bart, ProphetNet) for text generation, summarization, translation tasks etc."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/UKPLab/sentence-transformers"},"Sentence Embeddings with BERT & XLNet")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/fastformers"},"FastFormers")," - Provides a set of recipes and methods to achieve highly efficient inference of Transformer models for Natural Language Understanding (NLU)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/anli"},"Adversarial NLI")," - Adversarial Natural Language Inference Benchmark."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/deanmalmgren/textract"},"textract")," - Extract text from any document. No muss. No fuss. (",(0,n.kt)("a",{parentName:"li",href:"https://textract.readthedocs.io/en/stable/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://techblog.smc.it/en/2020-12-11/nlp-ner"},"NLP e Named Entity Recognition (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/bigbird"},"Big Bird: Transformers for Longer Sequences")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/will-thompson-k/deeplearning-nlp-models"},"NLP PyTorch Tutorial")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jasonwei20/eda_nlp"},"EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1909.01441"},"CrossWeigh: Training Named Entity Tagger from Imperfect Annotations (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZihanWangKi/CrossWeigh"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://bair.berkeley.edu/blog/2020/12/20/lmmem/"},"Does GPT-2 Know Your Phone Number? (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.14271"},"Towards Fully Automated Manga Translation (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/brightmart/text_classification"},"Text Classification Models")," - All kinds of text classification models and more with deep learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mathsyouth/awesome-text-summarization"},"Awesome Text Summarization")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ofir.io/shortformer.pdf"},"Shortformer: Better Language Modeling using Shorter Inputs (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25588675"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/huggingface_hub"},"huggingface_hub")," - Client library to download and publish models and other files on the huggingface.co hub."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.singlelunch.com/2020/02/16/embeddings-from-the-ground-up/"},"Embeddings from the Ground Up (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jalammar/ecco"},"Ecco")," - Tools to visuals and explore NLP language models. (",(0,n.kt)("a",{parentName:"li",href:"https://www.eccox.io/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25683808"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jalammar.github.io/explaining-transformers/"},"Interfaces for Explaining Transformer Language Models (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/dall-e/"},"DALL\xb7E: Creating Images from Text (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25649557"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/MachineLearning/comments/kr63ot/r_new_paper_from_openai_dalle_creating_images/"},"Reddit"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/clip/"},"CLIP: Connecting Text and Images (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25649740"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf"},"Paper"),") (",(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/clip/"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/OpenNRE"},"OpenNRE")," - Open-Source Package for Neural Relation Extraction (NRE)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://princeton-nlp.github.io/"},"Princeton NLP Group")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-nlp"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/NREPapers"},"Must-read papers on neural relation extraction (NRE)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/FewRel"},"FewRel Dataset, Toolkits and Baseline Models")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1909.06639"},"Tree Transformer: Integrating Tree Structures into Self-Attention (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yaushian/Tree-Transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/SentEval"},"SentEval: evaluation toolkit for sentence embeddings")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/maraoz/gpt-scrolls"},"gpt-scrolls")," - Collaborative collection of open-source safe GPT-3 prompts that work well."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ringgaard/sling"},"SLING - A natural language frame semantics parser")," - Built to learn to read and understand Wikipedia articles in many languages for the purpose of knowledge base completion."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bplank/awesome-neural-adaptation-in-NLP"},"Awesome Neural Adaptation in NLP")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.cambridge.org/core/journals/natural-language-engineering/article/natural-language-generation-the-commercial-state-of-the-art-in-2020/BA2417D73AF29F8073FF5B611CDEB97F"},"Natural language generation: The commercial state of the art in 2020")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25711669"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kahne/NonAutoregGenProgress"},"Non-Autoregressive Generation Progress")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nlp-uoregon/trankit"},"Trankit: A Light-Weight Transformer-based Python Toolkit for Multilingual Natural Language Processing")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/artetxem/vecmap"},"VecMap")," - Framework to learn cross-lingual word embedding mappings."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kiri-ai/kiri"},"Kiri")," - Natural Language Engine. (",(0,n.kt)("a",{parentName:"li",href:"https://kiri.ai/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sw-yx/gpt3-list"},"GPT3 List")," - List of things that people are claiming is enabled by GPT3."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/DeBERTa"},"DeBERTa")," - Decoding-enhanced BERT with Disentangled Attention."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/awslabs/sockeye"},"Sockeye")," - Open-source sequence-to-sequence framework for Neural Machine Translation based on Apache MXNet. (",(0,n.kt)("a",{parentName:"li",href:"https://awslabs.github.io/sockeye/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/robustness-gym/robustness-gym"},"Robustness Gym")," - Python evaluation toolkit for natural language processing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/transfer-learning-conv-ai"},"State-of-the-Art Conversational AI with Transfer Learning")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.eleuther.ai/gpt-neo"},"GPT-Neo")," - GPT-3-sized model, open source and free. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25819803"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/gpt-neo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/deep-daze"},"Deep Daze")," - Simple command line tool for text to image generation using OpenAI's CLIP and Siren (Implicit neural representation network)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/notebooks"},"Notebooks using the Hugging Face libraries")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nlpcloud.io/"},"NLP Cloud")," - Serve spaCy pre-trained models, and your own custom models, through a RESTful API."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2010.10392"},"CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/helboukkouri/character-bert"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nyu-mll/jiant"},"jiant")," - Multitask and transfer learning toolkit for NLP. (",(0,n.kt)("a",{parentName:"li",href:"https://jiant.info/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/TAADpapers"},"Must-read Papers on Textual Adversarial Attack and Defense")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/luyug/Reranker"},"Reranker")," - Build Text Rerankers with Deep Language Models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/guillaume-be/rust-bert"},"rust-bert")," - Rust native ready-to-use NLP pipelines and transformer-based models (BERT, DistilBERT, GPT2,...)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/guillaume-be/rust-tokenizers"},"rust-tokenizers")," - Offers high-performance tokenizers for modern language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html"},"Replicating GPT-2 at Home (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25883791"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ryanjgallagher/shifterator"},"Shifterator")," - Interpretable data visualizations for understanding how texts differ at the word level."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://phontron.com/class/nn4nlp2021/schedule.html"},"CMU Neural Networks for NLP Course (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PL8PYTP1V4I8AkaHEJ7lOOrlex-pcxS-XV"},"Videos"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/neubig/minnn-assignment"},"minnn")," - Exercise in developing a minimalist neural network toolkit for NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1910.02677"},"Controllable Sentence Simplification (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/access"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/roomylee/awesome-relation-extraction"},"Awesome Relation Extraction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/retextjs/retext"},"retext")," - Natural language processor powered by plugins part of the unified collective. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/retextjs/awesome-retext"},"Awesome"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.clipplayground.co/"},"CLIP Playground")," - Try OpenAI's CLIP model in your browser."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gpt3demo.com/"},"GPT-3 Demo")," - GPT-3 Examples, Demos, Showcase, and NLP Use-cases."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/big-sleep"},"Big Sleep")," - Simple command line tool for text to image generation, using OpenAI's CLIP and a BigGAN."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google/BIG-bench"},"Beyond the Imitation Game Benchmark (BIG-bench)")," - Collaborative benchmark intended to probe large language models, and extrapolate their future capabilities."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/autonlp"},"AutoNLP")," - Automatic way to train, evaluate and deploy state-of-the-art NLP models for different tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/linkedin/detext"},"DeText")," - Deep Neural Text Understanding Framework for Ranking and Classification Tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/inejc/paragraph-vectors"},"Paragraph Vectors in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/neuspell/neuspell"},"NeuSpell: A Neural Spelling Correction Toolkit")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/haltakov/natural-language-youtube-search"},"Natural Language YouTube Search")," - Search inside YouTube videos using natural language."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/accelerate"},"Accelerate")," - Simple way to train and use NLP models with multi-GPU, TPU, mixed-precision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cltk/cltk"},"Classical Language Toolkit (CLTK)")," - Python library offering natural language processing (NLP) for pre-modern languages. (",(0,n.kt)("a",{parentName:"li",href:"http://cltk.org/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Xirider/finetune-gpt2xl"},"Guide: Finetune GPT2-XL")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/GENRE"},"GENRE (Generarive ENtity REtrieval)")," - Uses a sequence-to-sequence approach to entity retrieval (e.g., linking), based on fine-tuned BART architecture."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ainize.ai/teachable-nlp"},"Teachable NLP")," - GPT-2 Training as a Service."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-nlp/DensePhrases"},"DensePhrases")," - Provides answers to your natural language questions from the entire Wikipedia in real-time."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/sharifshameem/status/1379756878062710789"},"How to use GPT-3 recursively to solve general problems (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TakeLab/podium"},"Podium")," - Framework agnostic Python NLP library for data loading and preprocessing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://prompts.ai/"},"Prompts")," - Advanced GPT-3 playground. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sevazhidkov/prompts-ai"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/textflint/textflint"},"TextFlint")," - Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/icoxfog417/awesome-text-summarization"},"Awesome Text Summarization")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08821"},"SimCSE: Simple Contrastive Learning of Sentence Embeddings (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-nlp/SimCSE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nikitakit/self-attentive-parser"},"Berkeley Neural Parser")," - High-accuracy NLP parser with models for 11 languages. (",(0,n.kt)("a",{parentName:"li",href:"https://parser.kitaev.io/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/makcedward/nlpaug"},"nlpaug")," - Data augmentation for NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ddangelov/Top2Vec"},"Top2Vec")," - Learns jointly embedded topic, document and word vectors."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.12714"},"Focused Attention Improves Document-Grounded Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/shrimai/Focused-Attention-Improves-Document-Grounded-Generation"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/artefactory/NLPretext"},"NLPretext")," - All the goto functions you need to handle NLP use-cases."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TakeLab/spacy-udpipe"},"spaCy + UDPipe")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Adapter-Hub/adapter-transformers"},"adapter-transformers")," - Friendly fork of HuggingFace's Transformers, adding Adapters to PyTorch language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/QData/TextAttack"},"TextAttack")," - Generating adversarial examples for NLP models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/gpt-neox"},"GPT-NeoX")," - Implementation of model parallel GPT-3-like models on GPUs, based on the DeepSpeed library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://naacl2019.org/program/tutorials/"},"Transfer Learning in Natural Language Processing (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/naacl_transfer_learning_tutorial"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://cohere.ai/"},"Cohere")," - Help computers understand language. (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/AidanNGomez/status/1389574000796479489"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cdpierse/transformers-interpret"},"Transformers Interpret")," - Model explainability tool designed to work exclusively with the transformers package."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/greyblake/whatlang-rs"},"Whatlang")," - Natural language detection library for Rust. (",(0,n.kt)("a",{parentName:"li",href:"https://whatlang.org/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jbrkr/Category_Theory_Natural_Language_Processing_NLP"},"Category Theory + NLP Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/unilm"},"UniLM")," - Pre-trained models for natural language understanding (NLU) and generation (NLG) tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/autonlp"},"AutoNLP")," - Faster and easier training and deployments of SOTA NLP models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/tapas"},"TAble PArSing (TAPAS)")," - End-to-end neural table-text understanding models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/"},"Replacing Bert Self-Attention with Fourier Transform: 92% Accuracy, 7X Faster (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.03824"},"FNet: Mixing Tokens with Fourier Transforms (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/ilyaeck/status/1393132270806966272"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.11447"},"True Few-Shot Learning with Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/EthanJPerez/status/1397015129506541570"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ethanjperez/true_few_shot"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/projects"},"End-to-end NLP workflows from prototype to production")," (",(0,n.kt)("a",{parentName:"li",href:"https://spacy.io/usage/projects"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/deepset-ai/haystack"},"Haystack")," - End-to-end Python framework for building natural language search interfaces to data. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29501045"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/PLMpapers"},"PLMpapers")," - Must-read Papers on pre-trained language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"},"English-to-Spanish translation with a sequence-to-sequence Transformer in Keras")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/lm-evaluation-harness"},"Evaluation Harness for Large Language Models")," - Framework for few-shot evaluation of autoregressive language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/mlp-gpt-jax"},"MLP GPT - Jax")," - GPT, made only of MLPs, in Jax."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2101.00438"},"Few-Shot Question Answering by Pretraining Span Selection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/oriram/splinter"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.04612"},"Neural Extractive Search (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://spike.neural-sim.apps.allenai.org/datasets"},"Demo"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/course/chapter1/1"},"Hugging Face NLP Course")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/course"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google/sentencepiece"},"SentencePiece")," - Unsupervised text tokenizer for Neural Network-based text generation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09685"},"LoRA: Low-Rank Adaptation of Large Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/LoRA"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/PromptPapers"},"PromptPapers")," - Must-read papers on prompt-based tuning for pre-trained language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/obsei/obsei"},"Obsei")," - Automation tool for text analysis need."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.03374"},"Evaluating Large Language Models Trained on Code (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/human-eval"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/SOS4NLP"},"Survey of Surveys for Natural Language Processing (SOS4NLP)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://colab.research.google.com/drive/1ED6_MYVXTApBHzQObUPaaMolgf9hZOOF"},"CLIP guided diffusion")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://codewords.recurse.com/issues/seven/data-driven-literary-analysis"},"Data driven literary analysis")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/borisdayma/dalle-mini"},"DALL\xb7E Mini")," - Generate images from a text prompt."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/obss/jury"},"Jury")," - Evaluation for Natural Language Generation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/recognai/rubrix"},"Rubrix")," - Free and open-source tool to explore, label, and monitor data for NLP projects."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08696"},"Knowledge Neurons in Pretrained Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/knowledge-neurons"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Hunter-DDM/knowledge-neurons"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mlfoundations/open_clip"},"OpenCLIP")," - Open source implementation of OpenAI's CLIP (Contrastive Language-Image Pre-training)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.03654"},"Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Alibaba-NLP/CLNER"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2101.06887"},"Can a Fruit Fly Learn Word Embeddings? (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JohnSnowLabs/spark-nlp"},"Spark NLP")," - Natural Language Processing library built on top of Apache Spark ML. (",(0,n.kt)("a",{parentName:"li",href:"https://nlp.johnsnowlabs.com/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JohnSnowLabs/spark-nlp-workshop"},"Spark NLP Workshop")," - Showcasing notebooks and codes of how to use Spark NLP in Python and Scala."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/commonsense/conceptnet-numberbatch"},"ConceptNet Numberbatch")," - Set of semantic vectors (also known as word embeddings) than can be used directly as a representation of word meanings."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/openai-codex/"},"OpenAI Codex")," - AI system that translates natural language to code. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=28131745"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.04473"},"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/GEM-benchmark/NL-Augmenter"},"NL-Augmenter")," - Collaborative Repository of Natural Language Transformations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ronxin.github.io/wevi/"},"wevi")," - Word embedding visual inspector. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ronxin/wevi"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rom1504/clip-retrieval"},"clip-retrieval")," - Easily computing clip embeddings and building a clip retrieval system with them."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/NeMo"},"NVIDIA NeMo")," - Toolkit for conversational AI."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ofirpress/attention_with_linear_biases"},"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/UKPLab/beir"},"BEIR")," - Heterogeneous benchmark containing diverse IR tasks. It also provides a common and easy framework for evaluation of your NLP-based retrieval models within the benchmark."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dbiir/UER-py"},"UER-py")," - Open Source Pre-training Model Framework in PyTorch & Pre-trained Model Zoo."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/neulab/ExplainaBoard"},"ExplainaBoard")," - Explainable Leaderboard for NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/utterworks/fast-bert"},"Fast-BERT")," - Super easy library for BERT based NLP models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stanford-oval/genie-toolkit"},"Genie Tookit")," - Generator of Natural Language Parsers for Compositional Virtual Assistants. (",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1904.09020"},"Paper"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://quantumstat.com/"},"Quantum Stat")," - Your NLP Model Training Platform."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stanford-crfm/mistral"},"Mistral")," - Framework for transparent and accessible large-scale language model training, built with Hugging Face. (",(0,n.kt)("a",{parentName:"li",href:"https://nlp.stanford.edu/mistral/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ebanalyse/NERDA"},"NERDA")," - Framework for fine-tuning pretrained transformers for Named-Entity Recognition (NER) tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/styfeng/DataAug4NLP"},"Data Augmentation Techniques for NLP")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mehdidc/feed_forward_vqgan_clip"},"Feed forward VQGAN-CLIP model")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/LIAAD/yake"},"Yet Another Keyword Extractor (Yake)")," - Unsupervised Approach for Automatic Keyword Extraction using Text Features."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.07445"},"Challenges in Detoxifying Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/IasonGabriel/status/1438497173897768960"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/airaria/TextBrewer"},"TextBrewer")," - PyTorch-based model distillation toolkit for natural language processing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.02555"},"GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.05093"},"PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ElementAI/picard"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nerdyrodent/VQGAN-CLIP"},"VQGAN-CLIP Overview")," - Repo for running VQGAN+CLIP locally."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.15011"},"TLDR: Extreme Summarization of Scientific Documents (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/allenai/scitldr"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.07154"},"Can Language Models be Biomedical Knowledge Bases? (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stanford-futuredata/ColBERT"},"ColBERT: Contextualized Late Interaction over BERT (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2007.08426"},"Investigating Pretrained Language Models for Graph-to-Text Generation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/UKPLab/plms-graph2text"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.informatik.tu-darmstadt.de/ukp/ukp_home/index.en.jsp"},"Ubiquitous Knowledge Processing Lab")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/UKPLab"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/fritshermans/deduplipy"},"DedupliPy")," - Python package for deduplication/entity resolution using active learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08825"},"Flexible Generation of Natural Language Deductions (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/alephic/ParaPattern"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/THUNLP-MT/MT-Reading-List"},"Machine Translation Reading List")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openreview.net/forum?id=SylKikSYDH"},"Compressive Transformers for Long-Range Sequence Modelling (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/compressive-transformer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kunaldahiya/pyxclib"},"pyxclib")," - Tools for multi-label classification problems."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/electra"},"ELECTRA")," - Pre-training Text Encoders as Discriminators Rather Than Generators."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/OpenPrompt"},"OpenPrompt")," - Open-Source Toolkit for Prompt-Learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.05448"},"Unsupervised Neural Machine Translation with Generative Language Models Only (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/jessemhan/status/1447793397675220997"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.08858"},"Grounding Spatio-Temporal Language with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/flowersteam/spatio-temporal-language-transformers/"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/oborchers/Fast_Sentence_Embeddings"},"Fast Sentence Embeddings (fse)")," - Compute Sentence Embeddings Fast."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.07178"},"Symbolic Knowledge Distillation: from General Language Models to Commonsense Models (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.surgehq.ai/"},"Surge AI")," - Build powerful NLP datasets using our global labeling force and platform. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/surge-ai/surge-python"},"Python SDK"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08027"},"Mirror-BERT: Converting Pretrained Language Models to universal text encoders without labels")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cambridgeltl/mirror-bert"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ogen-go/ogen"},"ogen")," - OpenAPI v3 code generator for go."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bigscience-workshop/promptsource"},"PromptSource")," - Toolkit for collecting and applying prompts to NLP datasets. (",(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/bigscience/T0pp"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=28905640"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.07775"},"Creating User Interface Mock-ups from High-Level Text Descriptions with Deep-Learning Models (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rrwick/Filtlong"},"Filtlong")," - Tool for filtering long reads by quality. It can take a set of long reads and produce a smaller, better subset."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.14739"},"Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/awslabs/pptod"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/xformers"},"xFormers")," - Hackable and optimized Transformers building blocks, supporting a composable construction."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2110.04888.pdf"},"Language Models As or For Knowledge Bases (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://wikipedia2vec.github.io/wikipedia2vec/"},"Wikipedia2Vec")," - Tool for learning vector representations of words and entities from Wikipedia. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/wikipedia2vec/wikipedia2vec"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://crfm.stanford.edu/2021/10/18/reflections.html"},"Reflections on Foundation Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/erikbryn/status/1451720985132945415"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/chartbeat-labs/textacy"},"textacy")," - NLP, before and after spaCy."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.coursera.org/specializations/natural-language-processing"},"Natural Language Processing Specialization Course")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/LysandreJik/status/1453436693391060997"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/philschmid/huggingface-sagemaker-workshop-series"},"Hugging Face on Amazon SageMaker Workshop")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ"},"CS224N: Natural Language Processing with Deep Learning | Winter 2021 - YouTube")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/jjvincent/status/1455194365169700864"},"GPT-3 creates geofoam, but out of text (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.07038"},"Towards Efficient NLP: A Standard Evaluation and A Strong Baseline (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/fastnlp/ElasticBERT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.13711"},"Hierarchical Transformers Are More Efficient Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29112983"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/hourglass-transformer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.06304"},"Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sf-wa-326/phrase-bert-topic-model"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://lastweekin.ai/p/gpt-3-is-no-longer-the-only-game"},"GPT-3 is no longer the only game in town (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29139884"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Tencent/PatrickStar"},"PatrickStar")," - Parallel Training of Large Language Models via a Chunk-based Memory Management."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"},"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mfrashad/text2art"},"Text2Art")," - AI Powered Text-to-Art Generator."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.02668"},"Emergent Communication of Generalizations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jayelm/emergent-generalization"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Albert-Ma/awesome-pretrained-models-for-information-retrieval"},"Awesome Pretrained Models for Information Retrieval")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Yale-LILY/SummerTime"},"SummerTime")," - Text Summarization Toolkit for Non-experts."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.04130"},"NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient Framework (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yaoxingcheng/TLM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.06500"},"Differentially Private Fine-tuning of Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/thegautamkamath/status/1450113340617940998"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.04198"},"TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yxuansu/TaCL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/eps696/aphantasia"},"Aphantasia")," - CLIP + FFT/DWT/RGB = text to image/video."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/api-no-waitlist/"},"OpenAI\u2019s API Now Available with No Waitlist (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29265640"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/izuna385/Entity-Linking-Recent-Trends"},"Recent trends of Entity Linking, Disambiguation, and Representation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://docs.cohere.ai/intro-to-llms/"},"Intro to Large Language Models with Cohere")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spacy-experimental"},"spacy-experimental")," - Cutting-edge experimental spaCy components and features."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Novetta/adaptnlp"},"AdaptNLP")," - High level framework and library for running, training, and deploying state-of-the-art Natural Language Processing (NLP) models for end to end tasks. (",(0,n.kt)("a",{parentName:"li",href:"https://novetta.github.io/adaptnlp/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/declare-lab/awesome-sentiment-analysis"},"Reading list for Awesome Sentiment Analysis papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ScalaConsultants/Aspect-Based-Sentiment-Analysis"},"Aspect-Based-Sentiment-Analysis: Transformer & Explainable ML (TensorFlow)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ELS-RD/transformer-deploy"},"Deploy optimized transformer based models in production")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/AnjanaRita/converse"},"PyConverse")," - Conversational text Analysis using various NLP techniques."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/KILT"},"KILT")," - Library for Knowledge Intensive Language Tasks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.09864"},"RoFormer: Enhanced Transformer with Rotary Position Embedding (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/rotary-embedding-torch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openreview.net/forum?id=GxjCYmQAody"},"N-grammer: Augmenting Transformers with latent n-grams (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/n-grammer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kootenpv/textsearch"},"textsearch")," - Find strings/words in text; convenience and C speed."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.packtpub.com/product/mastering-spacy/9781800563353"},"Mastering spaCy Book (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/PacktPublishing/Mastering-spaCy"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/sense2vec"},"sense2vec")," - Contextually-keyed word vectors."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.15588"},"Pureformer: Do We Even Need Attention? (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PaddlePaddle/Knover"},"Knover")," - Toolkit for knowledge grounded dialogue generation based on PaddlePaddle."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://deepmind.com/blog/article/language-modelling-at-scale"},"Language Modelling at Scale: Gopher, Ethical considerations, and Retrieval | DeepMind (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29486607"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PL8PYTP1V4I8AYSXn_GKVgwXVluCT9chJ6"},"CMU Advanced NLP 2021 - YouTube")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/RasaHQ/whatlies"},"whatlies"),' - Toolkit to help understand "what lies" in word embeddings. Also benchmarking.'),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nerdyrodent/CLIP-Guided-Diffusion"},"CLIP-Guided-Diffusion")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.05240"},"Factual Probing Is [MASK]: Learning vs. Learning to Recall (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-nlp/OptiPrompt"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.07610"},"Improving Compositional Generalization with Latent Structure and Data Augmentation (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kakaobrain/pororo"},"PORORO")," - Platform Of neuRal mOdels for natuRal language prOcessing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.08499"},"PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/allenai/PRIMER"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://evjang.com/2021/12/17/lang-generalization.html"},"To Understand Language Is to Understand Generalization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29600510"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.16668"},"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/mixture-of-experts"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/georgian-io/Multimodal-Toolkit"},"Multimodal Transformers | Transformers with Tabular Data")," (",(0,n.kt)("a",{parentName:"li",href:"https://medium.com/georgian-impact-blog/how-to-incorporate-tabular-data-with-huggingface-transformers-b70ac45fcfb4"},"Article"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.11575"},"Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dmis-lab/excord"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://deepmind.com/research/publications/2021/improving-language-models-by-retrieving-from-trillions-of-tokens"},"Improving Language Models by Retrieving from Trillions of Tokens (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/gkiril/oie-resources"},"Open Information Extraction (OIE) Resources")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1905.09217v1"},"Deeper Text Understanding for IR with Contextual Neural Language Modeling (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/AdeDZY/SIGIR19-BERT-IR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/x-clip"},"x-clip")," - Concise but complete implementation of CLIP with various experimental improvements from recent papers."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thesephist/calamity"},"Calamity")," - Self-hosted GPT playground."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://aclanthology.org/2021.acl-long.80/"},"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/voxpopuli"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://aclanthology.org/events/tacl-2021/"},"Transactions of the Association for Computational Linguistics (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/HelloRusk/entity-related-papers"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Spico197/DocEE"},"DocEE")," - Toolkit for document-level event extraction, containing some SOTA model implementations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2010.00904"},"Autoregressive Entity Retrieval (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.07672"},"Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.14373"},"A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.06499"},"Deduplicating Training Data Makes Language Models Better (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/deduplicate-text-datasets"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1910.05895"},"Transformers without Tears: Improving the Normalization of Self-Attention (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/tnq177/transformers_without_tears"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/githubharald/CTCDecoder"},"CTCDecoder")," - Connectionist Temporal Classification (CTC) decoding algorithms: best path, beam search, lexicon search, prefix search, and token passing. Implemented in Python."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amrrs/custom-ner-with-spacy3"},"Custom Named Entity Recognition with Spacy3")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.11520"},"BARTScore: Evaluating Generated Text as Text Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/neulab/BARTScore"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kakaobrain/minDALL-E"},"minDALL-E on Conceptual Captions")," - PyTorch implementation of a 1.3B text-to-image generation model trained on 14 million image-text pairs."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2010.10042"},"Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ysmiura/ifcc"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.08207"},"Multitask Prompted Training Enables Zero-Shot Task Generalization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/bigscience-workshop/t-zero"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spacy-models"},"spaCy models")," - Models for the spaCy Natural Language Processing (NLP) library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/huggingface/awesome-huggingface"},"Awesome Huggingface")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tensordot/syntaxdot"},"SyntaxDot")," - Neural syntax annotator, supporting sequence labeling, lemmatization, and dependency parsing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stephenleo/stripnet"},"STriP Net")," - Semantic Similarity of Scientific Papers (S3P) Network."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/webis-de/small-text"},"Small-Text")," - Active Learning for Text Classification in Python."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1912.02164"},"Plug and Play Language Models: A Simple Approach to Controlled Text Generation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/uber-research/PPLM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sberbank-ai/ru-dolph"},"RuDOLPH")," - One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wxl1999/PLMPapers"},"PLM papers")," - Paper list of pre-trained language models (PLMs)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bigscience-workshop/Megatron-DeepSpeed"},"Ongoing research training transformer language models at scale, including: BERT & GPT-2")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.04426"},"Improving language models by retrieving from trillions of tokens (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/RETRO-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dvlab-research/Entity"},"EntitySeg Toolbox")," - Towards precise and open-world image segmentation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/instruction-following/"},"Aligning Language Models to Follow Instructions (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/janleike/status/1486731620656640010"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/following-instructions-human-feedback"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.08808"},"Simple Questions Generate Named Entity Recognition Datasets (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dmis-lab/GeNER"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1910.11494"},"KRED: Knowledge-Aware Document Representation for News Recommendations (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/danyang-liu/KRED"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nlp.stanford.edu/software/openie.html"},"Stanford Open Information Extraction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/philipperemy/stanford-openie-python"},"Python3 wrapper for Stanford OpenIE")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2101.01321"},"I-BERT: Integer-only BERT Quantization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/kssteven418/I-BERT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/KennethEnevoldsen/spacy-wrap"},"spaCy-wrap")," - Wrapping fine-tuned transformers in spaCy pipelines."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/anhaidgroup/deepmatcher"},"DeepMatcher")," - Python package for performing Entity and Text Matching using Deep Learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.06249"},"Machine Reading Comprehension: The Role of Contextualized Language Models and Beyond (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cooelf/AwesomeMRC"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/medspacy/medspacy"},"medspacy")," - Library for clinical NLP with spaCy."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"},"Natural Language Processing with Transformers Book")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nlp-with-transformers/notebooks"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ohmeow/blurr"},"blurr")," - Library that integrates huggingface transformers with the world of fastai, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hankcs/HanLP"},"HanLP")," - Multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image"},"Awesome Text-to-Image")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://newsletter.ruder.io/"},"NLP News Newsletter")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://aclanthology.org/2020.acl-main.577/"},"Named Entity Recognition as Dependency Parsing (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/juntaoy/biaffine-ner"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/FreddeFrallan/Multilingual-CLIP"},"Multilingual-CLIP")," - OpenAI CLIP text encoders for any language."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/FasterTransformer"},"FasterTransformer")," - Transformer related optimization, including BERT, GPT."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/causaltext/causal-text-papers"},"Papers about Causal Inference and Language")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NetEase-FuXi/EET"},"EET (Easy and Efficient Transformer)")," - Efficient PyTorch inference plugin focus on Transformer-based models with large model sizes and long sequences."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2009.03300"},"Measuring Massive Multitask Language Understanding (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hendrycks/test"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.14660"},"A Theoretical Analysis of the Repetition Problem in Text Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/fuzihaofzh/repetition-problem-nlg"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/HHousen/TransformerSum"},"TransformerSum")," - Models to perform neural summarization (extractive and abstractive) using machine learning transformers and a tool to convert abstractive summarization datasets to the extractive task."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://transformersbook.com/"},"Natural Language Processing with Transformers Book")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.06991"},"Transformer Memory as a Differentiable Search Index (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30356264"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/arankomatsuzaki/status/1493767303661383682"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2003.10555"},"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/electra-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/explosion/spacy-stanza"},"spaCy + Stanza")," - Use the latest Stanza (StanfordNLP) research models directly in spaCy."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tstanislawek/awesome-document-understanding"},"Awesome Document Understanding")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/adaptive-span"},"Sequential Transformer")," - Code for training Transformers on sequential tasks such as language modeling."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hanxiao/bert-as-service"},"bert-as-service")," - Mapping a variable-length sentence to a fixed-length vector using BERT model."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.06417"},"A Contrastive Framework for Neural Text Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yxuansu/SimCTG"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/uber-research/parallax"},"Parallax")," - Tool for interactive embeddings visualization."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/anandsm7/BERT_as_serverless_service"},"Serve PyTorch model as an API using AWS + serverless framework")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.12246"},"Neural reality of argument structure constructions (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.00555"},"DeepNet: Scaling Transformers to 1,000 Layers (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30533914"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/VHellendoorn/Code-LMs"},"Large Models of Source Code")," - Guide to using pre-trained large language models of source code."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.03691"},"HyperMixer: An MLP-based Green AI Alternative to Transformers (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/NLP-THU"},"NLP Course Material & QA")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NiuTrans/ABigSurvey"},"Survey of Surveys (NLP & ML)")," - Collection of 700+ survey papers on Natural Language Processing (NLP) and Machine Learning (ML)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yzhuoning/Awesome-CLIP"},"Awesome CLIP")," - Awesome list for research on CLIP (Contrastive Language-Image Pre-Training)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Aleph-Alpha/magma"},"MAGMA")," - GPT-style multimodal model that can understand any combination of images and language."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/paulrinckens/timexy"},"Timexy")," - spaCy custom component that extracts and normalizes temporal expressions."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/blog/gpt-3-edit-insert/"},"New Capabilities for GPT-3: Edit and Insert (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30689902"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://bigscience.huggingface.co/blog/which-hardware-to-train-a-176b-parameters-model"},"Which hardware to train a 176B parameters model? (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/BigscienceW/status/1503775017653391369"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dair-ai/nlp_fundamentals"},"Fundamentals of NLP")," - Series of hands-on notebooks for learning the fundamentals of NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jessevig/bertviz"},"BertViz")," - Visualize Attention in Transformer Models (BERT, GPT2, BART, etc.)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1706.03762"},"Attention Is All You Need (2017)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/bkoch4142/attention-is-all-you-need-paper"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hyunwoongko/transformer"},"PyTorch Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/word2vec-explained-49c52b4ccb71"},"Word2Vec Explained. Explaining the Intuition of Word2Vec (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30820299"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/minimaxir/imgbeddings"},"imgbeddings")," - Python package to generate image embeddings with CLIP without PyTorch/TensorFlow."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ysymyth/ec-nl"},"Linking Emergent and Natural Languages via Corpus Transfer (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://carolchen.me/blog/transformer-inference-arithmetic/"},"Transformer Inference Arithmetic (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.15556"},"Training Compute-Optimal Large Language Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/karpathy/status/1509227367302148098"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TimSchopf/KeyphraseVectorizers"},"KeyphraseVectorizers")," - Set of vectorizers that extract keyphrases with part-of-speech patterns from a collection of text documents and convert them into a document-keyphrase matrix."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PrithivirajDamodaran/Gramformer"},"Gramformer")," - Framework for detecting, highlighting and correcting grammatical errors on natural language text."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Pandora-Intelligence/classy-classification"},"Classy Classification")," - Easy and intuitive approach to few-shot classification using sentence-transformers or spaCy models, or zero-shot classificaiton with Huggingface."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Sphere"},"Sphere")," - Web-scale retrieval for knowledge-intensive NLP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/mutransformers"},"muTransformers")," - Common Huggingface transformers in maximal update parametrization (\xb5P)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/BaptisteBlouin/EventExtractionPapers"},"Event Extraction papers")," - List of NLP resources focused on event extraction task."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xcfcode/Summarization-Papers"},"Summarization Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Jack000/glid-3"},"GLID-3")," - Combination of OpenAI GLIDE, Latent Diffusion and CLIP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/AlekseyKorshuk/optimum-transformers"},"Optimum Transformers")," - Accelerated NLP pipelines for fast inference on CPU and GPU. Built with Transformers, Optimum and ONNX Runtime."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html"},"Pathways Language Model (PaLM): Scaling to 540B parameters (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30908941"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/PaLM-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hpcaitech/PaLM-colossalai"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.06190"},"A Divide-and-Conquer Approach to the Summarization of Long Documents (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/AlexGidiotis/DANCER-summ"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/stepthom/text_mining_resources"},"Resources for learning about Text Mining and Natural Language Processing")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.15827"},"LinkBERT: Pretraining Language Models with Document Links (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/michiyasunaga/LinkBERT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openai.com/dall-e-2/"},"Dall-E 2 (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30932095"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/sama/status/1511724264629678084"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/OpenAI/status/1511714511673126914"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rish-16/dalle2-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/DALLE2-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/dalle-2-preview"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/BecomingCritter/status/1511808277490896903"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/nickcammarata/status/1511861061988892675"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30961385"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=X3_LD3R_Ygs"},"Video Summary"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31228710"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/irinarish/status/1520768296290861059"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1602.03606"},"Variations of the Similarity Function of TextRank for Automated Summarization (2016)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/summanlp/textrank"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.10157"},"Logic-Guided Data Augmentation and Regularization for Consistent Question Answering (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/AkariAsai/logic_guided_qa"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dkozlov/awesome-knowledge-distillation"},"Awesome Knowledge Distillation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hustvl/YOLOS"},"You Only One Sequence (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.13219"},"Towards Understanding and Mitigating Social Biases in Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/pliang279/LM_bias"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.02492"},"DialogLM: Pre-trained Model for Long Dialogue Understanding and Summarization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/DialogLM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://programmatic.humanloop.com/"},"Humanloop Programmatic")," - Create large high-quality datasets for NLP in minutes. No hand labelling required. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30955699"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://socraticmodels.github.io/"},"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/russelljkaplan/status/1513128005828165634"},"Second order effects of the rise of large language models (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/labmlai/neox"},"Simple Annotated implementation of GPT-NeoX in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.04696"},"BLEURT: Learning Robust Metrics for Text Generation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/bleurt"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hazyresearch.stanford.edu/bootleg/"},"Bootleg")," - Self-supervised named entity disambiguation (NED) system that links mentions in text to entities in a knowledge base. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/HazyResearch/bootleg"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/EleutherAI/DALLE-mtf"},"DALL-E in Mesh-TensorFlow")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.bramadams.dev/projects/dalle-tricks"},"A few things to try with DALL\xb7E (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31009129"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=RJwPN4qNi_Y"},"Google's 540B PaLM Language Model & OpenAI's DALL-E 2 Text-to-Image Revolution (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.06361"},"Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunlp/BkdAtk-LWS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1710.10723"},"Simple and Effective Multi-Paragraph Reading Comprehension (2017)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/allenai/document-qa"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.quantamagazine.org/researchers-glimpse-how-ai-gets-so-good-at-language-processing-20220414/"},"Researchers Glimpse How AI Gets So Good at Language Processing (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit"},"Cornell Conversational Analysis Toolkit (ConvoKit)")," - Toolkit for extracting conversational features and analyzing social phenomena in conversations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.05966"},"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/HKUNLP/UnifiedSKG"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bhoov/exbert"},"exBERT")," - Visual Analysis Tool to Explore Learned Representations in Transformers Models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.assemblyai.com/blog/how-dall-e-2-actually-works/"},"How DALL-E 2 Works (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31084312"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/"},"Getting started with NLP for absolute beginners (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alibaba/EasyNLP"},"EasyNLP")," - Comprehensive and Easy-to-use NLP Toolkit."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.08674"},"Reframing Human-AI Collaboration for Generating Free-Text Explanations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/mark_riedl/status/1516815203517751303"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/unitaryai/detoxify"},"Detoxify")," - Comment Classification with PyTorch Lightning and Transformers."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dlatk/dlatk"},"DLATK")," - End to end human text analysis package, specifically suited for social media and social scientific applications."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.11370"},"Language modeling via stochastic processes (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rosewang2008/language_modeling_via_stochastic_processes"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.13023"},"An Enhanced Span-based Decomposition Method for Few-Shot Sequence Labeling (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Wangpeiyi9979/ESD"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1911.03437"},"SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/archinetai/smart-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ExpressAI/DataLab"},"DataLab")," - Unified platform that allows for NLP researchers to perform a number of data-related tasks in an efficient and easy-to-use manner."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/benjamin_hilton/status/1520032772072607747"},"Limitations of DALL-E")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31218915"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ucinlp/autoprompt"},"AutoPrompt")," - Automatic Prompt Construction for Masked Language Models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jina-ai/dalle-flow"},"DALL\xb7E Flow")," - Human-in-the-Loop workflow for creating HD images from text."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kabirkhan/recon"},"Recon NER")," - Debug and correct annotated Named Entity Recognition (NER) data for inconsitencies and get insights on improving the quality of your data."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amaiya/causalnlp"},"CausalNLP"),' - Practical toolkit for causal inference with text as treatment, outcome, or "controlled-for" variable.'),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.01068"},"OPT: Open Pre-trained Transformer Language Models (2022)")," - Meta's 175B parameter language model. (",(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/MachineLearning/comments/uh5e2f/r_meta_is_releasing_a_175b_parameter_language/"},"Reddit"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/WriteArthur/status/1521987954994192384"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dmmiller612/bert-extractive-summarizer"},"Bert Extractive Summarizer")," - Easy to use extractive text summarization with BERT."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2009.06978"},"Dialogue Response Ranking Training with Large-Scale Human Feedback Data (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/golsun/DialogRPT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mega002/lm-debugger"},"LM-Debugger")," - Interactive tool for inspection and intervention in transformer-based language models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/schrep/status/1521850083792154624"},"100 Pages of raw notes released with the language model OPT-175")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31260665"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.07937"},"Unsupervised Cross-Task Generalization via Retrieval Augmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/INK-USC/ReCross"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/SemanticDebugger"},"On Continual Model Refinement in Out-of-Distribution Data Streams (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Jack000/glid-3-xl"},"GLID-3-XL")," - 1.4B latent diffusion model from CompVis back-ported to the guided diffusion codebase."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.fastforwardlabs.com/2022/05/05/neutralizing-subjectivity-bias-with-huggingface-transformers.html"},"Neutralizing Subjectivity Bias with HuggingFace Transformers (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.09192"},"Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/g8a9/ear"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/peppeatta/status/1522230686832336897"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/go-ego/gse"},"gse")," - Go efficient multilingual NLP and text segmentation; support english, chinese, japanese and other."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.pinecone.io/learn/bertopic/"},"BERTopic: The Future of Topic Modeling (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31341250"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.05131"},"Unifying Language Learning Paradigms (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/google-research/tree/master/ul2"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.10360"},"GLM: General Language Model Pretraining with Autoregressive Blank Infilling (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/THUDM/GLM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/npew/status/1525900849888866307"},"GPT-3 limitations (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.nlpdemystified.org/"},"Natural Language Processing Demystified")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Pandora-Intelligence/concise-concepts"},"Concise Concepts")," - Contains an easy and intuitive approach to few-shot NER using most similar expansion over spaCy embeddings. Now with entity scoring."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.deepmind.com/publications/dynamic-language-understanding-adaptation-to-new-knowledge-in-parametric-and-semi-parametric-models"},"Dynamic language understanding: adaptation to new knowledge in parametric and semi-parametric models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/DeepMind/status/1529846251558256642"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bminixhofer/nlprule"},"nlprule")," - Fast, low-resource Natural Language Processing and Text Correction library written in Rust."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.13636"},"Quark: Controllable Text Generation with Reinforced Unlearning (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/rajammanabrolu/status/1531308092629012485"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/giannis_daras/status/1531693093040230402"},"DALL-E 2 has a secret language")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31573282"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/benjamin_hilton/status/1531780892972175361"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31587316"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/adatest"},"AdaTest")," - Find and fix bugs in natural language machine learning models using adaptive testing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.14217"},"Diffusion-LM Improves Controllable Text Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/XiangLi1999/Diffusion-LM"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/percyliang/status/1533977616666923008"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.08678"},"RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/salesforce/rng-kbqa"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Davidzhangyuanhan/NOAH"},"Neural Prompt Search")," - Searching prompt modules for parameter-efficient transfer learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/karpathy/makemore"},"makemore")," - Most accessible way of tinkering with a GPT - one hackable script."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/saharmor/dalle-playground"},"DALL-E Playground")," - Playground for DALL-E enthusiasts to tinker with the open-source version of OpenAI's DALL-E, based on DALL-E Mini."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ryanzhumich/Contrastive-Learning-NLP-Papers"},"Contrastive Learning for Natural Language Processing"))))}g.isMDXComponent=!0}}]);
"use strict";(self.webpackChunkkinderheim=self.webpackChunkkinderheim||[]).push([[986],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return c}});var i=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,i,r=function(e,t){if(null==e)return{};var a,i,r={},n=Object.keys(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=i.createContext({}),m=function(e){var t=i.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=m(e.components);return i.createElement(s.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef((function(e,t){var a=e.components,r=e.mdxType,n=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=m(a),c=r,g=u["".concat(s,".").concat(c)]||u[c]||h[c]||n;return a?i.createElement(g,o(o({ref:t},p),{},{components:a})):i.createElement(g,o({ref:t},p))}));function c(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=a.length,o=new Array(n);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var m=2;m<n;m++)o[m]=a[m];return i.createElement.apply(null,o)}return i.createElement.apply(null,a)}u.displayName="MDXCreateElement"},19305:function(e,t,a){a.r(t),a.d(t,{assets:function(){return p},contentTitle:function(){return s},default:function(){return c},frontMatter:function(){return l},metadata:function(){return m},toc:function(){return h}});var i=a(87462),r=a(63366),n=(a(67294),a(3905)),o=["components"],l={},s="Computer vision",m={unversionedId:"computer-graphics/computer-vision/computer-vision",id:"computer-graphics/computer-vision/computer-vision",title:"Computer vision",description:"LiT (Locked-image Tuning) paper is neat. Trying to understand Vision Transformers. Kornia seems like a great library. Imagen is fascinating.",source:"@site/docs/computer-graphics/computer-vision/computer-vision.md",sourceDirName:"computer-graphics/computer-vision",slug:"/computer-graphics/computer-vision/",permalink:"/kinderheim/computer-graphics/computer-vision/",draft:!1,editUrl:"https://github.com/ecioran/kinderheim/docs/computer-graphics/computer-vision/computer-vision.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"B\xe9zier curves",permalink:"/kinderheim/computer-graphics/bezier-curves"},next:{title:"Optical character recognition",permalink:"/kinderheim/computer-graphics/computer-vision/ocr"}},p={},h=[{value:"Links",id:"links",level:2}],u={toc:h};function c(e){var t=e.components,a=(0,r.Z)(e,o);return(0,n.kt)("wrapper",(0,i.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"computer-vision"},"Computer vision"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://twitter.com/giffmana/status/1508400604082806785"},"LiT (Locked-image Tuning)")," paper is neat. Trying to understand ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/lucidrains/vit-pytorch"},"Vision Transformers"),". ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/kornia/kornia"},"Kornia")," seems like a great library. ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/lucidrains/imagen-pytorch"},"Imagen")," is fascinating."),(0,n.kt)("h2",{id:"links"},"Links"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv"},"OpenCV")," - Open Source Computer Vision Library. (",(0,n.kt)("a",{parentName:"li",href:"https://opencv.org/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=oXlwWbU8l2o"},"OpenCV Course"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dmlc/gluon-cv"},"Gluon CV Toolkit")," - Provides implementations of the sate-of-the-art (SOTA) deep learning models in computer vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pythia"},"Pythia")," - Modular framework for vision and language multimodal research. Built on top of PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zllrunning/video-object-removal"},"video-object-removal")," - Just draw a bounding box and you can remove the object you want to remove."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hybridgroup/gocv"},"GoCV")," - Go package for computer vision using OpenCV 4 and beyond."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/osmr/imgclsmob"},"Sandbox for training convolutional networks for computer vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.pyimagesearch.com/start-here/"},"Get started with Computer Vision, Deep Learning, and OpenCV")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/donnyyou/torchcv"},"TorchCV")," - PyTorch-Based Framework for Deep Learning in Computer Vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/habitat-sim"},"AI Habitat")," - Flexible, high-performance 3D simulator for Embodied AI research."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kornia/kornia"},"Kornia")," - Open Source Differentiable Computer Vision Library for PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://kornia.github.io//"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://roboflow.com/"},"Roboflow")," - Raw images to trained computer vision model. (",(0,n.kt)("a",{parentName:"li",href:"https://nickarner.com/notes/roboflow-memo-february-1-2021/"},"Article"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/SlowFast"},"PySlowFast")," - Open source video understanding codebase from FAIR that provides state-of-the-art video classification models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://brohrer.github.io/images_to_numbers.html"},"How to Convert a Picture to Numbers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jbhuang0604/awesome-computer-vision"},"Awesome Computer Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p"},"The Ancient Secrets of Computer Vision (2018)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=fpw26tpHGr8&list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI"},"Variational Methods for Computer Vision lectures (2013)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/ClassyVision"},"Classy Vision")," - New end-to-end, PyTorch-based framework for large-scale training of state-of-the-art image and video classification models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alicevision/meshroom"},"Meshroom")," - 3D Reconstruction Software."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://alicevision.org/"},"AliceVision")," - Photogrammetric Computer Vision Framework. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/alicevision/AliceVision"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/alicevision"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pytorch3d"},"PyTorch3d")," - Provides efficient, reusable components for 3D Computer Vision research with PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://pytorch3d.org/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ageitgey/face_recognition"},"Face Recognition")," - World's simplest facial recognition api for Python and the command line."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/votenet"},"Deep Hough Voting for 3D Object Detection in Point Clouds")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PointCloudLibrary/pcl"},"Point Cloud Library")," - Standalone, large scale, open project for 2D/3D image and point cloud processing."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jasonmayes/Real-Time-Person-Removal"},"Disappearing-People")," - Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=22353596"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/computervision-recipes"},"Best Practices, code samples, and documentation for Computer Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amzn/computer-vision-basics-in-microsoft-excel"},"Computer Vision Basics in Microsoft Excel")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2002.10880"},"PolyGen: An Autoregressive Generative Model of 3D Meshes (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/strasdat/Sophus"},"Sophus")," - C++ implementation of Lie Groups using Eigen."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MIPT-Oulu/solt"},"SOLT")," - Streaming over lightweight data transformations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jiachenli94/Awesome-Interaction-aware-Trajectory-Prediction"},"Awesome Interaction-aware Behavior and Trajectory Prediction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.robots.ox.ac.uk/~ow/synsin.html"},"SynSin: End-to-end View Synthesis from a Single Image (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/synsin"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nywang16/Pixel2Mesh"},"Pixel2Mesh")," - Generating 3D Mesh Models from Single RGB Images."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://aliaksandrsiarohin.github.io/first-order-model-website/"},"First Order Motion Model for Image Animation")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/AliaksandrSiarohin/first-order-model"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cleardusk/3DDFA"},"PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alex04072000/ObstructionRemoval"},"Learning to See Through Obstructions")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yl-1993/learn-to-cluster"},"Learning to Cluster Faces on an Affinity Graph (LTC)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alievk/avatarify"},"Avatarify")," - Avatars for Zoom and Skype."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Maclory/SPSR"},"SPSR")," - PyTorch implementation of Structure-Preserving Super Resolution with Gradient Guidance."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/HolmesShuan/OISR-PyTorch"},"OISR-PyTorch"),' - PyTorch implementation of "ODE-inspired Network Design for Single Image Super-Resolution.'),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vt-vl-lab/3d-photo-inpainting"},"3D Photography using Context-aware Layered Depth Inpainting")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/youngwanLEE/CenterMask"},"CenterMask : Real-Time Anchor-Free Instance Segmentation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=lWwkbiufwNE"},"Interview with Dmytro Mushkin | Computer Vision Research | Kaggle, ML & Education (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/devendrachaplot/Neural-SLAM"},'Pytorch code for ICLR-20 Paper "Learning to Explore using Active Neural SLAM"')),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kylemcdonald/FaceTracker"},"FaceTracker")," - Real time deformable face tracking in C++ with OpenCV 3."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ChaofWang/Awesome-Super-Resolution"},"Awesome Super Resolution")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/podgorskiy/ALAE"},"Adversarial Latent Autoencoders")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mp3guy/ElasticFusion"},"ElasticFusion")," - Real-time dense visual SLAM system capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tancik/StegaStamp"},"StegaStamp: Invisible Hyperlinks in Physical Photographs")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yemount/pose-animator/"},"Pose Animator")," - Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23124786"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/fvcore"},"fvcore")," - Collection of common code that's shared among different research projects in FAIR computer vision team."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://ai.stanford.edu/blog/selfsupervised-multimodal/"},"Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cyrildiagne/screenpoint"},"ScreenPoint")," - Project an image centroid to another image using OpenCV."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NathanUA/U-2-Net"},"U^2-Net"),' - Code for our newly accepted paper in Pattern Recognition 2020: "U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection".'),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/fepegar/torchio"},"TorchIO")," - Tools for medical image processing in deep learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/anandpawara/Real_Time_Image_Animation"},"Real time Image Animation in OpenCV using first order model")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23312259"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/openmv/openmv"},"OpenMV (Open-Source Machine Vision)")," - Aims at making machine vision more accessible to beginners by developing a user-friendly, open-source, low-cost machine vision platform."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sense-X/TSD"},"TSD")," - 1st place models in Google OpenImage Detection Challenge 2019."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZJULearning/ttfnet"},"Training-Time-Friendly Network for Real-Time Object Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/big_transfer"},"Big Transfer (BiT): General Visual Representation Learning")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ilovepose/fast-human-pose-estimation.pytorch"},"Fast Human Pose Estimation CVPR2019")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/leoxiaobin/deep-high-resolution-net.pytorch"},"Deep High-Resolution Representation Learning for Human Pose Estimation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/senguptaumd/Background-Matting"},"Background Matting: The World is Your Green Screen")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/detr"},"DE\u2af6TR: End-to-End Object Detection with Transformers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/shunsukesaito/PIFu"},"PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xingyizhou/CenterTrack"},"Tracking Objects as Points")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mkocabas/VIBE"},"VIBE")," - Video Inference for Human Body Pose and Shape Estimation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/idearibosome/srzoo"},"SRZoo")," - Integrated repository for super-resolution using deep learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Cartucho/mAP"},"mAP (mean Average Precision)")," - Evaluates the performance of your neural net for object recognition."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jiashunwang/Neural-Pose-Transfer"},"Neural Pose Transfer by Spatially Adaptive Instance Normalization (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/weihaox/awesome-neural-rendering"},"Awesome Neural Rendering")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wvangansbeke/Unsupervised-Classification"},"Learning To Classify Images Without Labels")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mit-han-lab/dlg"},"Deep Leakage From Gradients (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.3dflow.net/"},"3Dflow")," - Offers customized computer vision software solutions."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wkentaro/labelme"},"labelme")," - Image Polygonal Annotation with Python."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wkentaro/imgviz"},"imgviz")," - Image Visualization Tools."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wukaoliu/CVPR2020-HAttMatting"},"Attention-Guided Hierarchical Structure Aggregation for Image Matting")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.roboflow.ai/yolov5-is-here/"},"YOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23478151"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ultralytics/yolov5"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/joe-siyuan-qiao/DetectoRS"},"DetectoRS")," - Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thepowerfuldeez/facemesh.pytorch"},"PyTorch implementation of paper Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kdexd/virtex"},"VirTex: Learning Visual Representations from Textual Annotations")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pifuhd"},"High-Resolution 3D Human Digitization from A Single Image")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ifzhang/FairMOT"},"FairMOT")," - Simple baseline for one-shot multi-object tracking."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://vsitzmann.github.io/siren/"},"Implicit Neural Representations with Periodic Activation Functions (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mseg-dataset/mseg-semantic"},"MSeg: A Composite Dataset for Multi-Domain Segmentation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/CuriousAI/mean-teacher"},"Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmdetection"},"MMDetection")," - OpenMMLab Detection Toolbox and Benchmark."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/noahtren/Fourier-Feature-Networks-TensorFlow-2"},"Fourier Feature Networks in TensorFlow 2")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://vision.ee.ethz.ch/"},"Computer Vision Lab | ETH Zurich")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5"},"PyTorch Computer Vision Library for Experts and Beginners (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/balavenkatesh3322/CV-pretrained-model"},"Computer Vision Pretrained Models")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://sandlab.cs.uchicago.edu/fawkes/"},"Fawkes: Image \u201cCloaking\u201d for Personal Privacy")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=23917337"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Motion-Project/motion"},"Motion")," - Software motion detector."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nextjournal.com/nirmal-suthar/supervised-3d-mesh-reconstruction"},"Supervised 3D Mesh Reconstruction (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nerf-w.github.io/"},"NeRF in the Wild")," - Neural Radiance Fields for Unconstrained Photo Collections."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1912.03207"},"NASA: Neural Articulated Shape Approximation (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2008.06365v2"},"An Overview of Deep Learning Architectures in Few-Shot Learning Domain (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1803.11288"},"FutureMapping: The Computational Structure of Spatial AI Systems (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/AjdDavison/status/1045617261925543937"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/"},"Optimal Peanut Butter and Banana Sandwiches (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/eprosenthal/status/1298290961294950401"},"Twitter"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://justinmeiners.github.io/gesture-recognition/"},"Gesture Recognition with Line Integrals")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/justinmeiners/gesture-recognition"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://slazebni.cs.illinois.edu/spring20/"},"Computer Vision: Looking Back to Look Forward (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/baowenbo/DAIN"},"DAIN (Depth-Aware Video Frame Interpolation)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://picsellia.com/"},"Picsellia")," - Development platform dedicated to Computer Vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vita-epfl/openpifpaf"},'Official implementation of "PifPaf: Composite Fields for Human Pose Estimation" in PyTorch')),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://link.springer.com/chapter/10.1007/3-540-46805-6_19"},"Object Recognition with Gradient-Based Learning (1999)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/imaginaire"},"Imaginaire")," - NVIDIA PyTorch GAN library with distributed and mixed precision support. (",(0,n.kt)("a",{parentName:"li",href:"http://imaginaire.cc/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/floe/deepbacksub"},"DeepBackSub")," - Virtual Video Device for Background Replacement with Deep Semantic Segmentation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kuanhungchen/awesome-tiny-object-detection"},"Awesome Tiny Object Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vt-vl-lab/FGVC"},"Flow-edge Guided Video Completion")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/"},"5 Things to look for in a Computer Vision startup job (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=Gl48KciWZp0"},"Transformers for Image Recognition at Scale (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24754538"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MIC-DKFZ/nnUNet"},"nnU-Net")," - Segmentation method that is designed to deal with the dataset diversity."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MIC-DKFZ/batchgenerators"},"batchgenerators")," - Framework for data augmentation for 2D and 3D image classification and segmentation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.lookuq.com/create-your-own-app"},"Lookuq")," - App to create object detection projects without coding. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=24784680"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/deepinsight/insightface"},"InsightFace")," - Face Analysis Project on MXNet. (",(0,n.kt)("a",{parentName:"li",href:"http://insightface.ai/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/swav"},"PyTorch implementation of SwAV (Swapping Assignments between Views)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Alibaba-MIIL/ASL"},"Asymmetric Loss For Multi-Label Classification in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/adobe/antialiased-cnns"},"Antialiased CNNs")," - Making Convolutional Networks Shift-Invariant Again."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/richzhang/PerceptualSimilarity"},"Perceptual Similarity Metric and Dataset")," - Unreasonable Effectiveness of Deep Features as a Perceptual Metric."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/deeppomf/DeepLearningAnimePapers"},"Deep Learning Anime Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/vision_transformer"},"Vision Transformer")," - Models from the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MIDIBlocks/handsfree"},"Handsfree.js")," - Wrapper library around computer vision models for working with face pointers, assistive tech, and creative expression. (",(0,n.kt)("a",{parentName:"li",href:"https://handsfreejs.glitch.me/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amirgholami/ZeroQ"},"ZeroQ: A Novel Zero Shot Quantization Framework")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amirgholami/SqueezeNext"},"SqueezeNext")," - Contains the Caffe implementation of SqueezeNext."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/amirgholami/anode"},"ANODE: Adjoint Based Neural ODEs")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/AdamSpannbauer/python_video_stab"},"Python Video Stabilization using OpenCV")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers"},"Recent Advances in Vision and Language PreTrained Models (VL-PTMs)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kuangliu/torchcv"},"TorchCV")," - PyTorch vision library mimics ChainerCV."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jeonsworld/ViT-pytorch"},"Vision Transformer in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/perone/medicaltorch"},"MedicalTorch")," - Medical imaging framework for PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://medicaltorch.readthedocs.io/en/stable/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/elcorto/imagecluster"},"imagecluster")," - Cluster images based on image content using a pre-trained deep neural network, optional time distance scaling and hierarchical clustering."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alankbi/detecto"},"Detecto")," - Build fully-functioning computer vision models with PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://detecto.readthedocs.io/en/latest/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/thoughtworksarts/EmoPy"},"EmoPy")," - Deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER)."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/NVAE"},'PyTorch Implementation of "NVAE: A Deep Hierarchical Variational Autoencoder"')),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/weijun88/LDF"},"Label Decoupling Framework for Salient Object Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Project-MONAI/MONAI"},"MONAI")," - PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. (",(0,n.kt)("a",{parentName:"li",href:"https://monai.io/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/implus/GFocal"},"Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.paperspace.com/faster-r-cnn-explained-object-detection/"},"Faster R-CNN Explained for Object Detection Tasks (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.jeremymorgan.com/tutorials/raspberry-pi/how-to-install-opencv-raspberry-pi/"},"How to Install OpenCV on a Raspberry Pi (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alexanderkroner/saliency"},"Contextual Encoder-Decoder Network for Visual Saliency Prediction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.pyimagesearch.com/"},"PyImageSearch")," - Master Computer Vision, Deep Learning, and OpenCV."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hendrycks/natural-adv-examples"},"Natural Adversarial Examples")," - Harder ImageNet Test Set."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/@venkateshpnk22/how-to-upload-50-opencv-frames-into-cloud-storage-within-1-second-653ee73d7711"},"How to upload 50 OpenCV frames into cloud storage within 1 second (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://gvv.mpi-inf.mpg.de/projects/EgoChat/"},"Egocentric Videoconferencing (2020)")," - Method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=atzPvW95ahQ"},"Video overview"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/gradslam/gradslam"},"gradslam")," - Open source differentiable dense SLAM library for PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/saic-mdal/HiDT"},"High-Resolution Daytime Translation Without Domain Labels")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/s9xie/hed"},"Holistically-Nested Edge Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pycls"},"pycls")," - Image classification codebase, written in PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Justin-Tan/high-fidelity-generative-compression"},"PyTorch implementation of High-Fidelity Generative Image Compression + Routines for neural image compression")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-vl/selfstudy"},"How Useful is Self-Supervised Pretraining for Visual Tasks?")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/adamian98/pulse"},"PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/InterHand2.6M"},"InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/adipandas/multi-object-tracker"},"Multi-object trackers in Python")," - Easy to use implementation of various multi-object tracking algorithms."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://svl.stanford.edu/"},"Stanford Vision and Learning Lab")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/StanfordVL"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/learning-computer-vision-41398ad9941f"},"Learning computer vision. Overview of methods and software (2018)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/@rom1504/image-embeddings-ed1b194d113e"},"Image embeddings. Image similarity and building (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rom1504/image_embeddings"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/"},"All You Need to Know About Object Detection Systems (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lightly-ai/lightly"},"Lightly")," - Computer vision framework for self-supervised learning."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.13566"},"DISK: Learning local features with policy gradient (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cvlab-epfl/disk"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jasmcaus/caer"},"Caer")," - Lightweight Computer Vision library for high-performance AI research. (",(0,n.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/introducing-caer-modern-computer-vision-on-the-fly-1619d7155c15"},"Intro"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/weihaox/awesome-image-translation"},"Awesome Image to Image Translation Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/toandaominh1997/EfficientDet.Pytorch"},"EfficientDet: Scalable and Efficient Object Detection, in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/milesial/Pytorch-UNet"},"UNet: semantic segmentation with PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.10566"},"Exploring Simple Siamese Representation Learning (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/PatrickHua/SimSiam"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/simsiam"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/aimagelab/show-control-and-tell"},"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nerfies.github.io/"},"Nerfies: Deformable Neural Radiance Fields")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google/nerfies"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1812.01289"},"Timeception for Complex Action Recognition (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/noureldien/timeception"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://programmingcomputervision.com/"},"Programming Computer Vision with Python (2014)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jesolem/PCV"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nico/cvbook"},"Notes"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020"},"Fast and Accurate One-Stage Space-Time Video Super-Resolution (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://alexyu.net/pixelnerf/"},"pixelNeRF: Neural Radiance Fields from One or Few Images (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sxyu/pixel-nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Media-Smart/vedadet"},"vedadet")," - Single stage object detector toolbox based on PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PeizeSun/OneNet"},"OneNet: End-to-End One-Stage Object Detection by Classification Cost")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/consistent_depth"},"Consistent Video Depth Estimation")," - Estimate dense, flicker-free, geometrically consistent depth from monocular video, for example hand-held cell phone video."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vsitzmann/siren"},"Implicit Neural Representations with Periodic Activation Functions")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.computationalimaging.org/"},"Computational Imaging Stanford Lab")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZHKKKe/MODNet"},"Trimap-Free Solution for Portrait Matting in Real Time")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Fyusion/LLFF"},"Local Light Field Fusion")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/gjy3035/Awesome-Crowd-Counting"},"Awesome Crowd Counting")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/NSVF"},"Neural Sparse Voxel Fields (NSVF)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.15126"},"One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/goodfellow_ian/status/1333845997697388544"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/SharpAI/DeepCamera"},"SharpAI DeepCamera")," - Source stack for machine learning engineering with private deployment and AutoML for edge computing. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=25368272"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/krishnabits001/domain_specific_cl"},"Contrastive learning of global and local features for medical image segmentation with limited annotations")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.07810"},"Real-Time High-Resolution Background Matting (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/PeterL1n/BackgroundMattingV2"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/KaiyangZhou/deep-person-reid"},"Torchreid")," - Deep learning person re-identification in PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mangye16/Unsupervised_Embedding_Learning"},"Unsupervised Embedding Learning via Invariant and Spreading Instance Feature")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vitoralbiero/img2pose"},"img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection"},"SSD: Single Shot MultiBox Detector | a PyTorch Tutorial to Object Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2012.09688.pdf"},"PCT: Point Cloud Transformer (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MenghaoGuo/PCT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.09161"},"Learning Continuous Image Representation with Local Implicit Image Function (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yinboc/liif"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/openvinotoolkit/cvat"},"Computer Vision Annotation Tool (CVAT)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/deit"},"DeiT: Data-efficient Image Transformers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vsitzmann/awesome-implicit-representations"},"Awesome Implicit Neural Representations")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/OlafenwaMoses/ImageAI"},"ImageAI")," - Python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities. (",(0,n.kt)("a",{parentName:"li",href:"http://imageai.org/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://raivn.cs.washington.edu/"},"RAIVN Lab")," - Reasoning, AI and VisioN (RAIVN) Lab. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/RAIVNLab"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tryolabs/norfair"},"Norfair")," - Customizable lightweight Python library for real-time 2D object tracking."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sunshineatnoon/PytorchWCT"},"Universal Style Transfer in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/Dataset_Synthesizer"},"NVIDIA Deep learning Dataset Synthesizer (NDDS)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://paulbridger.com/posts/tensorrt-object-detection-quantized/"},"Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mtli/HTML4Vision"},"HTML4Vision")," - Simple HTML visualization tool for computer vision research."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/taldatech/soft-intro-vae-pytorch"},"Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/CompVis/taming-transformers"},"Taming Transformers for High-Resolution Image Synthesis")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sense-X/X-Temporal"},"X-Temporal")," - Easily implement SOTA video understanding methods with PyTorch on multiple machines and GPUs."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/RangiLyu/nanodet"},"NanoDet")," - Super fast and lightweight anchor-free object detection model. Real-time on mobile devices."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rwightman/pytorch-image-models"},"PyTorch Image Models")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sangminwoo/awesome-vision-and-language"},"Awesome Vision and Language")," - Curated list of awesome vision and language resources."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1810.12890v1"},"DropBlock: A regularization method for convolutional networks (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/miguelvr/dropblock"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/FrancescoSaverioZuppichini/glasses"},"Glasses")," - Compact, concise and customizable deep learning computer vision library. (",(0,n.kt)("a",{parentName:"li",href:"https://francescosaveriozuppichini.github.io/glasses-webapp/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/YuvalBahat/Explorable-Super-Resolution"},"Explorable Super Resolution (2019)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Breakthrough/PySceneDetect"},"PySceneDetect")," - Python and OpenCV-based scene cut/transition detection program & library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://phaseai.com/resources/computer-vision-best-practices"},"Best Practices for Building Computer Vision Models (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dbolya/tide"},"TIDE")," - General Toolbox for Identifying Object Detection Errors."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.12450"},"Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/PeizeSun/SparseR-CNN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/haltakov/natural-language-image-search"},"Unsplash Image Search")," - Search photos on Unsplash using natural language."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MIT-SPARK/Kimera-Semantics"},"Kimera Semantics")," - Real-Time 3D Semantic Reconstruction from 2D data."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ethz-asl/voxblox-plusplus"},"Voxblox++")," - Volumetric object-level semantic mapping framework."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nv-tlabs.github.io/nglod/"},"Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Surfaces")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nv-tlabs/nglod"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/"},"Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/nonrigid_nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html"},"DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/DeepSDF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yenchenlin/awesome-NeRF"},"Awesome Neural Radiance Fields")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JialeCao001/D2Det"},"D2Det: Towards High Quality Object Detection and Instance Segmentation (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.04803"},"DetCo: Unsupervised Contrastive Learning for Object Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xieenze/DetCo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kuzand/Computer-Vision-Video-Lectures"},"Computer Vision Video Lectures")," - Curated list of free, high-quality, university-level courses with video lectures related to the field of Computer Vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://cord.tech/"},"Cord")," - Training data toolbox for computer vision. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26104104"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/orpatashnik/StyleCLIP"},"Text-Guided Editing of Images (Using CLIP and StyleGAN)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/pytorch/vision"},"torchvision")," - Datasets, Transforms and Models specific to Computer Vision. (",(0,n.kt)("a",{parentName:"li",href:"https://paperswithcode.com/lib/torchvision"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.02371"},"MeInGame: Create a Game Character Face from a Single Portrait (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/FuxiCV/MeInGame"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/kjw0612/awesome-deep-vision"},"Awesome Deep Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dvschultz/dataset-tools"},"dataset-tools")," - Tools for quickly normalizing image datasets."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/"},"Using Streamlit to visualize object detection output (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/mobile-vision"},"Mobile Computer Vision @ Facebook")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medium.com/hasty-ai/opening-the-black-box-of-vision-ai-algorithms-466fc3d4bf78"},"Opening the black box of vision AI algorithms (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/exadel-inc/CompreFace"},"CompreFace")," - Free face recognition solution that can be easily integrated into any IT system without prior machine learning skills."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ibrnet.github.io/"},"IBRNet: Learning Multi-View Image-Based Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/googleinterns/IBRNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1812.03506"},"From Coarse to Fine: Robust Hierarchical Localization at Large Scale (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ethz-asl/hfnet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://roboalgorithms.com/posts/camera-response-function/"},"Camera Response Function (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2008.03713"},"I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mks0601/I2L-MeshNet_RELEASE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1711.09485"},"SkipNet: Learning Dynamic Routing in Convolutional Networks (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ucbdrive/skipnet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://mrcal.secretsauce.net/"},"Mrcal")," - Camera Calibrations and More. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26300118"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1806.01260"},"Digging Into Self-Supervised Monocular Depth Estimation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nianticlabs/monodepth2"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/pxl-th/Monodepth2.jl"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/vissl"},"VISSL")," - FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. (",(0,n.kt)("a",{parentName:"li",href:"https://vissl.ai/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.zumolabs.ai/"},"Zumo Labs")," - Generate custom synthetic data sets that result in more robust and reliable computer vision models. (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZumoLabs"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2008.07043"},"Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yijingru/BBAVectors-Oriented-Object-Detection"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.03206"},"Perceiver: General Perception with Iterative Attention (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/perceiver-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision"},"SEER: The start of a more powerful, flexible, and accessible era for computer vision (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gafniguy.github.io/4D-Facial-Avatars/"},"NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://neural-3d-video.github.io/"},"Neural 3D Video Synthesis")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.06255"},"Involution: Inverting the Inherence of Convolution for Visual Recognition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/d-li14/involution"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Wangt-CN/Awesome-Causality-in-CV"},"Awesome Causality in Computer Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.13413"},"Vision Transformers for Dense Prediction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/intel-isl/DPT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.00680"},"LoFTR: Detector-Free Local Feature Matching with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/LoFTR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/liuliu/ccv"},"ccv")," - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.13084"},"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zhengqili/Neural-Scene-Flow-Fields"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://xbpeng.github.io/projects/AMP/"},"AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/xbpeng4/status/1379465757688352769"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://healeycodes.com/computer-vision-and-embroidery/"},"Computer Vision and Embroidery (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/healeycodes/embroidery-vision"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jonbarron.info/mipnerf/"},"mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/svpino/status/1379666495811117062"},"Python libraries I use every day for computer vision work (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Soldelli/Awesome-Temporal-Language-Grounding-in-Videos"},"Awesome Temporal Sentence Grounding in Videos")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://authentic.sice.indiana.edu/publications/Su_Crandall-AffectiveGrowthCV-CVPR21.pdf"},"The Affective Growth of Computer Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2008.05711"},"Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nv-tlabs/lift-splat-shoot"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.14503"},"End-to-End Video Instance Segmentation with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Epiphqny/VisTR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/obss/sahi"},"SAHI: Slicing Aided Hyper Inference")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.gamasutra.com/blogs/RobertPepperell/20200527/363615/FOVO_A_new_3D_rendering_technique_based_on_human_vision.php"},"FOVO: A new 3D rendering technique based on human vision (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26795290"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.05095"},"Is Space-Time Attention All You Need for Video Understanding? (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/TimeSformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dk-liang/Awesome-Visual-Transformer"},"Awesome Visual-Transformer")," - Transformer with Computer-Vision (CV) papers."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/pytorchvideo"},"PyTorchVideo")," - Deep learning library for video understanding research. (",(0,n.kt)("a",{parentName:"li",href:"https://pytorchvideo.org/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://charigyang.github.io/motiongroup/"},"Self-supervised Video Object Segmentation by Motion Grouping (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26842018"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/charigyang/motiongrouping"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/torchvideo/torchvideo"},"torchvideo")," - Datasets, transforms and samplers for video in PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1701.03077"},"A General and Adaptive Robust Loss Function (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jonbarron/robust_loss_pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://geyixiao.com/projects/sfrs"},"Self-supervising Fine-grained Region Similarities for Large-scale Image Localization (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yxgeee/OpenIBL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2021/04/max-deeplab-dual-path-transformers-for.html"},"MaX-DeepLab: Dual-Path Transformers for End-to-End Panoptic Segmentation (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://vizycam.com/"},"Vizy")," - AI Camera."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://casual-effects.com/research/McGuire2021PixelArt/McGuire2021PixelArt.pdf"},"MMPX Style-Preserving Pixel Art Magnification (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=26934973"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hkchengrex.github.io/MiVOS/"},"Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hkchengrex/Scribble-to-Mask"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1712.07629"},"SuperPoint: Self-Supervised Interest Point Detection and Description (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/eric-yyjau/pytorch-superpoint"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.02808"},"Multi-Stage Progressive Image Restoration (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/swz30/MPRNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/colmap/colmap"},"COLMAP")," - General-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. (",(0,n.kt)("a",{parentName:"li",href:"https://colmap.github.io/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tzutalin/awesome-visual-slam"},"Awesome Vision-based SLAM / Visual Odometry")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.03230"},"Barlow Twins: Self-Supervised Learning via Redundancy Reduction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/barlowtwins"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cpc/hipcl"},"HIPCL")," - OpenCL/SPIR-V implementation of HIP."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmcv"},"MMCV")," - Foundational library for computer vision research and supports many research projects. (",(0,n.kt)("a",{parentName:"li",href:"https://mmcv.readthedocs.io/en/latest/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.12763"},"MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ashkamath/mdetr"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.13963"},"Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/suncet"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/msn"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.14294"},"Emerging Properties in Self-Supervised Vision Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/dino"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/i/lists/1351120526220152839"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/schrep/status/1388189398496202752"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.07652"},"Geometry-Free View Synthesis: Transformers and no 3D Priors (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/CompVis/geometry-free-view-synthesis"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://minimaxir.com/2021/04/styleclip/"},"Easily Transform Portraits of People into AI Aberrations Using StyleCLIP (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.09105"},"DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Colin97/DeepMetaHandles"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/onepanelio/onepanel"},"Onepanel")," - Open and extensible integrated development environment (IDE) for computer vision. (",(0,n.kt)("a",{parentName:"li",href:"https://docs.onepanel.ai/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.12229"},"Vector Neurons: A General Framework for SO(3)-Equivariant Networks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/FlyingGiraffe/vnn"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.00637"},"ISTR: End-to-End Instance Segmentation with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hujiecpp/ISTR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.01601"},"MLP-Mixer: An all-MLP Architecture for Vision (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/mlp-mixer-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rishikksh20/MLP-Mixer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/The-AI-Summer/self-attention-cv"},"Self-attention building blocks for computer vision applications in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/LeViT"},"LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.14631"},"Text2Video: Text-driven Talking-head Video Synthesis with Phonetic Dictionary (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://sites.google.com/view/sibozhang/text2video"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sibozhang/Text2Video"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.unite.ai/neural-rendering-low-resolution-input-intel/"},"Neural Rendering: How Low Can You Go in Terms of Input? (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://intel-isl.github.io/PhotorealismEnhancement/"},"Enhancing Photorealism Enhancement (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.04619"},"Paper"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/intel-isl/PhotorealismEnhancement"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.geometrylearning.com/DeepFaceEditing/"},"DeepFaceEditing: Deep Face Generation and Editing with Disentangled Geometry and Appearance Control (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/IGLICT/DeepFaceEditing-Jittor"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://omnimatte.github.io/"},"Omnimatte: Associating Objects and Their Effects in Video (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.07576"},'Rethinking "Batch" in BatchNorm (2021)')),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rafaelpadilla/Object-Detection-Metrics"},"Most popular metrics used to evaluate object detection algorithms")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2002.06353"},"UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/UniVL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/unrealcv/synthetic-computer-vision"},"Synthetic for Computer Vision")," - List of synthetic dataset and tools for computer vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Cartucho/vision_blender"},"vision_blender")," - Blender addon for generating synthetic ground truth data for Computer Vision applications."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sicara/easy-few-shot-learning"},"Easy Few-Shot Learning")," - Ready-to-use code and tutorial notebooks to boost your way into few-shot image classification."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xinntao/BasicSR"},"BasicSR (Basic Super Restoration)")," - Open source image and video restoration toolbox based on PyTorch, such as super-resolution, denoise, deblurring, JPEG artifacts removal, etc."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.10497"},"Intriguing Properties of Vision Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/MachineLearning/comments/njm2ru/r_intriguing_properties_of_vision_transformers/"},"Reddit"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.sbxrobotics.com/tutorial"},"DIY Amazon Go \u2013 computer vision tutorial for cashierless checkout")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://matsui528.github.io/cvpr2020_tutorial_retrieval/"},"Image Retrieval in the Wild (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV"},"Awesome Transformer in CV papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.tangramvision.com/blog/calibration-from-scratch-using-rust-part-1-of-3"},"Sensor Calibration from Scratch with Rust (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.tangramvision.com/"},"Tangram Vision")," - Integrate, Calibrate Perception Sensors For Robots, Drones & Automation. (",(0,n.kt)("a",{parentName:"li",href:"https://www.tangramvision.com/blog"},"Blog"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rust-cv/cv"},"Rust CV")," - Project to implement computer vision algorithms, abstractions, and systems in Rust."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://gvv.mpi-inf.mpg.de/projects/NeuralActor/"},"Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=27393047"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.02107"},"Robust Instance Segmentation through Reasoning about Multi-Object Occlusion (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/XD7479/Multi-Object-Occlusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.02636"},"MERLOT: Multimodal Neural Script Knowledge Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/jmhessel/status/1401983972272345088"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.04560"},"Scaling Vision Transformers (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.02788"},"Self-Supervised Scene De-occlusion (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/XiaohangZhan/deocclusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.05744"},"Pivotal Tuning for Latent-based Editing of Real Images (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/danielroich/PTI"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://flame.is.tue.mpg.de/"},"FLAME: Articulated Expressive 3D Head Model")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Rubikplayer/flame-fitting"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09681"},"XCiT: Cross-Covariance Image Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/xcit"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://robust-cvd.github.io/"},"Robust Consistent Video Depth Estimation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/robust_cvd"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Megvii-BaseDetection/cvpods"},"cvpods")," - All-in-one Toolbox for Computer Vision Research."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.10559"},"CDFI: Compression-Driven Network Design for Frame Interpolation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/tding1/CDFI"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nerfmm.active.vision/"},"NeRF--: Neural Radiance Fields Without Known Camera Parameters (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ActiveVisionLab/nerfmm"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ventusff/improved-nerfmm"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.robots.ox.ac.uk/ActiveVision/"},"Oxford Active Vision Laboratory")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ActiveVisionLab"},"GitHub"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://szeliski.org/Book/"},"Computer Vision: Algorithms and Applications, 2nd ed.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ccrisan/motioneyeos"},"motionEyeOS")," - Linux distribution that turns your single board computer into a video surveillance system."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.02192"},"Long-Short Transformer: Efficient Transformers for Language and Vision (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/long-short-transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://distill.pub/2017/feature-visualization/"},"Feature Visualization \u2013 How NNs understand images (2017)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1904.01906"},"What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/clovaai/deep-text-recognition-benchmark"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.16831"},"Convolutional Hough Matching Networks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/juhongm999/chm"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/esvit"},"Efficient Self-Supervised Vision Transformers (EsViT)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.10697"},"ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/convit"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=QdbieYXn_XM"},"Paper Read"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.marktechpost.com/2021/07/20/facebook-ai-introduces-convit-a-computer-vision-model-that-improves-vision-transformers-vit-with-soft-convolutional-inductive-biases/"},"Article"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/co3d"},"CO3D: Common Objects In 3D")," - Tools for working with the Common Objects in 3D (CO3D) dataset."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.03841"},"ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/ORBIT-Dataset"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.13700"},"Vision Transformer Architecture Search (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xiusu/ViTAS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2007.12072"},"TSIT: A Simple and Versatile Framework for Image-to-Image Translation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/EndlessSora/TSIT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://machinelearning.apple.com/research/recognizing-people-photos"},"Recognizing People in Photos Through Private On-Device Machine Learning (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.02047"},"CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/CoCosNet-v2"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.10620"},"HPNet: Deep Primitive Segmentation Using Hybrid Representations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/SimingYan/HPNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/datature/portal"},"Portal")," - Fastest way to load and visualize your deep neural networks on images and videos."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cbsudux/awesome-human-pose-estimation"},"Awesome Human Pose Estimation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.03791"},"Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/LongguangWang/ArbSR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/omihub777/ViT-CIFAR"},"PyTorch implementation for Vision Transformer")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/index.html"},"Repulsive Curves")," - Model 2D & 3D curves while avoiding self-intersection. (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/keenanisalive/status/1422318272800829440"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/icethrush/repulsive-curves"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31120139"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://chenlin9.github.io/SDEdit/"},"SDEdit: Image Synthesis and Editing with Stochastic Differential Equations")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ermongroup/SDEdit"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.12902"},"Region Similarity Representation Learning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Tete-Xiao/ReSim"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nex-mpi.github.io/"},"NeX: Real-time View Synthesis with Neural Basis Expansion (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nex-mpi/nex-code"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://pengsongyou.github.io/conv_onet"},"Convolutional Occupancy Networks (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/autonomousvision/convolutional_occupancy_networks"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.02166"},"Learning Optical Flow from a Few Matches (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zacjiang/SCV"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.05790"},"Visual Parser: Representing Part-whole Hierarchies with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/kevin-ssy/ViP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://jianghz.me/projects/superslomo/"},"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/avinashpaliwal/Super-SloMo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.14641"},"On Generating Transferable Targeted Perturbations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Muzammal-Naseer/TTP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bertjiazheng/awesome-scene-understanding"},"Awesome Scene Understanding")," - List of papers for scene understanding."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.07651"},"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/salesforce/ALBEF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://depthoraclenerf.github.io/"},"DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/DONERF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.strayrobots.io/blog/object-detection-in-an-hour"},"Object Detection in an Hour (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=28100346"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1906.06423"},"Fixing the train-test resolution discrepancy (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/FixRes"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2008.09397"},"Align Deep Features for Oriented Object Detection (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/csuhan/s2anet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.05565"},"Vision-Language Transformer and Query Generation for Referring Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/henghuiding/Vision-Language-Transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.cs.cmu.edu/~dsnerf/"},"Depth-supervised NeRF: Fewer Views and Faster Training for Free (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dunbar12138/DSNeRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.10257"},"SwinIR: Image Restoration Using Swin Transformer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JingyunLiang/SwinIR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.04206"},"You Only Learn One Representation: Unified Network for Multiple Tasks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/WongKinYiu/yolor"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.11944"},"Probabilistic Modeling for Human Mesh Recovery (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nkolot/ProHMR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/"},"BARF: Bundle-Adjusting Neural Radiance Fields (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chenhsuanlin/bundle-adjusting-NeRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://postech-cvlab.github.io/SCNeRF/"},"Self-Calibrating Neural Radiance Fields (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/POSTECH-CVLab/SCNeRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NielsRogge/Transformers-Tutorials"},"Transformers-Tutorials")," - Demos I made with the Transformers library by HuggingFace."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.02563"},"3D Human Texture Estimation from a Single Image with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xuxy09/Texformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08860"},"CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ArrowLuo/CLIP4Clip"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2003.12039"},"RAFT: Recurrent All Pairs Field Transforms for Optical Flow (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-vl/RAFT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ventusff/neurecon"},"Volume rendering + 3D implicit surface = Neural 3D Reconstruction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.contrib.andrew.cmu.edu/~gengshay/cvpr19stereo"},"Hierarchical Deep Stereo Matching on High-resolution Images (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/gengshan-y/high-res-stereo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://zju3dv.github.io/object_nerf/"},"Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/object_nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://shepnerd.github.io/scg/"},"Image Synthesis via Semantic Composition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dvlab-research/SCGAN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers"},"Awesome-Edge-Detection-Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MarkMoHR/Awesome-Image-Colorization"},"Awesome-Image-Colorization")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://longguangwang.github.io/Project/ArbSR/"},"Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/LongguangWang/ArbSR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/1adrianb/face-alignment"},"Face Recognition")," - 2D and 3D Face alignment library build using PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/willard-yuan/awesome-cbir-papers"},"Awesome image retrieval papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/aimakerspace/PeekingDuck"},"PeekingDuck")," - Modular framework built to simplify Computer Vision inference workloads."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.11225"},"Pri3D: Can 3D Priors Help 2D Representation Learning? (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sekunde/Pri3D"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xinntao/facexlib"},"FaceXLib")," - Aims at providing ready-to-use face-related functions based on current STOA open-source methods."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmaction2"},"MMAction2")," - Open-source toolbox for video understanding based on PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jslee02/awesome-collision-detection"},"Awesome Collision Detection")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.06847"},"Video Super-Resolution Transformer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/caojiezhang/VSR-Transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JulianKnodt/nerf_atlas"},"NeRF Atlas")," - Collection of NeRF extensions for fun and experimentation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cszn/KAIR"},"Training and testing codes for USRNet, DnCNN, FFDNet, SRMD, DPSR, MSRResNet, ESRGAN, BSRGAN, SwinIR")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.03106"},"Uformer: A General U-Shaped Transformer for Image Restoration (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZhendongWang6/Uformer"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/uformer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.12718"},"Self-Supervised Pretraining Improves Self-Supervised Pretraining (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cjrd/self-supervised-pretraining"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://xuchen-ethz.github.io/snarf/"},"SNARF: Differentiable Forward Skinning for Animating Non-Rigid Neural Implicit Shapes (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xuchen-ethz/snarf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/HRNet/HRFormer"},"HRFormer: High-Resolution Transformer for Dense Prediction, NeurIPS 2021")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/airctic/icevision"},"IceVision")," - Agnostic Computer Vision Framework - Pluggable to any Training Library: Fastai, Pytorch-Lightning with more to come. (",(0,n.kt)("a",{parentName:"li",href:"https://airctic.com/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.03761"},"e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/maximek3/status/1438554571756933127"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ozan-oktay/Attention-Gated-Networks"},"Attention Gated Networks (Image Classification & Segmentation) in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.03151v2"},"Full-Duplex Strategy for Video Object Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/GewelsJI/FSNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://handtracking.io/"},"YoHa")," - Practical hand tracking engine. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=28825820"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/handtracking-io/yoha"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.14948"},"Deep Learning for Face Anti-Spoofing: A Survey (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZitongYu/DeepFAS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.07645"},"A-SDF: Learning Disentangled Signed Distance Functions for Articulated Shape Representation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JitengMu/A-SDF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://saic-mdal.github.io/lama-project/"},"Resolution-robust Large Mask Inpainting with Fourier Convolutions (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/saic-mdal/lama"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.14030"},"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/Swin-Transformer"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/berniwal/swin-transformer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.06635"},"ADOP: Approximate Differentiable One-Pixel Point Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/rodolfor/status/1448655222876741634"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/keenanisalive/status/1448708734511951879"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/darglein/ADOP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openreview.net/forum?id=TVHS5Y4dNvM"},"Patches Are All You Need? (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/tmp-iclr/convmixer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.05258"},"ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/joe-siyuan-qiao/ViP-DeepLab"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.11339"},"Video Panoptic Segmentation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mcahny/vps"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Kobaayyy/Awesome-ICCV2021-Low-Level-Vision"},"Awesome-ICCV2021-Low-Level-Vision")," - Collection of Papers and Codes for ICCV2021 Low Level Vision and Image Generation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.00887"},"Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/clovaai/mxfont"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.07641"},"Non-deep Networks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/imankgoyal/NonDeepNetworks"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/fornaxai/receptivefield"},"receptivefield")," - Gradient based receptive field estimation for Convolutional Neural Networks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://igl.ethz.ch/projects/iso-points/"},"Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yifita/iso-points"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.03110"},"Neural Articulated Radiance Field (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nogu-atsu/NARF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.10957"},"Efficient Visual Pretraining with Contrastive Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/deepmind/detcon"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/VoTT"},"VoTT (Visual Object Tagging Tool)")," - Source annotation and labeling tool for image and video assets."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.08059"},"FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rjbruin/flexconv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.06864"},"ByteTrack: Multi-Object Tracking by Associating Every Detection Box (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ifzhang/ByteTrack"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://iashin.ai/bmt"},"Dense Video Captioning with Bi-modal Transformer (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/v-iashin/BMT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zhanghang1989/PyTorch-Encoding"},"PyTorch-Encoding")," - CV toolkit for my papers. (",(0,n.kt)("a",{parentName:"li",href:"https://hangzhang.org/PyTorch-Encoding/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.06474"},"Space Time Recurrent Memory Network (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/spacetime-recurrent-memory-network"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apple/ml-cvnets"},"CVNets")," - Library for training computer vision networks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/scenic"},"Scenic")," - Jax Library for Computer Vision Research and Beyond. (",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.11403"},"Paper"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://vincentqin.tech/cv-arxiv-daily/"},"CV Arxiv Daily")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Vincentqyw/cv-arxiv-daily"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/opencv/open_vision_capsules"},"OpenVisionCapsules")," - Set of libraries for encapsulating smart vision algorithms."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://medmnist.com/"},"MedMNIST: Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MedMNIST/MedMNIST"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.15358"},"Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dingmyu/VRDP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2011.13495"},"Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mabaorui/NeuralPull"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09672"},"The 2021 Image Similarity Dataset and Challenge (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/isc2021"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.14855"},"K-Net: Towards Unified Image Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZwwWayne/K-Net"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch"},"Yolov5 + Deep Sort with PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.03452"},"Shape As Points: A Differentiable Poisson Solver (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/autonomousvision/shape_as_points"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.05208"},"Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sense-GVT/DeCLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/daqingliu/awesome-vln"},"Awesome Vision-Language Navigation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://vision.cs.utexas.edu/projects/exploring-exploration/"},"An Exploration of Embodied Visual Exploration (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/exploring_exploration"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1812.00101"},"DVC: An End-to-end Deep Video Compression Framework (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/GuoLusjtu/DVC"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dribnet/pixray"},"Pixray")," - Neural image generation."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.03042"},"Unsupervised Learning of Compositional Energy Concepts (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/du_yilun/status/1456630363040751616"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://shuquanye.com/PNAL_website/"},"Learning with Noisy Labels for Robust Point Cloud Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/pleaseconnectwifi/PNAL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yeemachine/kalidoface"},"Kalidoface")," - Become a virtual character with just your webcam. (",(0,n.kt)("a",{parentName:"li",href:"https://kalidoface.com/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yeemachine/kalidokit"},"KalidoKit")," - Face, Pose, and Hand Tracking Kinematics."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://pjreddie.com/courses/computer-vision/"},"The Ancient Secrets of Computer Vision")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.01178"},"Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ShuhangGu/DASR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.pygaze.org/"},"PyGaze")," - Open source eye-tracking software and more. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29171416"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.13874"},"Exploring Relational Context for Multi-Task Dense Prediction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/brdav/atrc"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://light.princeton.edu/publication/neural-scene-graphs/"},"Neural Scene Graphs for Dynamic Scenes (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-computational-imaging/neural-scene-graphs"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://iterative-refinement.github.io/"},"Image Super-Resolution via Iterative Refinement")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29202899"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openreview.net/forum?id=nBU_u6DLvoK"},"UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/uniformer-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.05392"},"Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Motionformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://tianweiy.github.io/mvp/"},"Multimodal Virtual Point 3D Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/tianweiy/MVP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sara-Ahmed/SiT"},"SiT: Self-supervised vIsion Transformer")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.07624"},"Attention Mechanisms in Computer Vision: A Survey (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/MenghaoGuo/Awesome-Vision-Attentions"},"Awesome Vision Attention Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.04524"},"FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ltkong218/FastFlowNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.monkeyoverflow.com/#/rendernet-a-cnn-for-differentiable-rendering-from-3d-shapes/"},"RenderNet: A deep convolutional network for differentiable rendering from 3D shapes (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/thunguyenphuoc/RenderNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.06377"},"Masked Autoencoders Are Scalable Vision Learners (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/pengzhiliang/MAE-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/mae"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/catalys1/mae-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/compphoto/BoostingMonocularDepth"},"BoostingMonocularDepth")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.09162"},"It's About Time: Analog Clock Reading in the Wild (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/giffmana/status/1461249563466022913"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/charigyang/itsabouttime"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://composevisualrelations.github.io/"},"Learning to Compose Visual Relations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nanlliu/compose-visual-relations"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1805.09662"},"LF-Net: Learning Local Features from Images (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/vcg-uvic/lf-net-release"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.02637"},"Aligning Pretraining for Detection via Object-Level Contrastive Learning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hologerry/SoCo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.04138"},"Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/fel-thomas/Sobol-Attribution-Method"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cszn/USRNet"},"Deep unfolding network for image super-resolution (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.13112"},"VOLO: Vision Outlooker for Visual Recognition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sail-sg/volo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.04076"},"Direct Multi-view Multi-person 3D Pose Estimation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sail-sg/mvp"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jhonykaesemodel.com/publication/image2mesh/"},"Image2Mesh: A learning framework for single image 3D reconstruction (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jhonykaesemodel/image2mesh"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/PeculiarVentures/GammaCV"},"GammaCV")," - WebGL accelerated Computer Vision library for modern web applications. (",(0,n.kt)("a",{parentName:"li",href:"https://gammacv.com/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.14279"},"Localizing Objects with Self-Supervised Transformers and no Labels (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/valeoai/LOST"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/genicam/harvesters"},"Harvester")," - GenICam-based Image Acquisition Python Library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.12417"},"N\xdcWA: Visual Synthesis Pre-training for Neural visUal World creAtion (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/NUWA"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/nuwa-pytorch"},"PyTorch Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.03334"},"ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dandelin/ViLT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.11418"},"MetaFormer is Actually What You Need for Vision (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sail-sg/poolformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.09432"},"ARAPReg: An As-Rigid-As Possible Regularization Loss for Learning Deformable Shape Generators (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/GitBoSun/ARAPReg"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.11124"},"Mesa: A Memory-saving Training Framework for Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zhuang-group/Mesa"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmpose"},"MMPose")," - Open-source toolbox for pose estimation based on PyTorch. (",(0,n.kt)("a",{parentName:"li",href:"https://mmpose.readthedocs.io/en/latest/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.02387"},"An Empirical Study of Training End-to-End Vision-and-Language Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zdou0830/METER"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hassony2/useful-computer-vision-phd-resources"},"Useful computer vision PhD resources")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.tenyks.ai/"},"Tenyks")," - Data-centric Computer Vision."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://bowenc0221.github.io/mask2former/"},"Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Mask2Former"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://m-niemeyer.github.io/project-pages/giraffe/index.html"},"GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/autonomousvision/giraffe"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://mbaradad.github.io/learning_with_noise/"},"Learning to See by Looking at Noise (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mbaradad/learning_with_noise"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.07832"},"iBOT: Image BERT Pre-Training with Online Tokenizer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/bytedance/ibot"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.03857"},"Grounded Language-Image Pre-training (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/GLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1604.00449"},"3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction (2016)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chrischoy/3D-R2N2"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://proceedings.mlr.press/v97/lee19d.html"},"Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/juho-lee/set_transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TheShadow29/awesome-grounding"},"Awesome Visual Grounding")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.05464"},"Are Transformers More Robust Than CNNs? (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ytongbai/ViTs-vs-CNNs"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://alexyu.net/plenoxels/"},"Plenoxels: Radiance Fields without Neural Networks (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sxyu/svox2"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sarafridov/plenoxels"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TencentARC/GFPGAN"},"GFPGAN")," - Developing Practical Algorithms for Real-world Face Restoration."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yaochih/awesome-video-stabilization"},"Awesome Video Stabilization")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://apchenstu.github.io/mvsnerf/"},"MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apchenstu/mvsnerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://people.eecs.berkeley.edu/~jathushan/T3DP/"},"Tracking People with 3D Representations (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/brjathu/T3DP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1908.09492"},"Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection (2019:)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/poodarchu/Det3D"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hhsinping.github.io/3d_scene_stylization/"},"Learning to Stylize Novel Views (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hhsinping/stylescene"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Megvii-BaseDetection/YOLOX"},"YOLOX")," - High-performance anchor-free YOLO. (",(0,n.kt)("a",{parentName:"li",href:"https://yolox.readthedocs.io/en/latest/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hongwenzhang.github.io/pymaf/"},"PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/HongwenZhang/PyMAF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.08275"},"SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/wjf5203/SeqFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://markboss.me/publication/2021-nerd/"},"NeRD: Neural Reflectance Decomposition from Image Collections (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.14822"},"Vector Quantized Diffusion Model for Text-to-Image Synthesis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/VQ-Diffusion"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cientgu/VQ-Diffusion"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/VQ-Diffusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.10741"},"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/glide-text2im"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Unity-Technologies/SynthDet"},"SynthDet")," - End-to-end object detection pipeline using synthetic data."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.11010"},"MPViT: Multi-Path Vision Transformer for Dense Prediction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/youngwanLEE/MPViT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.10762"},"StyleSwin: Transformer-based GAN for High-resolution Image Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/StyleSwin"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.05304"},"Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-vl/SimpleView"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.12750"},"SLIP: Self-supervision meets Language-Image Pre-training (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/SLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.03109"},"General Facial Representation Learning in a Visual-Linguistic Manner (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/FaRL"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/FacePerceiver/FaRL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hypernerf.github.io/"},"HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google/hypernerf"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=29698276"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.03480"},"Learning to Regress Bodies from Images using Differentiable Semantic Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/saidwivedi/DSR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.10752"},"High-Resolution Image Synthesis with Latent Diffusion Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/CompVis/latent-diffusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://richardt.name/publications/audio-dvp/"},"Photorealistic Audio-driven Video Portraits (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xinwen-cs/AudioDVP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xinghaochen/awesome-hand-pose-estimation"},"Awesome Hand Pose Estimation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.15679"},"Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hila-chefer/Transformer-MM-Explainability"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.09838"},"Transformer Interpretability Beyond Attention Visualization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hila-chefer/Transformer-Explainability"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.03133"},"StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Synthesis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/pschaldenbrand/StyleCLIPDraw"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.07597"},"Light Field Image Super-Resolution with Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZhengyuLiang24/LFT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.12701"},"Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/samb-t/unleashing-transformers"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.vision.huji.ac.il/deepsim/"},"DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/eliahuhorwitz/DeepSIM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.00726"},"RAFT-3D: Scene Flow using Rigid-Motion Embeddings (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-vl/RAFT-3D"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://jwbian.net/unsupervised-indoor-depth"},"Unsupervised Indoor Depth Estimation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JiawangBian/Unsupervised-Indoor-Depth"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.06199"},"A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/LemonATsu/A-NeRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.17263"},"Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xvjiarui/VFS#readme"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gitlab.com/DO-CV/sara"},"Sara")," - Easy-to-Use C++ Computer Vision Library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.07547"},"RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/princeton-vl/RAFT-Stereo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.09007"},"U-2-Net: Going Deeper with Nested U-Structure for Salient Object Detection (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Norod/U-2-Net-StyleTransfer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.00487"},"Language as Queries for Referring Video Object Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/wjn922/ReferFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.08825"},"Localization with Sampling-Argmax (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Jeff-sjtu/sampling-argmax"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://voca.is.tue.mpg.de/"},"VOCA: Voice Operated Character Animation")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/TimoBolkart/voca"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cvzone/cvzone"},"CVZone")," - Computer vision package that makes its easy to run Image processing and AI functions."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/serengil/deepface"},"Deepface")," - Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.07131"},"Location-aware Single Image Reflection Removal (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zdlarr/Location-aware-SIRR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.08223"},"MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/meshtalk"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.02605"},"Detecting Twenty-thousand Classes using Image-level Supervision (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Detic"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.03546"},"Language-driven Semantic Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/isl-org/lang-seg"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.08459"},"Rethinking Nearest Neighbors for Visual Classification (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/KMnP/nn-revisit"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.00520"},"Vision Transformer with Deformable Attention (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/LeapLabTHU/DAT"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/deformable-attention"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/keras-team/keras-cv"},"KerasCV")," - Industry-strength Computer Vision workflows with Keras."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/instant-ngp"},"Instant Neural Graphics Primitives")," - Lightning fast NeRF and more."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.08322"},"Dynamic Head: Unifying Object Detection Heads with Attentions (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/DynamicHead"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.12786"},"ELSA: Enhanced Local Self-Attention for Vision Transformer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/damo-cv/ELSA"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/libffcv/ffcv"},"FFCV")," - Fast Forward Computer Vision (and other ML workloads!) (",(0,n.kt)("a",{parentName:"li",href:"https://ffcv.io/"},"Web"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/awesome-vit"},"Awesome Vit")," - Curated list and survey of awesome Vision Transformers."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nvlabs.github.io/instant-ngp/"},"Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ashawkey/torch-ngp"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yashbhalgat/HashNeRF-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=j8tMk-GE8hY"},"Video Summary"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30408898"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1711.10684"},"Road Extraction by Deep Residual U-Net (2017)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nikhilroxtomar/Deep-Residual-Unet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1911.08324"},"Single-Stage 6D Object Pose Estimation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cvlab-epfl/single-stage-pose"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/task_adaptation"},"Visual Task Adaptation Benchmark (VTAB)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://tadaconv-iclr2022.github.io/"},"TAda! Temporally-Adaptive Convolutions for Video Understanding (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/alibaba-mmai-research/TAdaConv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://moechsle.github.io/unisurf/"},"UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/autonomousvision/unisurf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://visual.cs.ucl.ac.uk/pubs/cofusion/index.html"},"Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/martinruenz/co-fusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.12288"},"VRT: A Video Restoration Transformer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JingyunLiang/VRT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.06796"},"Unknown Object Segmentation from Stereo Images (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/DLR-RM/instr"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1803.08024"},"Stacked Cross Attention for Image-Text Matching (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/kuanghuei/SCAN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.12086"},"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/salesforce/BLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2101.05796"},"DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/volflow/DeFlow"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.11539"},"DocFormer: End-to-End Transformer for Document Understanding (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/shabie/docformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.12782"},"SeMask: Semantically Masked Transformers for Semantic Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Picsart-AI-Research/SeMask-Segmentation"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2004.07728"},"Image Quality Assessment: Unifying Structure and Texture Similarity (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dingkeyan93/DISTS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/naver/fire"},"Learning Super-Features for Image Retrieval (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jinfagang/yolov7"},"YOLOv7")," - Framework Beyond Detection."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.14757"},"A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MendelXu/zsseg.baseline"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/JudasDie/SOTS"},"Single/Multiple Object Tracking and Segmentation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.07950"},"Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/meilfang/LMFD-PAD"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09965"},"HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/hififace"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://waymo.com/research/block-nerf/"},"Scalable Large Scene Neural View Synthesis (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30299498"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/dair-ai/Transformers-Recipe"},"Transformer Recipe")," - Quick recipe to learn all about Transformers."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.02533"},"NeROIC: Neural Rendering of Objects from Online Image Collections (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/snap-research/NeROIC"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.00888"},"DiffusionNet: Discretization Agnostic Learning on Surfaces (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nmwsharp/diffusion-net"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://film-net.github.io/"},"FILM: Frame Interpolation for Large Motion (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/frame-interpolation"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.09964"},"Learning Signed Distance Field for Multi-view Surface Reconstruction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jzhangbs/MVSDF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/bnu-wangxun/Deep_Metric"},"Deep Metric Learning in PyTorch")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://icon.is.tue.mpg.de/"},"ICON: Implicit Clothed humans Obtained from Normals (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/YuliangXiu/ICON"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://clipasso.github.io/clipasso/"},"CLIPasso: Semantically-Aware Object Sketching (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yael-vinker/CLIPasso"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://banmo-www.github.io/"},"BANMo: Building Animatable 3D Neural Models from Many Casual Videos (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/banmo"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xxxnell/how-do-vits-work"},"How Do Vision Transformers Work?")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/louisfb01/top-10-cv-papers-2021"},"Top 10 Computer Vision Papers of 2021")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.09603"},"Exploring Sparsity in Image Super-Resolution for Efficient Inference (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/The-Learning-And-Vision-Atelier-LAVA/SMSR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/computational-imaging/automatic-integration"},"AutoInt: Automatic Integration for Fast Neural Volume Rendering (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.01134"},"Learning to Prompt for Vision-Language Models (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/KaiyangZhou/CoOp"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1812.01969"},"Summarizing Videos with Attention (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ok1zjf/VASNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vkit-dev/vkit"},"vkit")," - Toolkit designed for CV (Computer Vision) developers. (",(0,n.kt)("a",{parentName:"li",href:"https://vkit-dev.github.io/"},"Docs"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.11191"},"Generative Adversarial Graph Convolutional Networks for Human Action Synthesis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/DegardinBruno/Kinetic-GAN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/wchstrife/Awesome-Image-Matting"},"Awesome Image Matting")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://lstm.seas.harvard.edu/latex/"},"Image-to-Markup Generation with Coarse-to-Fine Attention")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/harvardnlp/im2markup"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://aryanvij02.medium.com/push-ups-with-python-mediapipe-open-a544bd9b4351"},"Push-ups with Python, mediapipe and OpenCV")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30402651"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/Sanster/lama-cleaner"},"Lama-cleaner: Image inpainting tool powered by LaMa")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.10401"},"Vision-Language Pre-Training with Triple Contrastive Learning (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/uta-smile/TCL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/timzhang642/3D-Machine-Learning"},"3D Machine Learning resources/papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/voxel51/fiftyone"},"FiftyOne")," - Open-source tool for building high-quality datasets and computer vision models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.11539"},"Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/YangtaoWANG95/TokenCut"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/luanshiyinyang/awesome-multiple-object-tracking"},"Awesome Multiple object Tracking")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.05054"},"Rethinking Coarse-to-Fine Approach in Single Image Deblurring (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chosj95/MIMO-UNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.06183"},"Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jayleicn/ClipBERT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.11921"},"As-ViT: Auto-scaling Vision Transformers without Training (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/VITA-Group/AsViT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/3DFaceBody/awesome-3dbody-papers"},"Awesome 3D Body Papers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.00616"},"RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MengyangPu/RINDNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/drivendataorg/image-similarity-challenge"},"Image Similarity Challenge")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.14818"},"Blended Diffusion for Text-driven Editing of Natural Images (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/omriav/blended-diffusion"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.16241"},"The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hendrycks/imagenet-r"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nkalavak/awesome-object-pose"},"Awesome Object Pose")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yulunzhang/video-enhancement"},"Video Enhancement papers/resources")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ryanxingql/powerqe"},"PowerQE: An Open Framework for Quality Enhancement of Compressed Visual Data")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.03884"},"Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Haochen-Wang409/U2PL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://magamig.github.io/posts/accurate-image-alignment-and-registration-using-opencv/"},"Accurate Image Alignment and Registration Using OpenCV (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30613745"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/grounded-video-description"},"Video Grounding and Captioning")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/IDEACVR/awesome-detection-transformer"},"Awesome Detection Transformer")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.08985"},"StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/StyleNeRF"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"http://jiataogu.me/style_nerf/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30637403"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.11538"},"Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/iduta/pyconv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.12707"},"MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Vegetebird/MHFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.03605"},"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/IDEACVR/DINO"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zubair-irshad/CenterSnap"},"Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2107.10224"},"CycleMLP: A MLP-like Architecture for Dense Prediction (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ShoufaChen/CycleMLP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/weizhou-geek/Image-Quality-Assessment-Benchmark"},"Image Quality Assessment Benchmark")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.11427"},"StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/royorel/StyleSDF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/"},"Transformers, originally designed to handle language, are taking on vision (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=30629214"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1709.00643"},"Fast Image Processing with Fully-Convolutional Networks (2017)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nrupatunga/Fast-Image-Filters"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1812.01243"},"Efficient Attention: Attention with Linear Complexities (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cmsflash/efficient-attention"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://yandex-research.github.io/ddpm-segmentation/"},"Label-Efficient Semantic Segmentation with Diffusion Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yandex-research/ddpm-segmentation"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cvg/Hierarchical-Localization"},"hloc")," - Modular toolbox for state-of-the-art 6-DoF visual localization."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.10858"},"All Tokens Matter: Token Labeling for Training Better Vision Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zihangJiang/TokenLabeling"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1811.11168"},"Deformable ConvNets v2: More Deformable, Better Results (2018)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.09881"},"Restormer: Efficient Transformer for High-Resolution Image Restoration (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/swz30/Restormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://openreview.net/forum?id=O476oWmiNNp"},"Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/VITA-Group/ViT-Anti-Oversmoothing"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://zju3dv.github.io/neuralrecon/"},"NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/NeuralRecon"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rlczddl/awesome-3d-human-reconstruction"},"Awesome 3D Human Reconstruction")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/lijiaman/awesome-3d-human"},"Awesome 3D Human Resources List")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.03545"},"A ConvNet for the 2020s (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/ConvNeXt"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/FrancescoSaverioZuppichini/ConvNext"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/TachibanaYoshino/Remote-sensing-image-semantic-segmentation"},"Remote-sensing-image-semantic-segmentation")," - Uses Unet-based improved networks to study Remote sensing image semantic segmentation, which is based on keras."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.02872"},"Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/animatable_nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.09517"},"TensoRF: Tensorial Radiance Fields (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apchenstu/TensoRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.01941"},"Autoregressive Image Generation using Residual Quantization (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/RQ-Transformer"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/kakaobrain/rq-vae-transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/hmartelb/Pix2Pix-Timbre-Transfer"},"Pix2Pix Timbre Transfer")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.09301"},"One-Shot Adaptation of GAN in Just One CLIP (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/submission6378/OneshotCLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.14635"},"PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/CVMI-Lab/PAConv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.12602"},"VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MCG-NJU/VideoMAE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ucasligang/awesome-MIM"},"Awesome Masked Image Modeling")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.13249"},"BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/amazon-research/bigdetection"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.01293"},"A Transformer-Based Siamese Network for Change Detection (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/wgcban/ChangeFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.01486"},"Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/QVPR/Patch-NetVLAD"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.01903"},"Robust fine-tuning of zero-shot models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mlfoundations/wise-ft"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2105.06464"},"DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/DiscoBox"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.11094"},"GroupViT: Semantic Segmentation Emerges from Text Supervision (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/GroupViT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.02503"},"HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/wgcban/HyperTransformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.10489"},"TVConv: Efficient Translation Variant Convolution for Layout-aware Visual Processing (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JierunChen/TVConv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/marcoslucianops/DeepStream-Yolo"},"DeepStream-Yolo")," - NVIDIA DeepStream SDK 6.0.1 configuration for YOLO models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.05550"},"An Empirical Investigation of 3D Anomaly Detection and Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/eliahuhorwitz/3D-ADS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.04017"},"Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/syguan96/DynaBOA"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.11418"},"Layered Neural Atlases for Consistent Video Editing (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ykasten/layered-neural-atlases"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/YapengTian/TDAN-VSR-CVPR-2020"},"TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution (2020)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://chenyanglei.github.io/sfpwild/index.html"},"Shape from Polarization for Complex Scenes in the Wild (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ChenyangLEI/sfp-wild"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/pix2seq"},"Pix2Seq")," - General framework for turning RGB pixels into semantically meaningful sequences."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://gait3d.github.io/"},"Gait Recognition in the Wild with Dense 3D Representations and A Benchmark (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Gait3D/Gait3D-Benchmark"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/jaketae/ensemble-transformers"},"Ensembling Hugging Face Transformers made easy")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1904.05068"},"Relational Knowledge Distillation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lenscloth/RKD"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.12130"},"NICE-SLAM: Neural Implicit Scalable Encoding for SLAM (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cvg/nice-slam"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1711.07566"},"Neural 3D Mesh Renderer (2017)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/daniilidis-group/neural_renderer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.14463"},"Large-scale Bilingual Language-Image Contrastive Learning (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/navervision/KELIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/openMVG/openMVG"},"OpenMVG")," - Open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.04148"},"Neural Points: Point Cloud Representation with Neural Fields (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/WanquanF/NeuralPoints"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/vinissimus/opencv-js-webworker"},"OpenCV JS Web Worker")," - Getting started with OpenCV compiled to Webassembly and loaded in a worker."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.14297"},"Learning Graph Regularisation for Guided Super-Resolution (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/prs-eth/graph-super-resolution"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.14291"},"Video Polyp Segmentation: A Deep Learning Perspective (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/GewelsJI/VPS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.13664"},"Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MathLee/ACCoNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.09035"},"HybridNets: End-to-End Perception Network (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/datvuthanh/HybridNets"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://shsf0817.github.io/hdr-nerf/"},"HDR-NeRF: High Dynamic Range Neural Radiance Fields (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/shsf0817/hdr-nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.16507"},"AdaMixer: A Fast-Converging Query-Based Object Detector (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MCG-NJU/AdaMixer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.11082"},"MixFormer: End-to-End Tracking with Iterative Mixed Attention (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/MCG-NJU/MixFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://raywzy.com/Old_Film/"},"Bringing Old Films Back to Life (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/raywzy/Bringing-Old-Films-Back-to-Life"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nvlabs.github.io/nvdiffrec/"},"Extracting Triangular 3D Models, Materials, and Lighting From Images (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/nvdiffrec"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.07991"},"LiT: Zero-Shot Transfer with Locked-image text Tuning (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/giffmana/status/1508400604082806785"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.13792"},"LAFITE: Towards Language-Free Training for Text-to-Image Generation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/drboog/Lafite"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://neural-3d-video.github.io/"},"Neural 3D Video Synthesis from Multi-view Video (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Neural_3D_Video"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/tianyeli/tofu"},"ToFu: Topologically Consistent Multi-View Face Inference Using Volumetric Sampling (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1904.01786"},"Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ShichenLiu/SoftRas"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/frankmocap"},"FrankMocap: A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator (2021)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/rdeepak2002/reddit-place-script-2022"},"Reddit Place Script 2022")," - Script to draw an image onto r/place."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2108.08536"},"A Unified Objective for Novel Class Discovery (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/DonkeyShot21/UNO"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zhulf0804/3D-PointCloud"},"Papers and Datasets about Point Cloud")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.00613"},"On the Importance of Asymmetry for Siamese Representation Learning (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/asym-siam"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/yewzijian/RegTR"},"REGTR: End-to-end Point Cloud Correspondences with Transformers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2007.01294"},"A Closer Look at Local Aggregation Operators in Point Cloud Analysis (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zeliu98/CloserLook3D"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.15355"},"Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/clovaai/puridiver"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.00227"},"Perception Prioritized Training of Diffusion Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jychoi118/P2-weighting"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1908.03557"},"VisualBERT: A Simple and Performant Baseline for Vision and Language (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/uclanlp/visualbert"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.01678"},"MultiMAE: Multi-modal Multi-task Masked Autoencoders (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/EPFL-VILAB/MultiMAE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.10689"},"NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Totoro97/NeuS"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.02603"},"Towards Open World Object Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/JosephKJ/OWOD"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/DirtyHarryLYL/Transformer-in-Vision"},"Transformer in Vision")," - Recent Transformer-based CV and related works."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.15193"},"Shunted Self-Attention via Multi-Scale Token Aggregation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/OliverRensu/Shunted-Transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ajabri.github.io/videowalk/"},"Space-Time Correspondence as a Contrastive Random Walk (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ajabri/videowalk"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.04200"},"MaskGIT: Masked Generative Image Transformer (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/maskgit"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/alibaba/EasyCV"},"EasyCV")," - All-in-one computer vision toolbox based on PyTorch."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.02964"},"Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hustvl/MIMDet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/radekd91/emoca"},"EMOCA: Emotion Driven Monocular Face Capture and Animation (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.13161"},"Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/alvinliu0/HA2G"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"http://www.liuyebin.com/faceverse/faceverse.html"},"FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/LizhenWangT/FaceVerse"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.02413"},"PointCLIP: Point Cloud Understanding by CLIP (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZrrSkywalker/PointCLIP"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.03645"},"DaViT: Dual Attention Vision Transformers (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dingmyu/davit"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.04053"},"DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/j-min/DallEval"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.01923"},"Recovering 3D Human Mesh from Monocular Images: A Survey (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/tinatiansjz/hmr-survey"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.03458v1"},"Video Diffusion Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://video-diffusion.github.io/"},"Web"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/video-diffusion-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.01697"},"MaxViT: Multi-Axis Vision Transformer (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ChristophReich1996/MaxViT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.03610"},"Unified Contrastive Learning in Image-Text-Label Space (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/UniCL"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.00633"},"RePOSE: Fast 6D Object Pose Refinement via Deep Texture Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sh8/RePOSE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.12579"},"MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/BIT-DA/MetaSAug"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.07615"},"Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chunbolang/BAM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.02973"},"MAXIM: Multi-Axis MLP for Image Processing (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google-research/maxim"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://k155la3.blog/2022/04/04/tensil-tutorial-for-yolo-v4-tiny-on-ultra96-v2/"},"Tensil tutorial for YOLO v4 Tiny on Ultra96 V2 (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1909.11740"},"UNITER: UNiversal Image-TExt Representation Learning (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ChenRocks/UNITER"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://dynamic-video-depth.github.io/"},"Consistent Depth of Moving Objects in Video (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/google/dynamic-video-depth"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.04850"},"Bridging Video-text Retrieval with Multiple Choice Questions (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/TencentARC/MCQ"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2001.08735"},"Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hytseng0509/CrossDomainFewShot"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.04645"},"BACON: Band-limited Coordinate Networks for Multiscale Scene Representation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/computational-imaging/bacon"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.03475"},"Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Alibaba-MIIL/Solving_ImageNet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.vincentsitzmann.com/lfns/"},"Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/vsitzmann/light-field-networks"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.00928"},"SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/VITA-Group/SinNeRF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.01530"},"StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lukasHoel/stylemesh"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.07143"},"Neighborhood Attention Transformer (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/SHI-Labs/Neighborhood-Attention-Transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2102.02502"},"3D Surface Reconstruction From Multi-Date Satellite Images (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/SBCV/SatelliteSurfaceReconstruction"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.02861"},"Decoupling Makes Weakly Supervised Local Feature Better (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.14447"},"ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/YoadTew/zero-shot-image-to-text"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/EasyMocap"},"EasyMocap")," - Open-source toolbox for markerless human motion capture from RGB videos."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.08483"},"QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sapphire497/query-selected-attention"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1909.13226"},"PolarMask: Single Shot Instance Segmentation with Polar Representation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xieenze/PolarMask"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.10704"},"Latent Video Transformer (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rakhimovv/lvt"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2003.08934"},"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/unixpickle/learn-nerf"},"JAX Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.11895"},"A Latent Transformer for Disentangled Face Editing in Images and Videos (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/InterDigitalInc/latent-transformer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1903.09760"},"Photorealistic Style Transfer via Wavelet Transforms (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/clovaai/WCT2"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sayakpaul/probing-vits"},"Probing ViTs")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.03288"},"Dense Depth Priors for Neural Radiance Fields from Sparse Input Views (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/barbararoessle/dense_depth_priors_nerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.04215"},"Self-Supervised Models are Continual Learners (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/DonkeyShot21/cassle"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.vis.xyz/pub/transfiner/"},"Mask Transfiner for High-Quality Instance Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/SysCV/transfiner"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/naver-ai/vidt"},"An Extendable, Efficient and Effective Transformer-based Object Detector (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.11435"},"Learned Queries for Efficient Local Attention (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/moabarar/qna"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.10455"},"3D Human Pose Estimation with Spatial and Temporal Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zczcwh/PoseFormer"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1811.11742"},"3D human pose estimation in video with temporal convolutions and semi-supervised training (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/VideoPose3D"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.sciencedirect.com/science/article/abs/pii/S1077314221001818"},"MC-Calib: A generic and robust calibration toolbox for multi-camera systems (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rameau-fr/MC-Calib"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2204.12451"},"Understanding The Robustness in Vision Transformers (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/NVlabs/FAN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.14826"},"Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/liuzechun/Nonuniform-to-Uniform-Quantization"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model"},"Tackling multiple tasks with a single visual language model (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/flamingo-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/DeepMind/status/1519686445258231811"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.02638"},"Associating Objects with Transformers for Video Object Segmentation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/z-x-yang/AOT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/xingyizhou/UniDet"},"Simple multi-dataset detection")," - Object detection on multiple datasets with an automatically learned unified label space."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2006.04139"},"Learning Texture Transformer Network for Image Super-Resolution (2020)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/researchmm/TTSR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.16427"},"Balanced MSE for Imbalanced Visual Regression (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/jiawei-ren/BalancedMSE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.17234"},"Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nv-nguyen/template-pose"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.05670"},"Action-Conditioned 3D Human Motion Synthesis with Transformer VAE (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Mathux/ACTOR"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2103.06879"},"CoMoGAN: continuous model-guided image-to-image translation (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/cv-rits/CoMoGAN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/cdcseacave/openMVS"},"OpenMVS")," - Open Multi-View Stereo reconstruction library."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.05297"},"Sliced Recursive Transformer (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/szq0214/SReT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.01999"},"Neural Dual Contouring (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/czq142857/NDC"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/subeeshvasu/Awesome-Deblurring"},"Awesome Deblurring")," - Curated list of resources for Image and Video Deblurring."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.01917"},"CoCa: Contrastive Captioners are Image-Text Foundation Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/CoCa-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.01972"},"Sequencer: Deep LSTM for Image Classification (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.02655"},"Language Models Can See: Plugging Visual Controls in Text Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yxuansu/MAGIC"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/davanstrien/flyswot"},"flyswot")," - CLI for Hugging Face Transformers image classification models."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://zju3dv.github.io/manhattan_sdf/"},"Neural 3D Scene Reconstruction with the Manhattan-world Assumption (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/manhattan_sdf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.15625"},"PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Garfield-kh/PoseTriplet"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/RisingSayak/status/1515918406171914240"},"What do the Vision Transformers learn? How do they encode anything useful for image recognition? (2022)")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.15712"},"Integrative Few-Shot Learning for Classification and Segmentation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/dahyun-kang/ifsl"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.08799"},"DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/rubenwiersma/deltaconv"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2012.00926"},"pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/pi-GAN-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.03052"},"Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/OFA-Sys/OFA"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.03892"},"ConvMAE: Masked Convolution Meets Masked Autoencoders (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Alpha-VL/ConvMAE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.00667"},"Deep Kernelized Dense Geometric Matching (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/Parskatt/DKM"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.08414"},"Unsupervised Semantic Segmentation by Distilling Feature Correspondences (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/mhamilton723/STEGO"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.06844"},"RecursiveMix: Mixed Learning with History (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/implus/RecursiveMix-pytorch"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/open-mmlab/mmdetection3d"},"MMDetection3d")," - OpenMMLab's next-generation platform for general 3D object detection."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://imagen.research.google/"},"Imagen: Text-to-Image Diffusion Models")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/JeffDean/status/1528951937948741632"},"Tweet"),") (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/lucidrains/imagen-pytorch"},"Code"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31484562"},"HN"),") (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31513919"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2109.08141"},"An End-to-End Transformer Model for 3D Object Detection (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/3detr"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.12955"},"Neural 3D Reconstruction in the Wild (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/NeuralRecon-W"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/maria-korosteleva/Body-Shape-Estimation"},"Body shape and pose estimation on 3D scans of people in clothing using Ceres Solver")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2111.06091"},"A Survey of Visual Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/liuyang-ict/awesome-visual-transformers"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nerfies.github.io/"},"Nerfies: Deformable Neural Radiance Fields (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nerfies/nerfies.github.io"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://scienceplusplus.org/visions/index.html"},"Working notes on the role of vision papers in basic science (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://twitter.com/michael_nielsen/status/1530659395453202433"},"Tweet"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/THUDM/CogVideo"},"CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31561845"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.14865"},"Prompt-aligned Gradient for Prompt Tuning (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/BeierZhu/Prompt-align"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.15996"},"Text2Human: Text-Driven Controllable Human Image Generation (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yumingj/Text2Human"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.12257"},"OnePose: One-Shot Object Pose Estimation without CAD Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/zju3dv/OnePose"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2205.13524"},"PREF: Phasorial Embedding Fields for Compact Neural Representations (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hbb1/PREF"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2206.01161"},"Optimizing Relevance Maps of Vision Transformers Improves Robustness (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hila-chefer/RobustViT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.17274"},"Exploring Visual Prompts for Adapting Large-Scale Models (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/hjbahng/visual_prompting"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/sensity-ai/dot"},"Deepfake Offensive Toolkit")," - Makes real-time, controllable deepfakes ready for virtual cameras injection. (",(0,n.kt)("a",{parentName:"li",href:"https://news.ycombinator.com/item?id=31650797"},"HN"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2203.12338"},"Real-time Object Detection for Streaming Perception (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/yancie-yjr/StreamYOLO"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ZFTurbo/volumentations"},"Volumentations 3D")," - Library for 3D augmentations."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise"},"Awesome Learning with Label Noise")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ma-xu.github.io/LIVE/"},"LIVE: Towards Layer-wise Image Vectorization (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/ma-xu/LIVE"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2112.01529"},"BEVT: BERT Pretraining of Video Transformers (2021)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/xyzforever/BEVT"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://nv-tlabs.github.io/vqad/"},"Variable Bitrate Neural Fields (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nv-tlabs/vqad"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1907.05740"},"Gated-SCNN: Gated Shape CNNs for Semantic Segmentation (2019)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/nv-tlabs/GSCNN"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2206.02967"},"Masked Unsupervised Self-training for Zero-shot Image Classification (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/salesforce/MUST"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2201.04127"},"HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/chungyiweng/humannerf"},"Code"),")"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics"},"Awesome Implicit NeRF Robotics")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2206.01191"},"EfficientFormer: Vision Transformers at MobileNet Speed (2022)")," (",(0,n.kt)("a",{parentName:"li",href:"https://github.com/snap-research/EfficientFormer"},"Code"),")")))}c.isMDXComponent=!0}}]);